2024-12-27 09:27:47,352 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 09:27:47,909 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 09:27:47,952 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 09:27:47,958 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 09:27:48,161 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 09:27:48,772 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 09:27:49,449 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 09:27:49,805 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 09:27:50,267 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 09:27:50,267 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 09:27:50,268 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 09:27:50,275 - INFO - [pid 19770] Worker Worker(salt=1450631671, workers=1, host=Nanas.local, username=fajarianatm, pid=19770) done      Extract()
2024-12-27 09:27:50,276 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:27:50,278 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 09:27:50,278 - DEBUG - Asking scheduler for work...
2024-12-27 09:27:50,280 - DEBUG - Pending tasks: 2
2024-12-27 09:27:50,280 - INFO - [pid 19770] Worker Worker(salt=1450631671, workers=1, host=Nanas.local, username=fajarianatm, pid=19770) running   Load()
2024-12-27 09:27:50,282 - INFO - Read Load Query - SUCCESS
2024-12-27 09:27:50,944 - INFO - Read Extracted Data - SUCCESS
2024-12-27 09:27:50,945 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:27:51,039 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 09:27:51,039 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 09:27:52,844 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 09:27:52,925 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 09:27:52,928 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 09:27:54,029 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 09:27:56,843 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 09:28:00,734 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 09:28:03,072 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 09:28:05,561 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 09:28:05,561 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 09:28:12,769 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 09:28:12,780 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 09:28:12,844 - INFO - [pid 19770] Worker Worker(salt=1450631671, workers=1, host=Nanas.local, username=fajarianatm, pid=19770) done      Load()
2024-12-27 09:28:12,845 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:28:12,848 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 09:28:12,848 - DEBUG - Asking scheduler for work...
2024-12-27 09:28:12,849 - DEBUG - Pending tasks: 1
2024-12-27 09:28:12,850 - INFO - [pid 19770] Worker Worker(salt=1450631671, workers=1, host=Nanas.local, username=fajarianatm, pid=19770) running   Transform()
2024-12-27 09:28:12,852 - INFO - Read Transform Query - SUCCESS
2024-12-27 09:28:12,853 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:28:12,853 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 09:28:12,872 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 09:28:12,908 - ERROR - Transform Tables - FAILED
2024-12-27 09:28:12,911 - ERROR - [pid 19770] Worker Worker(salt=1450631671, workers=1, host=Nanas.local, username=fajarianatm, pid=19770) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column c.customer_zip_code does not exist
LINE 15:     c.customer_zip_code,
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column c.customer_zip_code does not exist
LINE 15:     c.customer_zip_code,
             ^

[SQL: -- Step 1: Initial Load of dim_customers data
-- This will insert the data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at  -- Set created_at timestamp to current time
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

------------------------------------------------------------------------------------------------------------

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert new customers data into the dim_customers table
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark as current when new data is inserted
        NOW()  -- Set the created timestamp
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create a trigger for inserting new rows into dim_customers
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();

------------------------------------------------------------------------------------------------------------

-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Mark the old record as expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    );

    -- Insert a new version of the customer with updated details
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark the new version as current
        NOW()  -- Set the created timestamp for the new version
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Update to Existing Data (SCD Type 2)
CREATE TRIGGER customer_update_trigger
AFTER UPDATE OF customer_zip_code, customer_city, customer_state
ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 09:28:12,936 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:28:12,942 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 09:28:12,942 - DEBUG - Asking scheduler for work...
2024-12-27 09:28:12,943 - DEBUG - Done
2024-12-27 09:28:12,943 - DEBUG - There are no more tasks to run at this time
2024-12-27 09:28:12,943 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 09:28:12,943 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 09:28:12,943 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 09:28:12,943 - INFO - Worker Worker(salt=1450631671, workers=1, host=Nanas.local, username=fajarianatm, pid=19770) was stopped. Shutting down Keep-Alive thread
2024-12-27 09:28:12,944 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 09:34:57,070 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 09:34:57,514 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 09:34:57,554 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 09:34:57,558 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 09:34:57,763 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 09:34:58,371 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 09:34:58,913 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 09:34:59,256 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 09:34:59,667 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 09:34:59,667 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 09:34:59,671 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 09:34:59,678 - INFO - [pid 22796] Worker Worker(salt=9465165136, workers=1, host=Nanas.local, username=fajarianatm, pid=22796) done      Extract()
2024-12-27 09:34:59,678 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:34:59,680 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 09:34:59,680 - DEBUG - Asking scheduler for work...
2024-12-27 09:34:59,682 - DEBUG - Pending tasks: 2
2024-12-27 09:34:59,682 - INFO - [pid 22796] Worker Worker(salt=9465165136, workers=1, host=Nanas.local, username=fajarianatm, pid=22796) running   Load()
2024-12-27 09:34:59,684 - INFO - Read Load Query - SUCCESS
2024-12-27 09:35:00,359 - INFO - Read Extracted Data - SUCCESS
2024-12-27 09:35:00,359 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:35:00,448 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 09:35:00,448 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 09:35:02,237 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 09:35:02,280 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 09:35:02,283 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 09:35:03,321 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 09:35:06,060 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 09:35:09,950 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 09:35:12,158 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 09:35:14,895 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 09:35:14,896 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 09:35:21,796 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 09:35:21,813 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 09:35:21,875 - INFO - [pid 22796] Worker Worker(salt=9465165136, workers=1, host=Nanas.local, username=fajarianatm, pid=22796) done      Load()
2024-12-27 09:35:21,876 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:35:21,879 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 09:35:21,879 - DEBUG - Asking scheduler for work...
2024-12-27 09:35:21,880 - DEBUG - Pending tasks: 1
2024-12-27 09:35:21,880 - INFO - [pid 22796] Worker Worker(salt=9465165136, workers=1, host=Nanas.local, username=fajarianatm, pid=22796) running   Transform()
2024-12-27 09:35:21,883 - INFO - Read Transform Query - SUCCESS
2024-12-27 09:35:21,883 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:35:21,883 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 09:35:22,251 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 09:35:22,289 - ERROR - Transform Tables - FAILED
2024-12-27 09:35:22,292 - ERROR - [pid 22796] Worker Worker(salt=9465165136, workers=1, host=Nanas.local, username=fajarianatm, pid=22796) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "customer_zip_code" of relation "customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "customer_zip_code" of relation "customers" does not exist

[SQL: -- Step 1: Initial Load of dim_customers data
-- This will insert the data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code_prefix,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at  -- Set created_at timestamp to current time
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

------------------------------------------------------------------------------------------------------------

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert new customers data into the dim_customers table
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark as current when new data is inserted
        NOW()  -- Set the created timestamp
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create a trigger for inserting new rows into dim_customers
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();

------------------------------------------------------------------------------------------------------------

-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Mark the old record as expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    );

    -- Insert a new version of the customer with updated details
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark the new version as current
        NOW()  -- Set the created timestamp for the new version
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Update to Existing Data (SCD Type 2)
CREATE TRIGGER customer_update_trigger
AFTER UPDATE OF customer_zip_code, customer_city, customer_state
ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 09:35:22,314 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:35:22,318 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 09:35:22,318 - DEBUG - Asking scheduler for work...
2024-12-27 09:35:22,320 - DEBUG - Done
2024-12-27 09:35:22,320 - DEBUG - There are no more tasks to run at this time
2024-12-27 09:35:22,320 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 09:35:22,320 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 09:35:22,320 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 09:35:22,320 - INFO - Worker Worker(salt=9465165136, workers=1, host=Nanas.local, username=fajarianatm, pid=22796) was stopped. Shutting down Keep-Alive thread
2024-12-27 09:35:22,321 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 09:38:04,331 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 09:38:04,739 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 09:38:04,778 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 09:38:04,783 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 09:38:04,964 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 09:38:05,436 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 09:38:05,975 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 09:38:06,313 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 09:38:06,711 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 09:38:06,711 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 09:38:06,714 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 09:38:06,721 - INFO - [pid 24129] Worker Worker(salt=9154550526, workers=1, host=Nanas.local, username=fajarianatm, pid=24129) done      Extract()
2024-12-27 09:38:06,721 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:38:06,723 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 09:38:06,724 - DEBUG - Asking scheduler for work...
2024-12-27 09:38:06,725 - DEBUG - Pending tasks: 2
2024-12-27 09:38:06,725 - INFO - [pid 24129] Worker Worker(salt=9154550526, workers=1, host=Nanas.local, username=fajarianatm, pid=24129) running   Load()
2024-12-27 09:38:06,727 - INFO - Read Load Query - SUCCESS
2024-12-27 09:38:07,458 - INFO - Read Extracted Data - SUCCESS
2024-12-27 09:38:07,459 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:38:07,567 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 09:38:07,567 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 09:38:09,453 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 09:38:09,494 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 09:38:09,499 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 09:38:10,494 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 09:38:13,260 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 09:38:17,144 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 09:38:19,399 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 09:38:21,816 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 09:38:21,816 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 09:38:28,283 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 09:38:28,287 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 09:38:28,369 - INFO - [pid 24129] Worker Worker(salt=9154550526, workers=1, host=Nanas.local, username=fajarianatm, pid=24129) done      Load()
2024-12-27 09:38:28,369 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:38:28,372 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 09:38:28,373 - DEBUG - Asking scheduler for work...
2024-12-27 09:38:28,374 - DEBUG - Pending tasks: 1
2024-12-27 09:38:28,374 - INFO - [pid 24129] Worker Worker(salt=9154550526, workers=1, host=Nanas.local, username=fajarianatm, pid=24129) running   Transform()
2024-12-27 09:38:28,377 - INFO - Read Transform Query - SUCCESS
2024-12-27 09:38:28,378 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:38:28,378 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 09:38:28,747 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 09:38:28,780 - ERROR - Transform Tables - FAILED
2024-12-27 09:38:28,783 - ERROR - [pid 24129] Worker Worker(salt=9154550526, workers=1, host=Nanas.local, username=fajarianatm, pid=24129) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "customer_zip_code" of relation "customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "customer_zip_code" of relation "customers" does not exist

[SQL: -- Step 1: Initial Load of dim_customers data
-- This will insert the data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code_prefix,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at  -- Set created_at timestamp to current time
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

------------------------------------------------------------------------------------------------------------

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert new customers data into the dim_customers table
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark as current when new data is inserted
        NOW()  -- Set the created timestamp
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create a trigger for inserting new rows into dim_customers
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();

------------------------------------------------------------------------------------------------------------

-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Mark the old record as expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    );

    -- Insert a new version of the customer with updated details
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark the new version as current
        NOW()  -- Set the created timestamp for the new version
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Update to Existing Data (SCD Type 2)
CREATE TRIGGER customer_update_trigger
AFTER UPDATE OF customer_zip_code, customer_city, customer_state
ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 09:38:28,800 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:38:28,808 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 09:38:28,808 - DEBUG - Asking scheduler for work...
2024-12-27 09:38:28,810 - DEBUG - Done
2024-12-27 09:38:28,810 - DEBUG - There are no more tasks to run at this time
2024-12-27 09:38:28,810 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 09:38:28,810 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 09:38:28,810 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 09:38:28,810 - INFO - Worker Worker(salt=9154550526, workers=1, host=Nanas.local, username=fajarianatm, pid=24129) was stopped. Shutting down Keep-Alive thread
2024-12-27 09:38:28,811 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 09:43:42,620 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 09:43:43,026 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 09:43:43,066 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 09:43:43,070 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 09:43:43,245 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 09:43:43,746 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 09:43:44,338 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 09:43:44,672 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 09:43:45,060 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 09:43:45,060 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 09:43:45,062 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 09:43:45,069 - INFO - [pid 26492] Worker Worker(salt=6256850417, workers=1, host=Nanas.local, username=fajarianatm, pid=26492) done      Extract()
2024-12-27 09:43:45,069 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:43:45,072 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 09:43:45,072 - DEBUG - Asking scheduler for work...
2024-12-27 09:43:45,073 - DEBUG - Pending tasks: 2
2024-12-27 09:43:45,073 - INFO - [pid 26492] Worker Worker(salt=6256850417, workers=1, host=Nanas.local, username=fajarianatm, pid=26492) running   Load()
2024-12-27 09:43:45,075 - INFO - Read Load Query - SUCCESS
2024-12-27 09:43:45,739 - INFO - Read Extracted Data - SUCCESS
2024-12-27 09:43:45,739 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:43:45,832 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 09:43:45,833 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 09:43:47,640 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 09:43:47,681 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 09:43:47,684 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 09:43:48,714 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 09:43:51,631 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 09:43:55,619 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 09:43:57,943 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 09:44:00,391 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 09:44:00,391 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 09:44:07,325 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 09:44:07,333 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 09:44:07,391 - INFO - [pid 26492] Worker Worker(salt=6256850417, workers=1, host=Nanas.local, username=fajarianatm, pid=26492) done      Load()
2024-12-27 09:44:07,392 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:44:07,395 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 09:44:07,395 - DEBUG - Asking scheduler for work...
2024-12-27 09:44:07,397 - DEBUG - Pending tasks: 1
2024-12-27 09:44:07,397 - INFO - [pid 26492] Worker Worker(salt=6256850417, workers=1, host=Nanas.local, username=fajarianatm, pid=26492) running   Transform()
2024-12-27 09:44:07,400 - INFO - Read Transform Query - SUCCESS
2024-12-27 09:44:07,401 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:44:07,401 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 09:44:07,849 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 09:44:07,881 - ERROR - Transform Tables - FAILED
2024-12-27 09:44:07,885 - ERROR - [pid 26492] Worker Worker(salt=6256850417, workers=1, host=Nanas.local, username=fajarianatm, pid=26492) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "customer_zip_code" of relation "customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "customer_zip_code" of relation "customers" does not exist

[SQL: -- Step 1: Initial Load of dim_customers data
-- This will insert the data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code_prefix AS customer_zip_code,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at  -- Set created_at timestamp to current time
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

------------------------------------------------------------------------------------------------------------

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert new customers data into the dim_customers table
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark as current when new data is inserted
        NOW()  -- Set the created timestamp
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create a trigger for inserting new rows into dim_customers
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();

------------------------------------------------------------------------------------------------------------

-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Mark the old record as expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    );

    -- Insert a new version of the customer with updated details
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark the new version as current
        NOW()  -- Set the created timestamp for the new version
    );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Update to Existing Data (SCD Type 2)
CREATE TRIGGER customer_update_trigger
AFTER UPDATE OF customer_zip_code, customer_city, customer_state
ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 09:44:07,905 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:44:07,910 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 09:44:07,910 - DEBUG - Asking scheduler for work...
2024-12-27 09:44:07,912 - DEBUG - Done
2024-12-27 09:44:07,912 - DEBUG - There are no more tasks to run at this time
2024-12-27 09:44:07,912 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 09:44:07,912 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 09:44:07,912 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 09:44:07,912 - INFO - Worker Worker(salt=6256850417, workers=1, host=Nanas.local, username=fajarianatm, pid=26492) was stopped. Shutting down Keep-Alive thread
2024-12-27 09:44:07,914 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 09:53:57,763 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 09:53:58,182 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 09:53:58,217 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 09:53:58,221 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 09:53:58,406 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 09:53:58,878 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 09:53:59,416 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 09:53:59,750 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 09:54:00,150 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 09:54:00,150 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 09:54:00,153 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 09:54:00,160 - INFO - [pid 30739] Worker Worker(salt=6448848778, workers=1, host=Nanas.local, username=fajarianatm, pid=30739) done      Extract()
2024-12-27 09:54:00,160 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:54:00,162 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 09:54:00,163 - DEBUG - Asking scheduler for work...
2024-12-27 09:54:00,164 - DEBUG - Pending tasks: 2
2024-12-27 09:54:00,164 - INFO - [pid 30739] Worker Worker(salt=6448848778, workers=1, host=Nanas.local, username=fajarianatm, pid=30739) running   Load()
2024-12-27 09:54:00,166 - INFO - Read Load Query - SUCCESS
2024-12-27 09:54:00,846 - INFO - Read Extracted Data - SUCCESS
2024-12-27 09:54:00,847 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:54:00,956 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 09:54:00,956 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 09:54:02,761 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 09:54:02,804 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 09:54:02,807 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 09:54:03,838 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 09:54:06,717 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 09:54:10,717 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 09:54:13,132 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 09:54:15,832 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 09:54:15,832 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 09:54:22,616 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 09:54:22,620 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 09:54:22,675 - INFO - [pid 30739] Worker Worker(salt=6448848778, workers=1, host=Nanas.local, username=fajarianatm, pid=30739) done      Load()
2024-12-27 09:54:22,676 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:54:22,680 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 09:54:22,680 - DEBUG - Asking scheduler for work...
2024-12-27 09:54:22,683 - DEBUG - Pending tasks: 1
2024-12-27 09:54:22,683 - INFO - [pid 30739] Worker Worker(salt=6448848778, workers=1, host=Nanas.local, username=fajarianatm, pid=30739) running   Transform()
2024-12-27 09:54:22,685 - INFO - Read Transform Query - SUCCESS
2024-12-27 09:54:22,686 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:54:22,686 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 09:54:22,998 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-27 09:54:23,007 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-27 09:54:23,008 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 09:54:23,040 - ERROR - Transform Tables - FAILED
2024-12-27 09:54:23,043 - ERROR - [pid 30739] Worker Worker(salt=6448848778, workers=1, host=Nanas.local, username=fajarianatm, pid=30739) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.SyntaxError: syntax error at or near "SELECT"
LINE 38: SELECT * FROM final.dim_products;
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 111, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.SyntaxError) syntax error at or near "SELECT"
LINE 38: SELECT * FROM final.dim_products;
         ^

[SQL: -- Step 1: Initial Load od dim_products data
-- This will insert teh data into dim_products for the first time
INSERT INTO final.dim_products (
    product_id,
    product_nk,
    product_category_name,
    product_category_name_english,
    product_name_length,
    product_description_length,
    product_photos_qty,
    product_weight_g,
    product_length_cm,
    product_height_cm,
    product_width_cm,
    created_at,
    updated_at
)

SELECT
    p.id AS product_id,
    p.product_id AS product_nk,
    p.product_category_name,
    pc.product_category_name_english,
    p.product_name_length,
    p.product_description_length,
    p.product_photos_qty,
    p.product_weight_g,
    p.product_length_cm,
    p.product_height_cm,
    p.product_width_cm,
    NOW() AS created_at,
    NOW() AS updated_at
FROM stg.products AS p
JOIN stg.product_category_name_translation AS pc 
    ON p.product_category_name = pc.product_category_name

-- Verivy the data inserted
SELECT * FROM final.dim_products;

------------------------------------------------------------------------------------------------------------

-- Step 2: Trigger Functions to Insert New Data into dim_products
CREATE OR REPLACE FUNCTION final.insert_dim_products()
RETURN TRIGGER AS $$
BEGIN
    -- Insert new products data into the dim_products table
    INSERT INTO final.dim_products (
        product_id,
        product_nk,
        product_category_name,
        product_category_name_english,
        product_name_length,
        product_description_length,
        product_photos_qty,
        product_weight_g,
        product_length_cm,
        product_height_cm,
        product_width_cm,
        created_at,
        updated_at
    )
    SELECT
        NEW.id,
        NEW.product_id,
        NEW.product_category_name,
        pc.product_category_name_english,
        NEW.product_name_length,
        NEW.product_description_length,
        NEW.product_photos_qty,
        NEW.product_weight_g,
        NEW.product_length_cm,
        NEW.product_height_cm,
        NEW.product_width_cm,
        NOW(),
        NOW()
    FROM stg.product_category_name_translation AS pc
    WHERE NEW.product_category_name = pc.product_category_name;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql

-- Create a trigger for inserting new rows into dim_sellers
CREATE TRIGGER products_insert_trigger
AFTER INSERT ON stg.products
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_products();

------------------------------------------------------------------------------------------------------------

-- Step 3: SCD Type 1 Update (Insert New Version and Update the updated_at)
CREATE OR REPLACE FUNCTION final.update_dim_products()
RETURNS TRIGGER AS $$
BEGIN
    -- Update dim_products with new values from stg.products
    UPDATE final.dim_products
    SET
        product_category_name = NEW.product_category_name,
        product_category_name_english = (
            SELECT pc.product_category_name_english
            FROM stg.product_category_name_translation AS pc
            WHERE pc.product_category_name = NEW.product_category_name
        ),
        product_name_length = NEW.product_name_length,
        product_description_length = NEW.product_description_length,
        product_photos_qty = NEW.product_photos_qty,
        product_weight_g = NEW.product_weight_g,
        product_length_cm = NEW.product_length_cm,
        product_height_cm = NEW.product_height_cm,
        product_width_cm = NEW.product_width_cm,
        updated_at = NOW() -- Update timestamp for tracking changes
    WHERE product_nk = NEW.product_id; -- Match on natural key

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Updates to Relevant Columns in stg.products
CREATE TRIGGER products_update_trigger
AFTER UPDATE OF 
    product_category_name,
    product_name_length,
    product_description_length,
    product_photos_qty,
    product_weight_g,
    product_length_cm,
    product_height_cm,
    product_width_cm
ON stg.products
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_products();

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 09:54:23,065 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:54:23,070 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 09:54:23,070 - DEBUG - Asking scheduler for work...
2024-12-27 09:54:23,071 - DEBUG - Done
2024-12-27 09:54:23,072 - DEBUG - There are no more tasks to run at this time
2024-12-27 09:54:23,072 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 09:54:23,072 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 09:54:23,072 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 09:54:23,072 - INFO - Worker Worker(salt=6448848778, workers=1, host=Nanas.local, username=fajarianatm, pid=30739) was stopped. Shutting down Keep-Alive thread
2024-12-27 09:54:23,073 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 09:58:09,947 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 09:58:10,333 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 09:58:10,371 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 09:58:10,375 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 09:58:10,555 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 09:58:11,016 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 09:58:11,623 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 09:58:11,965 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 09:58:12,362 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 09:58:12,362 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 09:58:12,371 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 09:58:12,378 - INFO - [pid 32525] Worker Worker(salt=9557805289, workers=1, host=Nanas.local, username=fajarianatm, pid=32525) done      Extract()
2024-12-27 09:58:12,379 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:58:12,381 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 09:58:12,381 - DEBUG - Asking scheduler for work...
2024-12-27 09:58:12,382 - DEBUG - Pending tasks: 2
2024-12-27 09:58:12,382 - INFO - [pid 32525] Worker Worker(salt=9557805289, workers=1, host=Nanas.local, username=fajarianatm, pid=32525) running   Load()
2024-12-27 09:58:12,384 - INFO - Read Load Query - SUCCESS
2024-12-27 09:58:13,036 - INFO - Read Extracted Data - SUCCESS
2024-12-27 09:58:13,037 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:58:13,152 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 09:58:13,152 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 09:58:14,983 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 09:58:15,021 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 09:58:15,024 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 09:58:16,041 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 09:58:18,803 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 09:58:22,754 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 09:58:25,025 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 09:58:27,552 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 09:58:27,554 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 09:58:33,811 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 09:58:33,820 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 09:58:33,896 - INFO - [pid 32525] Worker Worker(salt=9557805289, workers=1, host=Nanas.local, username=fajarianatm, pid=32525) done      Load()
2024-12-27 09:58:33,897 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:58:33,900 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 09:58:33,900 - DEBUG - Asking scheduler for work...
2024-12-27 09:58:33,902 - DEBUG - Pending tasks: 1
2024-12-27 09:58:33,902 - INFO - [pid 32525] Worker Worker(salt=9557805289, workers=1, host=Nanas.local, username=fajarianatm, pid=32525) running   Transform()
2024-12-27 09:58:33,904 - INFO - Read Transform Query - SUCCESS
2024-12-27 09:58:33,905 - INFO - Connect to DWH - SUCCESS
2024-12-27 09:58:33,905 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 09:58:34,288 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-27 09:58:34,298 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-27 09:58:34,299 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 09:58:34,328 - ERROR - Transform Tables - FAILED
2024-12-27 09:58:34,331 - ERROR - [pid 32525] Worker Worker(salt=9557805289, workers=1, host=Nanas.local, username=fajarianatm, pid=32525) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.SyntaxError: syntax error at or near "AS"
LINE 44: RETURN TRIGGER AS $$
                        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 111, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.SyntaxError) syntax error at or near "AS"
LINE 44: RETURN TRIGGER AS $$
                        ^

[SQL: -- Step 1: Initial Load od dim_products data
-- This will insert teh data into dim_products for the first time
INSERT INTO final.dim_products (
    product_id,
    product_nk,
    product_category_name,
    product_category_name_english,
    product_name_length,
    product_description_length,
    product_photos_qty,
    product_weight_g,
    product_length_cm,
    product_height_cm,
    product_width_cm,
    created_at,
    updated_at
)

SELECT
    p.id AS product_id,
    p.product_id AS product_nk,
    p.product_category_name,
    pc.product_category_name_english,
    p.product_name_length,
    p.product_description_length,
    p.product_photos_qty,
    p.product_weight_g,
    p.product_length_cm,
    p.product_height_cm,
    p.product_width_cm,
    NOW() AS created_at,
    NOW() AS updated_at
FROM stg.products AS p
JOIN stg.product_category_name_translation AS pc 
    ON p.product_category_name = pc.product_category_name;

-- Verivy the data inserted
SELECT * FROM final.dim_products;

------------------------------------------------------------------------------------------------------------

-- Step 2: Trigger Functions to Insert New Data into dim_products
CREATE OR REPLACE FUNCTION final.insert_dim_products()
RETURN TRIGGER AS $$
BEGIN
    -- Insert new products data into the dim_products table
    INSERT INTO final.dim_products (
        product_id,
        product_nk,
        product_category_name,
        product_category_name_english,
        product_name_length,
        product_description_length,
        product_photos_qty,
        product_weight_g,
        product_length_cm,
        product_height_cm,
        product_width_cm,
        created_at,
        updated_at
    )
    SELECT
        NEW.id,
        NEW.product_id,
        NEW.product_category_name,
        pc.product_category_name_english,
        NEW.product_name_length,
        NEW.product_description_length,
        NEW.product_photos_qty,
        NEW.product_weight_g,
        NEW.product_length_cm,
        NEW.product_height_cm,
        NEW.product_width_cm,
        NOW(),
        NOW()
    FROM stg.product_category_name_translation AS pc
    WHERE NEW.product_category_name = pc.product_category_name;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql

-- Create a trigger for inserting new rows into dim_sellers
CREATE TRIGGER products_insert_trigger
AFTER INSERT ON stg.products
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_products();

------------------------------------------------------------------------------------------------------------

-- Step 3: SCD Type 1 Update (Insert New Version and Update the updated_at)
CREATE OR REPLACE FUNCTION final.update_dim_products()
RETURNS TRIGGER AS $$
BEGIN
    -- Update dim_products with new values from stg.products
    UPDATE final.dim_products
    SET
        product_category_name = NEW.product_category_name,
        product_category_name_english = (
            SELECT pc.product_category_name_english
            FROM stg.product_category_name_translation AS pc
            WHERE pc.product_category_name = NEW.product_category_name
        ),
        product_name_length = NEW.product_name_length,
        product_description_length = NEW.product_description_length,
        product_photos_qty = NEW.product_photos_qty,
        product_weight_g = NEW.product_weight_g,
        product_length_cm = NEW.product_length_cm,
        product_height_cm = NEW.product_height_cm,
        product_width_cm = NEW.product_width_cm,
        updated_at = NOW() -- Update timestamp for tracking changes
    WHERE product_nk = NEW.product_id; -- Match on natural key

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Updates to Relevant Columns in stg.products
CREATE TRIGGER products_update_trigger
AFTER UPDATE OF 
    product_category_name,
    product_name_length,
    product_description_length,
    product_photos_qty,
    product_weight_g,
    product_length_cm,
    product_height_cm,
    product_width_cm
ON stg.products
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_products();

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 09:58:34,351 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 09:58:34,357 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 09:58:34,357 - DEBUG - Asking scheduler for work...
2024-12-27 09:58:34,358 - DEBUG - Done
2024-12-27 09:58:34,358 - DEBUG - There are no more tasks to run at this time
2024-12-27 09:58:34,358 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 09:58:34,358 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 09:58:34,359 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 09:58:34,359 - INFO - Worker Worker(salt=9557805289, workers=1, host=Nanas.local, username=fajarianatm, pid=32525) was stopped. Shutting down Keep-Alive thread
2024-12-27 09:58:34,359 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 10:08:45,831 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 10:08:46,221 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 10:08:46,257 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 10:08:46,261 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 10:08:46,439 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 10:08:46,911 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 10:08:47,461 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 10:08:47,797 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 10:08:48,188 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 10:08:48,188 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 10:08:48,191 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 10:08:48,199 - INFO - [pid 34559] Worker Worker(salt=3410940079, workers=1, host=Nanas.local, username=fajarianatm, pid=34559) done      Extract()
2024-12-27 10:08:48,199 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 10:08:48,201 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 10:08:48,201 - DEBUG - Asking scheduler for work...
2024-12-27 10:08:48,203 - DEBUG - Pending tasks: 2
2024-12-27 10:08:48,203 - INFO - [pid 34559] Worker Worker(salt=3410940079, workers=1, host=Nanas.local, username=fajarianatm, pid=34559) running   Load()
2024-12-27 10:08:48,205 - INFO - Read Load Query - SUCCESS
2024-12-27 10:08:48,917 - INFO - Read Extracted Data - SUCCESS
2024-12-27 10:08:48,918 - INFO - Connect to DWH - SUCCESS
2024-12-27 10:08:49,025 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 10:08:49,026 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 10:08:50,822 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 10:08:50,863 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 10:08:50,867 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 10:08:51,891 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 10:08:54,729 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 10:08:58,642 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 10:09:00,870 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 10:09:03,129 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 10:09:03,129 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 10:09:09,345 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 10:09:09,354 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 10:09:09,406 - INFO - [pid 34559] Worker Worker(salt=3410940079, workers=1, host=Nanas.local, username=fajarianatm, pid=34559) done      Load()
2024-12-27 10:09:09,407 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 10:09:09,409 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 10:09:09,409 - DEBUG - Asking scheduler for work...
2024-12-27 10:09:09,413 - DEBUG - Pending tasks: 1
2024-12-27 10:09:09,413 - INFO - [pid 34559] Worker Worker(salt=3410940079, workers=1, host=Nanas.local, username=fajarianatm, pid=34559) running   Transform()
2024-12-27 10:09:09,415 - INFO - Read Transform Query - SUCCESS
2024-12-27 10:09:09,416 - INFO - Connect to DWH - SUCCESS
2024-12-27 10:09:09,416 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 10:09:09,784 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-27 10:09:09,795 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-27 10:09:09,795 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 10:09:09,824 - ERROR - Transform Tables - FAILED
2024-12-27 10:09:09,827 - ERROR - [pid 34559] Worker Worker(salt=3410940079, workers=1, host=Nanas.local, username=fajarianatm, pid=34559) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 84: CREATE TRIGGER products_insert_trigger
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 111, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.SyntaxError) syntax error at or near "CREATE"
LINE 84: CREATE TRIGGER products_insert_trigger
         ^

[SQL: -- Step 1: Initial Load od dim_products data
-- This will insert teh data into dim_products for the first time
INSERT INTO final.dim_products (
    product_id,
    product_nk,
    product_category_name,
    product_category_name_english,
    product_name_length,
    product_description_length,
    product_photos_qty,
    product_weight_g,
    product_length_cm,
    product_height_cm,
    product_width_cm,
    created_at,
    updated_at
)

SELECT
    p.id AS product_id,
    p.product_id AS product_nk,
    p.product_category_name,
    pc.product_category_name_english,
    p.product_name_length,
    p.product_description_length,
    p.product_photos_qty,
    p.product_weight_g,
    p.product_length_cm,
    p.product_height_cm,
    p.product_width_cm,
    NOW() AS created_at,
    NOW() AS updated_at
FROM stg.products AS p
JOIN stg.product_category_name_translation AS pc 
    ON p.product_category_name = pc.product_category_name;

-- Verivy the data inserted
SELECT * FROM final.dim_products;

------------------------------------------------------------------------------------------------------------

-- Step 2: Trigger Functions to Insert New Data into dim_products
CREATE OR REPLACE FUNCTION final.insert_dim_products()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert new products data into the dim_products table
    INSERT INTO final.dim_products (
        product_id,
        product_nk,
        product_category_name,
        product_category_name_english,
        product_name_length,
        product_description_length,
        product_photos_qty,
        product_weight_g,
        product_length_cm,
        product_height_cm,
        product_width_cm,
        created_at,
        updated_at
    )
    SELECT
        NEW.id,
        NEW.product_id,
        NEW.product_category_name,
        pc.product_category_name_english,
        NEW.product_name_length,
        NEW.product_description_length,
        NEW.product_photos_qty,
        NEW.product_weight_g,
        NEW.product_length_cm,
        NEW.product_height_cm,
        NEW.product_width_cm,
        NOW(),
        NOW()
    FROM stg.product_category_name_translation AS pc
    WHERE NEW.product_category_name = pc.product_category_name;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql

-- Create a trigger for inserting new rows into dim_sellers
CREATE TRIGGER products_insert_trigger
AFTER INSERT ON stg.products
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_products();

------------------------------------------------------------------------------------------------------------

-- Step 3: SCD Type 1 Update (Insert New Version and Update the updated_at)
CREATE OR REPLACE FUNCTION final.update_dim_products()
RETURNS TRIGGER AS $$
BEGIN
    -- Update dim_products with new values from stg.products
    UPDATE final.dim_products
    SET
        product_category_name = NEW.product_category_name,
        product_category_name_english = (
            SELECT pc.product_category_name_english
            FROM stg.product_category_name_translation AS pc
            WHERE pc.product_category_name = NEW.product_category_name
        ),
        product_name_length = NEW.product_name_length,
        product_description_length = NEW.product_description_length,
        product_photos_qty = NEW.product_photos_qty,
        product_weight_g = NEW.product_weight_g,
        product_length_cm = NEW.product_length_cm,
        product_height_cm = NEW.product_height_cm,
        product_width_cm = NEW.product_width_cm,
        updated_at = NOW() -- Update timestamp for tracking changes
    WHERE product_nk = NEW.product_id; -- Match on natural key

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Updates to Relevant Columns in stg.products
CREATE TRIGGER products_update_trigger
AFTER UPDATE OF 
    product_category_name,
    product_name_length,
    product_description_length,
    product_photos_qty,
    product_weight_g,
    product_length_cm,
    product_height_cm,
    product_width_cm
ON stg.products
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_products();

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 10:09:09,842 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 10:09:09,847 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 10:09:09,848 - DEBUG - Asking scheduler for work...
2024-12-27 10:09:09,849 - DEBUG - Done
2024-12-27 10:09:09,849 - DEBUG - There are no more tasks to run at this time
2024-12-27 10:09:09,849 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 10:09:09,849 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 10:09:09,849 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 10:09:09,849 - INFO - Worker Worker(salt=3410940079, workers=1, host=Nanas.local, username=fajarianatm, pid=34559) was stopped. Shutting down Keep-Alive thread
2024-12-27 10:09:09,850 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 10:10:31,084 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 10:10:31,477 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 10:10:31,515 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 10:10:31,519 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 10:10:31,707 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 10:10:32,185 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 10:10:32,730 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 10:10:33,121 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 10:10:33,516 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 10:10:33,516 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 10:10:33,519 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 10:10:33,526 - INFO - [pid 35342] Worker Worker(salt=7287426341, workers=1, host=Nanas.local, username=fajarianatm, pid=35342) done      Extract()
2024-12-27 10:10:33,526 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 10:10:33,528 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 10:10:33,528 - DEBUG - Asking scheduler for work...
2024-12-27 10:10:33,529 - DEBUG - Pending tasks: 2
2024-12-27 10:10:33,529 - INFO - [pid 35342] Worker Worker(salt=7287426341, workers=1, host=Nanas.local, username=fajarianatm, pid=35342) running   Load()
2024-12-27 10:10:33,532 - INFO - Read Load Query - SUCCESS
2024-12-27 10:10:34,207 - INFO - Read Extracted Data - SUCCESS
2024-12-27 10:10:34,207 - INFO - Connect to DWH - SUCCESS
2024-12-27 10:10:34,302 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 10:10:34,302 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 10:10:36,089 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 10:10:36,133 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 10:10:36,137 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 10:10:37,202 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 10:10:40,127 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 10:10:44,049 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 10:10:46,228 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 10:10:48,537 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 10:10:48,537 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 10:10:54,544 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 10:10:54,549 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 10:10:54,597 - INFO - [pid 35342] Worker Worker(salt=7287426341, workers=1, host=Nanas.local, username=fajarianatm, pid=35342) done      Load()
2024-12-27 10:10:54,598 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 10:10:54,600 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 10:10:54,601 - DEBUG - Asking scheduler for work...
2024-12-27 10:10:54,602 - DEBUG - Pending tasks: 1
2024-12-27 10:10:54,602 - INFO - [pid 35342] Worker Worker(salt=7287426341, workers=1, host=Nanas.local, username=fajarianatm, pid=35342) running   Transform()
2024-12-27 10:10:54,606 - INFO - Read Transform Query - SUCCESS
2024-12-27 10:10:54,606 - INFO - Connect to DWH - SUCCESS
2024-12-27 10:10:54,606 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 10:10:54,947 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-27 10:10:54,957 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-27 10:10:55,078 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-27 10:10:55,086 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 10:10:55,112 - ERROR - Transform Tables - FAILED
2024-12-27 10:10:55,115 - ERROR - [pid 35342] Worker Worker(salt=7287426341, workers=1, host=Nanas.local, username=fajarianatm, pid=35342) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "stg_orders" does not exist
LINE 11:         stg_orders so
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 119, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "stg_orders" does not exist
LINE 11:         stg_orders so
                 ^

[SQL: WITH stg_fct_orders AS (
    SELECT
        so.order_id AS order_nk,
        soi.order_item_id AS order_item_nk,
        fdc.customer_id AS customer_id,
        fds.seller_id AS seller_id,
        fdp.product_id AS product_id,
        soi.price AS price,
        soi.freight_value AS freight_value
    FROM
        stg_orders so

    JOIN stg.order_items soi
        ON soi.order_id = so.order_id

    JOIN final.dim_customers fdc
        ON fdc.customer_nk = so.customer_id

    JOIN final.dim_sellers fds
        ON fds.seller_nk = soi.seller_id

    JOIN final.dim_products fdp
        ON fdp.product_nk = soi.product_id

)

INSERT INTO final.fct_orders (
    order_nk,
    order_item_nk,
    customer_id,
    seller_id,
    product_id,
    price,
    freight_value
)

SELECT *
FROM stg_fct_orders

ON CONFLICT(order_nk, order_item_nk)
DO UPDATE SET
    customer_id = EXCLUDED.customer_id,
    seller_id = EXCLUDED.seller_id,
    product_id = EXCLUDED.product_id,
    price = EXCLUDED.price,
    freight_value = EXCLUDED.freight_value,
    updated_at = CASE
                    WHEN final.fct_orders.customer_id <> EXCLUDED.customer_id
                         OR final.fct_orders.seller_id <> EXCLUDED.seller_id
                         OR final.fct_orders.product_id <> EXCLUDED.product_id
                         OR final.fct_orders.price <> EXCLUDED.price
                         OR final.fct_orders.freight_value <> EXCLUDED.freight_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_orders.updated_at
                 END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 10:10:55,132 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 10:10:55,136 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 10:10:55,136 - DEBUG - Asking scheduler for work...
2024-12-27 10:10:55,137 - DEBUG - Done
2024-12-27 10:10:55,137 - DEBUG - There are no more tasks to run at this time
2024-12-27 10:10:55,137 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 10:10:55,137 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 10:10:55,137 - INFO - Worker Worker(salt=7287426341, workers=1, host=Nanas.local, username=fajarianatm, pid=35342) was stopped. Shutting down Keep-Alive thread
2024-12-27 10:10:55,138 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 10:14:06,331 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 10:14:06,739 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 10:14:06,779 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 10:14:06,784 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 10:14:06,987 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 10:14:07,516 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 10:14:08,191 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 10:14:08,544 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 10:14:09,021 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 10:14:09,021 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 10:14:09,025 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 10:14:09,032 - INFO - [pid 36863] Worker Worker(salt=9786317116, workers=1, host=Nanas.local, username=fajarianatm, pid=36863) done      Extract()
2024-12-27 10:14:09,032 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 10:14:09,035 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 10:14:09,035 - DEBUG - Asking scheduler for work...
2024-12-27 10:14:09,036 - DEBUG - Pending tasks: 2
2024-12-27 10:14:09,036 - INFO - [pid 36863] Worker Worker(salt=9786317116, workers=1, host=Nanas.local, username=fajarianatm, pid=36863) running   Load()
2024-12-27 10:14:09,039 - INFO - Read Load Query - SUCCESS
2024-12-27 10:14:09,727 - INFO - Read Extracted Data - SUCCESS
2024-12-27 10:14:09,728 - INFO - Connect to DWH - SUCCESS
2024-12-27 10:14:09,806 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 10:14:09,806 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 10:14:11,599 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 10:14:11,639 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 10:14:11,642 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 10:14:12,687 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 10:14:15,418 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 10:14:19,313 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 10:14:21,517 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 10:14:23,824 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 10:14:23,824 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 10:14:24,920 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-27 10:14:24,953 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-27 10:14:24,956 - ERROR - [pid 36863] Worker Worker(salt=9786317116, workers=1, host=Nanas.local, username=fajarianatm, pid=36863) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: operator does not exist: character varying <> integer
LINE 8:         customer_zip_code <> NEW.customer_zip_code_prefix
                                  ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
QUERY:  UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code_prefix
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    )
CONTEXT:  PL/pgSQL function final.update_dim_customers() line 4 at SQL statement


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: character varying <> integer
LINE 8:         customer_zip_code <> NEW.customer_zip_code_prefix
                                  ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
QUERY:  UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code_prefix
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    )
CONTEXT:  PL/pgSQL function final.update_dim_customers() line 4 at SQL statement

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-27 10:14:24,977 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 10:14:24,983 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-27 10:14:24,983 - DEBUG - Asking scheduler for work...
2024-12-27 10:14:24,985 - DEBUG - Done
2024-12-27 10:14:24,985 - DEBUG - There are no more tasks to run at this time
2024-12-27 10:14:24,985 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-27 10:14:24,985 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-27 10:14:24,985 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-27 10:14:24,985 - INFO - Worker Worker(salt=9786317116, workers=1, host=Nanas.local, username=fajarianatm, pid=36863) was stopped. Shutting down Keep-Alive thread
2024-12-27 10:14:24,986 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 11:14:17,476 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 11:14:17,880 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 11:14:17,919 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 11:14:17,923 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 11:14:18,108 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 11:14:18,598 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 11:14:19,145 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 11:14:19,490 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 11:14:19,877 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 11:14:19,877 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 11:14:19,880 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 11:14:19,887 - INFO - [pid 45951] Worker Worker(salt=8385692669, workers=1, host=Nanas.local, username=fajarianatm, pid=45951) done      Extract()
2024-12-27 11:14:19,888 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 11:14:19,890 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 11:14:19,890 - DEBUG - Asking scheduler for work...
2024-12-27 11:14:19,891 - DEBUG - Pending tasks: 2
2024-12-27 11:14:19,891 - INFO - [pid 45951] Worker Worker(salt=8385692669, workers=1, host=Nanas.local, username=fajarianatm, pid=45951) running   Load()
2024-12-27 11:14:19,893 - INFO - Read Load Query - SUCCESS
2024-12-27 11:14:20,546 - INFO - Read Extracted Data - SUCCESS
2024-12-27 11:14:20,547 - INFO - Connect to DWH - SUCCESS
2024-12-27 11:14:20,679 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 11:14:20,679 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 11:14:22,584 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 11:14:22,629 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 11:14:22,633 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 11:14:23,658 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 11:14:26,606 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 11:14:30,646 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 11:14:32,974 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 11:14:35,435 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 11:14:35,435 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 11:14:36,671 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-27 11:14:36,715 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-27 11:14:36,719 - ERROR - [pid 45951] Worker Worker(salt=8385692669, workers=1, host=Nanas.local, username=fajarianatm, pid=45951) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: operator does not exist: character varying <> integer
LINE 8:         customer_zip_code <> NEW.customer_zip_code_prefix
                                  ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
QUERY:  UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code_prefix
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    )
CONTEXT:  PL/pgSQL function final.update_dim_customers() line 4 at SQL statement


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: character varying <> integer
LINE 8:         customer_zip_code <> NEW.customer_zip_code_prefix
                                  ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
QUERY:  UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code_prefix
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    )
CONTEXT:  PL/pgSQL function final.update_dim_customers() line 4 at SQL statement

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-27 11:14:36,744 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 11:14:36,750 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-27 11:14:36,750 - DEBUG - Asking scheduler for work...
2024-12-27 11:14:36,751 - DEBUG - Done
2024-12-27 11:14:36,751 - DEBUG - There are no more tasks to run at this time
2024-12-27 11:14:36,751 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-27 11:14:36,751 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-27 11:14:36,751 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-27 11:14:36,751 - INFO - Worker Worker(salt=8385692669, workers=1, host=Nanas.local, username=fajarianatm, pid=45951) was stopped. Shutting down Keep-Alive thread
2024-12-27 11:14:36,752 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 11:16:05,914 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 11:16:06,286 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 11:16:06,323 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 11:16:06,328 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 11:16:06,522 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 11:16:06,994 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 11:16:07,559 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 11:16:07,966 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 11:16:08,370 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 11:16:08,370 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 11:16:08,374 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 11:16:08,381 - INFO - [pid 46764] Worker Worker(salt=9096299189, workers=1, host=Nanas.local, username=fajarianatm, pid=46764) done      Extract()
2024-12-27 11:16:08,382 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 11:16:08,384 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 11:16:08,384 - DEBUG - Asking scheduler for work...
2024-12-27 11:16:08,385 - DEBUG - Pending tasks: 2
2024-12-27 11:16:08,385 - INFO - [pid 46764] Worker Worker(salt=9096299189, workers=1, host=Nanas.local, username=fajarianatm, pid=46764) running   Load()
2024-12-27 11:16:08,387 - INFO - Read Load Query - SUCCESS
2024-12-27 11:16:09,044 - INFO - Read Extracted Data - SUCCESS
2024-12-27 11:16:09,044 - INFO - Connect to DWH - SUCCESS
2024-12-27 11:16:09,166 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 11:16:09,166 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 11:16:10,959 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 11:16:11,002 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 11:16:11,006 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 11:16:12,033 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 11:16:14,762 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 11:16:18,617 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 11:16:20,863 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 11:16:23,239 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 11:16:23,239 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 11:16:24,320 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-27 11:16:24,354 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-27 11:16:24,359 - ERROR - [pid 46764] Worker Worker(salt=9096299189, workers=1, host=Nanas.local, username=fajarianatm, pid=46764) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: operator does not exist: character varying <> integer
LINE 8:         customer_zip_code <> NEW.customer_zip_code_prefix
                                  ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
QUERY:  UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code_prefix
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    )
CONTEXT:  PL/pgSQL function final.update_dim_customers() line 4 at SQL statement


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: character varying <> integer
LINE 8:         customer_zip_code <> NEW.customer_zip_code_prefix
                                  ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
QUERY:  UPDATE final.dim_customers
    SET 
        current_flag = 'expired',  -- Set current_flag to expired for the old record
        expired_at = NOW()         -- Set expired_at to current timestamp
    WHERE customer_id = NEW.id  -- Match based on customer_id
    AND current_flag = 'current'  -- Only expire the current active record
    AND (
        customer_zip_code <> NEW.customer_zip_code_prefix
        OR customer_city <> NEW.customer_city
        OR customer_state <> NEW.customer_state
    )
CONTEXT:  PL/pgSQL function final.update_dim_customers() line 4 at SQL statement

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-27 11:16:24,381 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 11:16:24,389 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-27 11:16:24,390 - DEBUG - Asking scheduler for work...
2024-12-27 11:16:24,392 - DEBUG - Done
2024-12-27 11:16:24,392 - DEBUG - There are no more tasks to run at this time
2024-12-27 11:16:24,392 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-27 11:16:24,392 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-27 11:16:24,393 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-27 11:16:24,393 - INFO - Worker Worker(salt=9096299189, workers=1, host=Nanas.local, username=fajarianatm, pid=46764) was stopped. Shutting down Keep-Alive thread
2024-12-27 11:16:24,393 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 11:36:44,953 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 11:36:45,524 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 11:36:45,566 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 11:36:45,569 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 11:36:45,729 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 11:36:46,241 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 11:36:46,815 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 11:36:47,168 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 11:36:47,574 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 11:36:47,575 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 11:36:47,580 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 11:36:47,587 - INFO - [pid 55609] Worker Worker(salt=2158682784, workers=1, host=Nanas.local, username=fajarianatm, pid=55609) done      Extract()
2024-12-27 11:36:47,588 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 11:36:47,590 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 11:36:47,590 - DEBUG - Asking scheduler for work...
2024-12-27 11:36:47,591 - DEBUG - Pending tasks: 2
2024-12-27 11:36:47,591 - INFO - [pid 55609] Worker Worker(salt=2158682784, workers=1, host=Nanas.local, username=fajarianatm, pid=55609) running   Load()
2024-12-27 11:36:47,594 - INFO - Read Load Query - SUCCESS
2024-12-27 11:36:48,475 - INFO - Read Extracted Data - SUCCESS
2024-12-27 11:36:48,479 - INFO - Connect to DWH - SUCCESS
2024-12-27 11:36:48,541 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 11:36:48,541 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 11:36:50,358 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 11:36:50,418 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 11:36:50,422 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 11:36:51,524 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 11:36:54,286 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 11:36:58,211 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 11:37:00,393 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 11:37:02,700 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 11:37:02,700 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 11:37:10,442 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 11:37:10,468 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 11:37:10,522 - INFO - [pid 55609] Worker Worker(salt=2158682784, workers=1, host=Nanas.local, username=fajarianatm, pid=55609) done      Load()
2024-12-27 11:37:10,523 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 11:37:10,525 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 11:37:10,526 - DEBUG - Asking scheduler for work...
2024-12-27 11:37:10,527 - DEBUG - Pending tasks: 1
2024-12-27 11:37:10,527 - INFO - [pid 55609] Worker Worker(salt=2158682784, workers=1, host=Nanas.local, username=fajarianatm, pid=55609) running   Transform()
2024-12-27 11:37:10,529 - INFO - Read Transform Query - SUCCESS
2024-12-27 11:37:10,530 - INFO - Connect to DWH - SUCCESS
2024-12-27 11:37:10,530 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 11:37:10,979 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-27 11:37:10,989 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-27 11:37:11,115 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-27 11:37:11,120 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 11:37:11,157 - ERROR - Transform Tables - FAILED
2024-12-27 11:37:11,159 - ERROR - [pid 55609] Worker Worker(salt=2158682784, workers=1, host=Nanas.local, username=fajarianatm, pid=55609) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InvalidColumnReference: there is no unique or exclusion constraint matching the ON CONFLICT specification


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 119, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.InvalidColumnReference) there is no unique or exclusion constraint matching the ON CONFLICT specification

[SQL: WITH stg_fct_orders AS (
    SELECT
        so.order_id AS order_nk,
        soi.order_item_id AS order_item_nk,
        fdc.customer_id AS customer_id,
        fds.seller_id AS seller_id,
        fdp.product_id AS product_id,
        soi.price AS price,
        soi.freight_value AS freight_value
    FROM
        stg.orders so

    JOIN stg.order_items soi
        ON soi.order_id = so.order_id

    JOIN final.dim_customers fdc
        ON fdc.customer_nk = so.customer_id

    JOIN final.dim_sellers fds
        ON fds.seller_nk = soi.seller_id

    JOIN final.dim_products fdp
        ON fdp.product_nk = soi.product_id

)

INSERT INTO final.fct_orders (
    order_nk,
    order_item_nk,
    customer_id,
    seller_id,
    product_id,
    price,
    freight_value
)

SELECT *
FROM stg_fct_orders

ON CONFLICT(order_nk, order_item_nk)
DO UPDATE SET
    customer_id = EXCLUDED.customer_id,
    seller_id = EXCLUDED.seller_id,
    product_id = EXCLUDED.product_id,
    price = EXCLUDED.price,
    freight_value = EXCLUDED.freight_value,
    updated_at = CASE
                    WHEN final.fct_orders.customer_id <> EXCLUDED.customer_id
                         OR final.fct_orders.seller_id <> EXCLUDED.seller_id
                         OR final.fct_orders.product_id <> EXCLUDED.product_id
                         OR final.fct_orders.price <> EXCLUDED.price
                         OR final.fct_orders.freight_value <> EXCLUDED.freight_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_orders.updated_at
                 END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 11:37:11,177 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 11:37:11,181 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 11:37:11,182 - DEBUG - Asking scheduler for work...
2024-12-27 11:37:11,183 - DEBUG - Done
2024-12-27 11:37:11,183 - DEBUG - There are no more tasks to run at this time
2024-12-27 11:37:11,183 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 11:37:11,183 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 11:37:11,183 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 11:37:11,183 - INFO - Worker Worker(salt=2158682784, workers=1, host=Nanas.local, username=fajarianatm, pid=55609) was stopped. Shutting down Keep-Alive thread
2024-12-27 11:37:11,184 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 13:20:43,501 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 13:20:44,041 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 13:20:44,083 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 13:20:44,086 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 13:20:44,259 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 13:20:44,754 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 13:20:45,322 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 13:20:45,671 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 13:20:46,089 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 13:20:46,089 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 13:20:46,093 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 13:20:46,100 - INFO - [pid 68761] Worker Worker(salt=4928361181, workers=1, host=Nanas.local, username=fajarianatm, pid=68761) done      Extract()
2024-12-27 13:20:46,100 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 13:20:46,103 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 13:20:46,103 - DEBUG - Asking scheduler for work...
2024-12-27 13:20:46,104 - DEBUG - Pending tasks: 2
2024-12-27 13:20:46,104 - INFO - [pid 68761] Worker Worker(salt=4928361181, workers=1, host=Nanas.local, username=fajarianatm, pid=68761) running   Load()
2024-12-27 13:20:46,106 - INFO - Read Load Query - SUCCESS
2024-12-27 13:20:46,790 - INFO - Read Extracted Data - SUCCESS
2024-12-27 13:20:46,791 - INFO - Connect to DWH - SUCCESS
2024-12-27 13:20:46,871 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 13:20:46,871 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 13:20:48,685 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 13:20:48,783 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 13:20:48,786 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 13:20:49,839 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 13:20:52,768 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 13:20:56,940 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 13:20:59,313 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 13:21:01,748 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 13:21:01,748 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 13:21:08,624 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 13:21:08,638 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 13:21:08,696 - INFO - [pid 68761] Worker Worker(salt=4928361181, workers=1, host=Nanas.local, username=fajarianatm, pid=68761) done      Load()
2024-12-27 13:21:08,697 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 13:21:08,700 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 13:21:08,701 - DEBUG - Asking scheduler for work...
2024-12-27 13:21:08,702 - DEBUG - Pending tasks: 1
2024-12-27 13:21:08,702 - INFO - [pid 68761] Worker Worker(salt=4928361181, workers=1, host=Nanas.local, username=fajarianatm, pid=68761) running   Transform()
2024-12-27 13:21:08,704 - INFO - Read Transform Query - SUCCESS
2024-12-27 13:21:08,705 - INFO - Connect to DWH - SUCCESS
2024-12-27 13:21:08,706 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 13:21:09,132 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-27 13:21:09,144 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-27 13:21:09,272 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-27 13:21:09,469 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-27 13:21:09,472 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 13:21:09,517 - ERROR - Transform Tables - FAILED
2024-12-27 13:21:09,521 - ERROR - [pid 68761] Worker Worker(salt=4928361181, workers=1, host=Nanas.local, username=fajarianatm, pid=68761) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column excluded.sentimen does not exist
LINE 65: ...                OR final.fct_reviews.sentiment <> EXCLUDED.s...
                                                              ^
HINT:  Perhaps you meant to reference the column "excluded.sentiment".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 124, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column excluded.sentimen does not exist
LINE 65: ...                OR final.fct_reviews.sentiment <> EXCLUDED.s...
                                                              ^
HINT:  Perhaps you meant to reference the column "excluded.sentiment".

[SQL:  WITH stg_fct_reviews AS (
    SELECT 
        sor.review_id AS review_nk,
        sor.order_id AS order_nk,
        fdc.customer_id AS customer_id,
        CASE
            WHEN sor.review_score BETWEEN 1 AND 2 THEN 'negative'
            WHEN sor.review_score = 3 THEN 'netral'
            WHEN sor.review_score BETWEEN 4 AND 5 THEN 'positive'
            ELSE 'unknown'
        END AS sentiment,
        sop.payment_sequential AS payment_sequential,
        sop.payment_type AS payment_type,
        sop.payment_installments AS payment_installments,
        sop.payment_value AS payment_value,
        sor.review_score AS review_score,
        sor.review_comment_title AS review_comment_title,
        sor.review_comment_message AS review_comment_message,
        sor.review_creation_date AS review_creation_date
    FROM stg.order_reviews sor

    JOIN stg.orders so
        ON so.order_id = sor.order_id

    JOIN stg.order_payments sop
        ON sop.order_id = so.order_id

    JOIN final.dim_customers fdc
        ON fdc.customer_nk = so.customer_id
    
)

INSERT INTO final.fct_reviews (
    review_nk,
    order_nk,
    customer_id,
    sentiment,
    payment_sequential,
    payment_type,
    payment_installments,
    payment_value,
    review_score,
    review_comment_title,
    review_comment_message,
    review_creation_date
)

SELECT *
FROM stg_fct_reviews

ON CONFLICT(review_nk, order_nk)
DO UPDATE SET
    customer_id = EXCLUDED.customer_id,
    sentiment = EXCLUDED.sentiment,
    payment_sequential = EXCLUDED.payment_sequential,
    payment_type = EXCLUDED.payment_type,
    payment_installments = EXCLUDED.payment_installments,
    payment_value = EXCLUDED.payment_value,
    review_score = EXCLUDED.review_score,
    review_comment_title = EXCLUDED.review_comment_title,
    review_comment_message = EXCLUDED.review_comment_message,
    review_creation_date = EXCLUDED.review_creation_date,
    updated_at = CASE 
                    WHEN final.fct_reviews.customer_id <> EXCLUDED.customer_id
                        OR final.fct_reviews.sentiment <> EXCLUDED.sentimen
                        OR final.fct_reviews.payment_sequential <> EXCLUDED.payment_sequential
                        OR final.fct_reviews.payment_type <> EXCLUDED.payment_type
                        OR final.fct_reviews.payment_installments <> EXCLUDED.payment_installments
                        OR final.fct_reviews.payment_value <> EXCLUDED.payment_value
                        OR final.fct_reviews.review_score <> EXCLUDED.review_score
                        OR final.fct_reviews.review_comment_title <> EXCLUDED.review_comment_title
                        OR final.fct_reviews.review_comment_message <> EXCLUDED.review_comment_message
                        OR final.fct_reviews.review_creation_date <> EXCLUDED.review_creation_date
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_orders.updated_at
                 END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 13:21:09,542 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 13:21:09,549 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 13:21:09,549 - DEBUG - Asking scheduler for work...
2024-12-27 13:21:09,551 - DEBUG - Done
2024-12-27 13:21:09,551 - DEBUG - There are no more tasks to run at this time
2024-12-27 13:21:09,551 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 13:21:09,551 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 13:21:09,551 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 13:21:09,551 - INFO - Worker Worker(salt=4928361181, workers=1, host=Nanas.local, username=fajarianatm, pid=68761) was stopped. Shutting down Keep-Alive thread
2024-12-27 13:21:09,551 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 13:22:36,433 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 13:22:36,806 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 13:22:36,846 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 13:22:36,850 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 13:22:37,028 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 13:22:37,507 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 13:22:38,077 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 13:22:38,420 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 13:22:38,817 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 13:22:38,817 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 13:22:38,822 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 13:22:38,829 - INFO - [pid 69602] Worker Worker(salt=698162828, workers=1, host=Nanas.local, username=fajarianatm, pid=69602) done      Extract()
2024-12-27 13:22:38,830 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 13:22:38,832 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 13:22:38,832 - DEBUG - Asking scheduler for work...
2024-12-27 13:22:38,833 - DEBUG - Pending tasks: 2
2024-12-27 13:22:38,833 - INFO - [pid 69602] Worker Worker(salt=698162828, workers=1, host=Nanas.local, username=fajarianatm, pid=69602) running   Load()
2024-12-27 13:22:38,836 - INFO - Read Load Query - SUCCESS
2024-12-27 13:22:39,516 - INFO - Read Extracted Data - SUCCESS
2024-12-27 13:22:39,517 - INFO - Connect to DWH - SUCCESS
2024-12-27 13:22:39,615 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 13:22:39,615 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 13:22:41,429 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 13:22:41,469 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 13:22:41,472 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 13:22:42,511 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 13:22:45,335 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 13:22:49,333 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 13:22:51,617 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 13:22:54,052 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 13:22:54,052 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 13:22:55,248 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-27 13:22:55,285 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-27 13:22:55,288 - ERROR - [pid 69602] Worker Worker(salt=698162828, workers=1, host=Nanas.local, username=fajarianatm, pid=69602) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id)=(0a7d09c9-87b4-439f-a1f6-aaec21ce4dc6) already exists.
CONTEXT:  SQL statement "INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark the new version as current
        NOW()  -- Set the created timestamp for the new version
    )"
PL/pgSQL function final.update_dim_customers() line 17 at SQL statement


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id)=(0a7d09c9-87b4-439f-a1f6-aaec21ce4dc6) already exists.
CONTEXT:  SQL statement "INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark the new version as current
        NOW()  -- Set the created timestamp for the new version
    )"
PL/pgSQL function final.update_dim_customers() line 17 at SQL statement

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-27 13:22:55,310 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 13:22:55,315 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-27 13:22:55,315 - DEBUG - Asking scheduler for work...
2024-12-27 13:22:55,317 - DEBUG - Done
2024-12-27 13:22:55,317 - DEBUG - There are no more tasks to run at this time
2024-12-27 13:22:55,317 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-27 13:22:55,317 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-27 13:22:55,317 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-27 13:22:55,317 - INFO - Worker Worker(salt=698162828, workers=1, host=Nanas.local, username=fajarianatm, pid=69602) was stopped. Shutting down Keep-Alive thread
2024-12-27 13:22:55,318 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 13:44:53,065 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 13:44:53,477 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 13:44:53,513 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 13:44:53,516 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 13:44:53,706 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 13:44:54,174 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 13:44:54,716 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 13:44:55,054 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 13:44:55,446 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 13:44:55,446 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 13:44:55,449 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 13:44:55,457 - INFO - [pid 77222] Worker Worker(salt=090280595, workers=1, host=Nanas.local, username=fajarianatm, pid=77222) done      Extract()
2024-12-27 13:44:55,457 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 13:44:55,459 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 13:44:55,459 - DEBUG - Asking scheduler for work...
2024-12-27 13:44:55,460 - DEBUG - Pending tasks: 2
2024-12-27 13:44:55,460 - INFO - [pid 77222] Worker Worker(salt=090280595, workers=1, host=Nanas.local, username=fajarianatm, pid=77222) running   Load()
2024-12-27 13:44:55,462 - INFO - Read Load Query - SUCCESS
2024-12-27 13:44:56,140 - INFO - Read Extracted Data - SUCCESS
2024-12-27 13:44:56,140 - INFO - Connect to DWH - SUCCESS
2024-12-27 13:44:56,285 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 13:44:56,285 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 13:44:58,090 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 13:44:58,130 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 13:44:58,133 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 13:44:59,187 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 13:45:02,193 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 13:45:06,824 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 13:45:09,505 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 13:45:11,843 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 13:45:11,843 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 13:45:13,032 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-27 13:45:13,083 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-27 13:45:13,087 - ERROR - [pid 77222] Worker Worker(salt=090280595, workers=1, host=Nanas.local, username=fajarianatm, pid=77222) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id)=(0a7d09c9-87b4-439f-a1f6-aaec21ce4dc6) already exists.
CONTEXT:  SQL statement "INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark the new version as current
        NOW()  -- Set the created timestamp for the new version
    )"
PL/pgSQL function final.update_dim_customers() line 17 at SQL statement


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id)=(0a7d09c9-87b4-439f-a1f6-aaec21ce4dc6) already exists.
CONTEXT:  SQL statement "INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current',  -- Mark the new version as current
        NOW()  -- Set the created timestamp for the new version
    )"
PL/pgSQL function final.update_dim_customers() line 17 at SQL statement

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-27 13:45:13,108 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 13:45:13,114 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-27 13:45:13,114 - DEBUG - Asking scheduler for work...
2024-12-27 13:45:13,116 - DEBUG - Done
2024-12-27 13:45:13,116 - DEBUG - There are no more tasks to run at this time
2024-12-27 13:45:13,116 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-27 13:45:13,116 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-27 13:45:13,116 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-27 13:45:13,116 - INFO - Worker Worker(salt=090280595, workers=1, host=Nanas.local, username=fajarianatm, pid=77222) was stopped. Shutting down Keep-Alive thread
2024-12-27 13:45:13,116 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 14:42:19,184 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 14:42:19,793 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 14:42:19,837 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 14:42:19,840 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 14:42:20,018 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 14:42:20,514 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 14:42:21,076 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 14:42:21,420 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 14:42:21,822 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 14:42:21,822 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 14:42:21,830 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 14:42:21,837 - INFO - [pid 894] Worker Worker(salt=3232860460, workers=1, host=Nanas.local, username=fajarianatm, pid=894) done      Extract()
2024-12-27 14:42:21,838 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 14:42:21,840 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 14:42:21,840 - DEBUG - Asking scheduler for work...
2024-12-27 14:42:21,841 - DEBUG - Pending tasks: 2
2024-12-27 14:42:21,841 - INFO - [pid 894] Worker Worker(salt=3232860460, workers=1, host=Nanas.local, username=fajarianatm, pid=894) running   Load()
2024-12-27 14:42:21,843 - INFO - Read Load Query - SUCCESS
2024-12-27 14:42:22,490 - INFO - Read Extracted Data - SUCCESS
2024-12-27 14:42:22,490 - INFO - Connect to DWH - SUCCESS
2024-12-27 14:42:22,573 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 14:42:22,573 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 14:42:24,340 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 14:42:24,401 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 14:42:24,405 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 14:42:25,441 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 14:42:28,189 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 14:42:32,084 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 14:42:34,307 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 14:42:36,618 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 14:42:36,619 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 14:42:43,226 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 14:42:43,257 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 14:42:43,313 - INFO - [pid 894] Worker Worker(salt=3232860460, workers=1, host=Nanas.local, username=fajarianatm, pid=894) done      Load()
2024-12-27 14:42:43,314 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 14:42:43,317 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 14:42:43,317 - DEBUG - Asking scheduler for work...
2024-12-27 14:42:43,319 - DEBUG - Pending tasks: 1
2024-12-27 14:42:43,319 - INFO - [pid 894] Worker Worker(salt=3232860460, workers=1, host=Nanas.local, username=fajarianatm, pid=894) running   Transform()
2024-12-27 14:42:43,320 - INFO - Read Transform Query - SUCCESS
2024-12-27 14:42:43,321 - INFO - Connect to DWH - SUCCESS
2024-12-27 14:42:43,321 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 14:42:43,345 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 14:42:43,379 - ERROR - Transform Tables - FAILED
2024-12-27 14:42:43,381 - ERROR - [pid 894] Worker Worker(salt=3232860460, workers=1, host=Nanas.local, username=fajarianatm, pid=894) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "expired_at" of relation "dim_customers" violates not-null constraint
DETAIL:  Failing row contains (c053cd77-8b08-4cf9-84ee-6b184358e250, 06b8999e2fba1a1fbc88172c00ba8bc7, 14409, franca, SP, 2024-12-27 07:42:43.34369, null, current).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "expired_at" of relation "dim_customers" violates not-null constraint
DETAIL:  Failing row contains (c053cd77-8b08-4cf9-84ee-6b184358e250, 06b8999e2fba1a1fbc88172c00ba8bc7, 14409, franca, SP, 2024-12-27 07:42:43.34369, null, current).

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code_prefix AS customer_zip_code,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,  
    NULL AS expired_at    
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert new customers data into dim_customers if not exists
    IF NOT EXISTS (
        SELECT 1 
        FROM final.dim_customers 
        WHERE customer_id = NEW.id
        AND expired_at IS NULL  -- Only check active records
    ) THEN
        INSERT INTO final.dim_customers (
            customer_id,
            customer_nk,
            customer_zip_code,
            customer_city,
            customer_state,
            current_flag,
            created_at,
            expired_at  -- Ensure expired_at is NULL for new records
        )
        VALUES (
            NEW.id,
            NEW.customer_id,
            NEW.customer_zip_code_prefix,
            NEW.customer_city,
            NEW.customer_state,
            'current',  -- Mark as current when new data is inserted
            NOW(),  -- Set the created timestamp
            NULL  -- Set expired_at to NULL for active records
        );
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create a trigger for inserting new rows into dim_customers
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();

-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Check if an update is needed
    IF (
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code_prefix OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    ) THEN
        -- Mark the old record as expired
        UPDATE final.dim_customers
        SET 
            current_flag = 'expired',  -- Set current_flag to expired for the old record
            expired_at = NOW()         -- Set expired_at to current timestamp for the old record
        WHERE customer_id = OLD.id  -- Match based on customer_id
        AND expired_at IS NULL;  -- Only expire the current active record

        -- Insert a new version of the customer with updated details
        INSERT INTO final.dim_customers (
            customer_id,
            customer_nk,
            customer_zip_code,
            customer_city,
            customer_state,
            current_flag,
            created_at,
            expired_at  -- Set expired_at to NULL for the new active record
        )
        SELECT
            NEW.id,
            NEW.customer_id,
            NEW.customer_zip_code_prefix,
            NEW.customer_city,
            NEW.customer_state,
            'current',  -- Mark the new version as current
            NOW(),  -- Set the created timestamp for the new version
            NULL;  -- Set expired_at to NULL for the new active record
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Update to Existing Data (SCD Type 2)
CREATE TRIGGER customer_update_trigger
AFTER UPDATE OF customer_zip_code_prefix, customer_city, customer_state
ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();

]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 14:42:43,398 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 14:42:43,408 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 14:42:43,409 - DEBUG - Asking scheduler for work...
2024-12-27 14:42:43,412 - DEBUG - Done
2024-12-27 14:42:43,412 - DEBUG - There are no more tasks to run at this time
2024-12-27 14:42:43,412 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 14:42:43,412 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 14:42:43,412 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 14:42:43,412 - INFO - Worker Worker(salt=3232860460, workers=1, host=Nanas.local, username=fajarianatm, pid=894) was stopped. Shutting down Keep-Alive thread
2024-12-27 14:42:43,413 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 22:09:41,114 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 22:09:41,646 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 22:09:41,688 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 22:09:41,692 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 22:09:41,865 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 22:09:42,378 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 22:09:42,959 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 22:09:43,314 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 22:09:43,717 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 22:09:43,717 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 22:09:43,720 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 22:09:43,728 - INFO - [pid 53240] Worker Worker(salt=6042541230, workers=1, host=192.168.0.102, username=fajarianatm, pid=53240) done      Extract()
2024-12-27 22:09:43,729 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 22:09:43,731 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 22:09:43,731 - DEBUG - Asking scheduler for work...
2024-12-27 22:09:43,732 - DEBUG - Pending tasks: 2
2024-12-27 22:09:43,733 - INFO - [pid 53240] Worker Worker(salt=6042541230, workers=1, host=192.168.0.102, username=fajarianatm, pid=53240) running   Load()
2024-12-27 22:09:43,735 - INFO - Read Load Query - SUCCESS
2024-12-27 22:09:44,398 - INFO - Read Extracted Data - SUCCESS
2024-12-27 22:09:44,398 - INFO - Connect to DWH - SUCCESS
2024-12-27 22:09:44,477 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 22:09:44,477 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 22:09:46,409 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 22:09:46,511 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 22:09:46,514 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 22:09:47,580 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 22:09:50,817 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 22:09:55,269 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 22:09:57,771 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 22:10:00,525 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 22:10:00,525 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 22:10:08,190 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 22:10:08,207 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 22:10:08,256 - INFO - [pid 53240] Worker Worker(salt=6042541230, workers=1, host=192.168.0.102, username=fajarianatm, pid=53240) done      Load()
2024-12-27 22:10:08,257 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 22:10:08,261 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 22:10:08,262 - DEBUG - Asking scheduler for work...
2024-12-27 22:10:08,263 - DEBUG - Pending tasks: 1
2024-12-27 22:10:08,264 - INFO - [pid 53240] Worker Worker(salt=6042541230, workers=1, host=192.168.0.102, username=fajarianatm, pid=53240) running   Transform()
2024-12-27 22:10:08,265 - INFO - Read Transform Query - SUCCESS
2024-12-27 22:10:08,266 - INFO - Connect to DWH - SUCCESS
2024-12-27 22:10:08,266 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 22:10:08,293 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 22:10:08,324 - ERROR - Transform Tables - FAILED
2024-12-27 22:10:08,326 - ERROR - [pid 53240] Worker Worker(salt=6042541230, workers=1, host=192.168.0.102, username=fajarianatm, pid=53240) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "expired_at" of relation "dim_customers" violates not-null constraint
DETAIL:  Failing row contains (634252ca-3eda-469e-8b55-20c36c1e238a, 06b8999e2fba1a1fbc88172c00ba8bc7, 14409, franca, SP, 2024-12-27 15:10:08.291071, null, current).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "expired_at" of relation "dim_customers" violates not-null constraint
DETAIL:  Failing row contains (634252ca-3eda-469e-8b55-20c36c1e238a, 06b8999e2fba1a1fbc88172c00ba8bc7, 14409, franca, SP, 2024-12-27 15:10:08.291071, null, current).

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code_prefix AS customer_zip_code,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,  
    NULL AS expired_at    
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Periksa apakah customer_nk sudah ada sebagai data aktif
    IF NOT EXISTS (
        SELECT 1
        FROM final.dim_customers
        WHERE customer_nk = NEW.customer_id
          AND current_flag = 'current'
    ) THEN
        -- Jika customer_nk belum ada, lakukan insert
        INSERT INTO final.dim_customers (
            customer_id,
            customer_nk,
            customer_zip_code,
            customer_city,
            customer_state,
            current_flag,
            created_at,
            expired_at
        )
        VALUES (
            NEW.id,
            NEW.customer_id,
            NEW.customer_zip_code_prefix,
            NEW.customer_city,
            NEW.customer_state,
            'current', -- Tandai sebagai data aktif
            NOW(),
            NULL -- Data baru tidak memiliki expired_at
        );
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Memeriksa perubahan pada kolom yang relevan (misalnya, customer_zip_code_prefix, customer_city, customer_state)
    IF (
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    ) THEN
        -- Tandai record lama sebagai expired
        UPDATE final.dim_customers
        SET 
            current_flag = 'expired', -- Menandai status sebagai expired
            expired_at = NOW() -- Memberikan timestamp pada expired_at
        WHERE customer_id = OLD.customer_id
        AND expired_at IS NULL; -- Hanya expire yang aktif (expired_at IS NULL)

        -- Menyisipkan versi baru dari customer dengan data yang telah diperbarui
        INSERT INTO final.dim_customers (
            customer_id,
            customer_nk,
            customer_zip_code,
            customer_city,
            customer_state,
            current_flag,
            created_at,
            expired_at
        )
        VALUES (
            NEW.id, -- Menggunakan ID dari staging (stg.customers)
            NEW.customer_id, -- customer_id dari staging sebagai customer_nk di final
            NEW.customer_zip_code_prefix, -- customer_zip_code_prefix dari staging
            NEW.customer_city, -- customer_city dari staging
            NEW.customer_state, -- customer_state dari staging
            'current', -- Tandai record ini sebagai current
            NOW(), -- Tanggal dan waktu pembuatan
            NULL -- expired_at untuk data aktif adalah NULL
        );
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger untuk menangani update pada data yang ada
CREATE TRIGGER customer_update_trigger
AFTER UPDATE OF customer_zip_code_prefix, customer_city, customer_state
ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();


]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 22:10:08,343 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 22:10:08,348 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 22:10:08,348 - DEBUG - Asking scheduler for work...
2024-12-27 22:10:08,349 - DEBUG - Done
2024-12-27 22:10:08,349 - DEBUG - There are no more tasks to run at this time
2024-12-27 22:10:08,349 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 22:10:08,349 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 22:10:08,349 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 22:10:08,349 - INFO - Worker Worker(salt=6042541230, workers=1, host=192.168.0.102, username=fajarianatm, pid=53240) was stopped. Shutting down Keep-Alive thread
2024-12-27 22:10:08,350 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 22:41:12,686 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 22:41:13,259 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 22:41:13,303 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 22:41:13,308 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 22:41:13,493 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 22:41:13,994 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 22:41:14,542 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 22:41:14,946 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 22:41:15,357 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 22:41:15,358 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 22:41:15,362 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 22:41:15,369 - INFO - [pid 66474] Worker Worker(salt=6903367155, workers=1, host=192.168.0.102, username=fajarianatm, pid=66474) done      Extract()
2024-12-27 22:41:15,369 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 22:41:15,372 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 22:41:15,372 - DEBUG - Asking scheduler for work...
2024-12-27 22:41:15,373 - DEBUG - Pending tasks: 2
2024-12-27 22:41:15,373 - INFO - [pid 66474] Worker Worker(salt=6903367155, workers=1, host=192.168.0.102, username=fajarianatm, pid=66474) running   Load()
2024-12-27 22:41:15,375 - INFO - Read Load Query - SUCCESS
2024-12-27 22:41:16,093 - INFO - Read Extracted Data - SUCCESS
2024-12-27 22:41:16,094 - INFO - Connect to DWH - SUCCESS
2024-12-27 22:41:16,177 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 22:41:16,177 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 22:41:18,063 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 22:41:18,141 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 22:41:18,145 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 22:41:19,194 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 22:41:22,209 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 22:41:26,055 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 22:41:28,253 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 22:41:30,675 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 22:41:30,676 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 22:41:37,476 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-27 22:41:37,487 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-27 22:41:37,544 - INFO - [pid 66474] Worker Worker(salt=6903367155, workers=1, host=192.168.0.102, username=fajarianatm, pid=66474) done      Load()
2024-12-27 22:41:37,545 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 22:41:37,549 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-27 22:41:37,549 - DEBUG - Asking scheduler for work...
2024-12-27 22:41:37,551 - DEBUG - Pending tasks: 1
2024-12-27 22:41:37,551 - INFO - [pid 66474] Worker Worker(salt=6903367155, workers=1, host=192.168.0.102, username=fajarianatm, pid=66474) running   Transform()
2024-12-27 22:41:37,553 - INFO - Read Transform Query - SUCCESS
2024-12-27 22:41:37,553 - INFO - Connect to DWH - SUCCESS
2024-12-27 22:41:37,554 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-27 22:41:38,024 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-27 22:41:38,035 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-27 22:41:38,148 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-27 22:41:38,425 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-27 22:41:38,428 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-27 22:41:38,469 - ERROR - Transform Tables - FAILED
2024-12-27 22:41:38,472 - ERROR - [pid 66474] Worker Worker(salt=6903367155, workers=1, host=192.168.0.102, username=fajarianatm, pid=66474) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: missing FROM-clause entry for table "fct_orders"
LINE 75:                     ELSE final.fct_orders.updated_at
                                  ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 124, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) missing FROM-clause entry for table "fct_orders"
LINE 75:                     ELSE final.fct_orders.updated_at
                                  ^

[SQL:  WITH stg_fct_reviews AS (
    SELECT 
        sor.review_id AS review_nk,
        sor.order_id AS order_nk,
        fdc.customer_id AS customer_id,
        CASE
            WHEN sor.review_score BETWEEN 1 AND 2 THEN 'negative'
            WHEN sor.review_score = 3 THEN 'netral'
            WHEN sor.review_score BETWEEN 4 AND 5 THEN 'positive'
            ELSE 'unknown'
        END AS sentiment,
        sop.payment_sequential AS payment_sequential,
        sop.payment_type AS payment_type,
        sop.payment_installments AS payment_installments,
        sop.payment_value AS payment_value,
        sor.review_score AS review_score,
        sor.review_comment_title AS review_comment_title,
        sor.review_comment_message AS review_comment_message,
        sor.review_creation_date AS review_creation_date
    FROM stg.order_reviews sor

    JOIN stg.orders so
        ON so.order_id = sor.order_id

    JOIN stg.order_payments sop
        ON sop.order_id = so.order_id

    JOIN final.dim_customers fdc
        ON fdc.customer_nk = so.customer_id
    
)

INSERT INTO final.fct_reviews (
    review_nk,
    order_nk,
    customer_id,
    sentiment,
    payment_sequential,
    payment_type,
    payment_installments,
    payment_value,
    review_score,
    review_comment_title,
    review_comment_message,
    review_creation_date
)

SELECT *
FROM stg_fct_reviews

ON CONFLICT(review_nk, order_nk)
DO UPDATE SET
    customer_id = EXCLUDED.customer_id,
    sentiment = EXCLUDED.sentiment,
    payment_sequential = EXCLUDED.payment_sequential,
    payment_type = EXCLUDED.payment_type,
    payment_installments = EXCLUDED.payment_installments,
    payment_value = EXCLUDED.payment_value,
    review_score = EXCLUDED.review_score,
    review_comment_title = EXCLUDED.review_comment_title,
    review_comment_message = EXCLUDED.review_comment_message,
    review_creation_date = EXCLUDED.review_creation_date,
    updated_at = CASE 
                    WHEN final.fct_reviews.customer_id <> EXCLUDED.customer_id
                        OR final.fct_reviews.sentiment <> EXCLUDED.sentiment
                        OR final.fct_reviews.payment_sequential <> EXCLUDED.payment_sequential
                        OR final.fct_reviews.payment_type <> EXCLUDED.payment_type
                        OR final.fct_reviews.payment_installments <> EXCLUDED.payment_installments
                        OR final.fct_reviews.payment_value <> EXCLUDED.payment_value
                        OR final.fct_reviews.review_score <> EXCLUDED.review_score
                        OR final.fct_reviews.review_comment_title <> EXCLUDED.review_comment_title
                        OR final.fct_reviews.review_comment_message <> EXCLUDED.review_comment_message
                        OR final.fct_reviews.review_creation_date <> EXCLUDED.review_creation_date
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_orders.updated_at
                 END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-27 22:41:38,493 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 22:41:38,501 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-27 22:41:38,502 - DEBUG - Asking scheduler for work...
2024-12-27 22:41:38,503 - DEBUG - Done
2024-12-27 22:41:38,503 - DEBUG - There are no more tasks to run at this time
2024-12-27 22:41:38,503 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-27 22:41:38,503 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-27 22:41:38,503 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-27 22:41:38,503 - INFO - Worker Worker(salt=6903367155, workers=1, host=192.168.0.102, username=fajarianatm, pid=66474) was stopped. Shutting down Keep-Alive thread
2024-12-27 22:41:38,504 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 22:48:40,529 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 22:48:41,105 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 22:48:41,144 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 22:48:41,149 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 22:48:41,327 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 22:48:41,884 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 22:48:42,441 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 22:48:42,813 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 22:48:43,254 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 22:48:43,254 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 22:48:43,257 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 22:48:43,265 - INFO - [pid 69649] Worker Worker(salt=8053917368, workers=1, host=192.168.0.102, username=fajarianatm, pid=69649) done      Extract()
2024-12-27 22:48:43,265 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 22:48:43,267 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 22:48:43,268 - DEBUG - Asking scheduler for work...
2024-12-27 22:48:43,269 - DEBUG - Pending tasks: 2
2024-12-27 22:48:43,269 - INFO - [pid 69649] Worker Worker(salt=8053917368, workers=1, host=192.168.0.102, username=fajarianatm, pid=69649) running   Load()
2024-12-27 22:48:43,271 - INFO - Read Load Query - SUCCESS
2024-12-27 22:48:43,997 - INFO - Read Extracted Data - SUCCESS
2024-12-27 22:48:43,998 - INFO - Connect to DWH - SUCCESS
2024-12-27 22:48:44,103 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 22:48:44,103 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 22:48:46,009 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 22:48:46,052 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 22:48:46,055 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 22:48:47,133 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 22:48:50,011 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 22:48:54,242 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 22:48:56,748 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 22:48:59,123 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 22:48:59,123 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 22:49:00,286 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-27 22:49:00,318 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-27 22:49:00,321 - ERROR - [pid 69649] Worker Worker(salt=8053917368, workers=1, host=192.168.0.102, username=fajarianatm, pid=69649) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-27 22:49:00,344 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 22:49:00,350 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-27 22:49:00,350 - DEBUG - Asking scheduler for work...
2024-12-27 22:49:00,352 - DEBUG - Done
2024-12-27 22:49:00,352 - DEBUG - There are no more tasks to run at this time
2024-12-27 22:49:00,352 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-27 22:49:00,352 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-27 22:49:00,352 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-27 22:49:00,352 - INFO - Worker Worker(salt=8053917368, workers=1, host=192.168.0.102, username=fajarianatm, pid=69649) was stopped. Shutting down Keep-Alive thread
2024-12-27 22:49:00,354 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 23:27:48,847 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 23:27:49,469 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 23:27:49,510 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 23:27:49,516 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 23:27:49,706 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 23:27:50,333 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 23:27:50,941 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 23:27:51,312 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 23:27:51,778 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 23:27:51,779 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 23:27:51,782 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 23:27:51,790 - INFO - [pid 85638] Worker Worker(salt=9241717387, workers=1, host=192.168.0.102, username=fajarianatm, pid=85638) done      Extract()
2024-12-27 23:27:51,791 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 23:27:51,793 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 23:27:51,793 - DEBUG - Asking scheduler for work...
2024-12-27 23:27:51,795 - DEBUG - Pending tasks: 2
2024-12-27 23:27:51,795 - INFO - [pid 85638] Worker Worker(salt=9241717387, workers=1, host=192.168.0.102, username=fajarianatm, pid=85638) running   Load()
2024-12-27 23:27:51,798 - INFO - Read Load Query - SUCCESS
2024-12-27 23:27:52,519 - INFO - Read Extracted Data - SUCCESS
2024-12-27 23:27:52,520 - INFO - Connect to DWH - SUCCESS
2024-12-27 23:27:52,758 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 23:27:52,758 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 23:27:54,893 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 23:27:54,935 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 23:27:54,938 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 23:27:56,154 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 23:27:59,236 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 23:28:03,316 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 23:28:05,689 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 23:28:08,124 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 23:28:08,124 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 23:28:09,463 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-27 23:28:09,491 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-27 23:28:09,493 - ERROR - [pid 85638] Worker Worker(salt=9241717387, workers=1, host=192.168.0.102, username=fajarianatm, pid=85638) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-27 23:28:09,513 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 23:28:09,520 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-27 23:28:09,521 - DEBUG - Asking scheduler for work...
2024-12-27 23:28:09,522 - DEBUG - Done
2024-12-27 23:28:09,522 - DEBUG - There are no more tasks to run at this time
2024-12-27 23:28:09,522 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-27 23:28:09,523 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-27 23:28:09,523 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-27 23:28:09,523 - INFO - Worker Worker(salt=9241717387, workers=1, host=192.168.0.102, username=fajarianatm, pid=85638) was stopped. Shutting down Keep-Alive thread
2024-12-27 23:28:09,523 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-27 23:29:46,851 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-27 23:29:47,290 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-27 23:29:47,332 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-27 23:29:47,337 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-27 23:29:47,525 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-27 23:29:48,024 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-27 23:29:48,583 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-27 23:29:48,937 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-27 23:29:49,400 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-27 23:29:49,400 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-27 23:29:49,406 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-27 23:29:49,416 - INFO - [pid 86578] Worker Worker(salt=9041281142, workers=1, host=192.168.0.102, username=fajarianatm, pid=86578) done      Extract()
2024-12-27 23:29:49,417 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 23:29:49,420 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-27 23:29:49,420 - DEBUG - Asking scheduler for work...
2024-12-27 23:29:49,422 - DEBUG - Pending tasks: 2
2024-12-27 23:29:49,422 - INFO - [pid 86578] Worker Worker(salt=9041281142, workers=1, host=192.168.0.102, username=fajarianatm, pid=86578) running   Load()
2024-12-27 23:29:49,424 - INFO - Read Load Query - SUCCESS
2024-12-27 23:29:50,300 - INFO - Read Extracted Data - SUCCESS
2024-12-27 23:29:50,301 - INFO - Connect to DWH - SUCCESS
2024-12-27 23:29:50,436 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-27 23:29:50,437 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-27 23:29:52,570 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-27 23:29:52,617 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-27 23:29:52,620 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-27 23:29:53,707 - INFO - LOAD 'src.products' - SUCCESS
2024-12-27 23:29:56,805 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-27 23:30:01,061 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-27 23:30:03,510 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-27 23:30:05,987 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-27 23:30:05,987 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-27 23:30:07,185 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-27 23:30:07,231 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-27 23:30:07,234 - ERROR - [pid 86578] Worker Worker(salt=9041281142, workers=1, host=192.168.0.102, username=fajarianatm, pid=86578) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-27 23:30:07,254 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-27 23:30:07,262 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-27 23:30:07,262 - DEBUG - Asking scheduler for work...
2024-12-27 23:30:07,264 - DEBUG - Done
2024-12-27 23:30:07,264 - DEBUG - There are no more tasks to run at this time
2024-12-27 23:30:07,264 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-27 23:30:07,264 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-27 23:30:07,264 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-27 23:30:07,264 - INFO - Worker Worker(salt=9041281142, workers=1, host=192.168.0.102, username=fajarianatm, pid=86578) was stopped. Shutting down Keep-Alive thread
2024-12-27 23:30:07,265 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 10:15:52,062 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 10:15:52,639 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 10:15:52,678 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 10:15:52,683 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 10:15:52,862 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 10:15:53,387 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 10:15:53,995 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 10:15:54,327 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 10:15:54,742 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 10:15:54,742 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 10:15:54,747 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 10:15:54,754 - INFO - [pid 25659] Worker Worker(salt=829468369, workers=1, host=Nanas.local, username=fajarianatm, pid=25659) done      Extract()
2024-12-28 10:15:54,755 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:15:54,757 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 10:15:54,757 - DEBUG - Asking scheduler for work...
2024-12-28 10:15:54,758 - DEBUG - Pending tasks: 2
2024-12-28 10:15:54,758 - INFO - [pid 25659] Worker Worker(salt=829468369, workers=1, host=Nanas.local, username=fajarianatm, pid=25659) running   Load()
2024-12-28 10:15:54,760 - INFO - Read Load Query - SUCCESS
2024-12-28 10:15:55,462 - INFO - Read Extracted Data - SUCCESS
2024-12-28 10:15:55,463 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:15:55,590 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 10:15:55,590 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 10:15:57,527 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 10:15:57,577 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 10:15:57,580 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 10:15:58,665 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 10:16:01,531 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 10:16:05,443 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 10:16:07,755 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 10:16:10,140 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 10:16:10,141 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 10:16:11,513 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-28 10:16:11,548 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-28 10:16:11,551 - ERROR - [pid 25659] Worker Worker(salt=829468369, workers=1, host=Nanas.local, username=fajarianatm, pid=25659) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-28 10:16:11,575 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:16:11,580 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-28 10:16:11,580 - DEBUG - Asking scheduler for work...
2024-12-28 10:16:11,582 - DEBUG - Done
2024-12-28 10:16:11,583 - DEBUG - There are no more tasks to run at this time
2024-12-28 10:16:11,583 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-28 10:16:11,583 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-28 10:16:11,583 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-28 10:16:11,583 - INFO - Worker Worker(salt=829468369, workers=1, host=Nanas.local, username=fajarianatm, pid=25659) was stopped. Shutting down Keep-Alive thread
2024-12-28 10:16:11,584 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 10:20:24,658 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 10:20:25,102 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 10:20:25,138 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 10:20:25,142 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 10:20:25,323 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 10:20:25,815 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 10:20:26,375 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 10:20:26,717 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 10:20:27,116 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 10:20:27,116 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 10:20:27,119 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 10:20:27,127 - INFO - [pid 27574] Worker Worker(salt=8254480920, workers=1, host=Nanas.local, username=fajarianatm, pid=27574) done      Extract()
2024-12-28 10:20:27,127 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:20:27,129 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 10:20:27,129 - DEBUG - Asking scheduler for work...
2024-12-28 10:20:27,130 - DEBUG - Pending tasks: 2
2024-12-28 10:20:27,131 - INFO - [pid 27574] Worker Worker(salt=8254480920, workers=1, host=Nanas.local, username=fajarianatm, pid=27574) running   Load()
2024-12-28 10:20:27,133 - INFO - Read Load Query - SUCCESS
2024-12-28 10:20:27,800 - INFO - Read Extracted Data - SUCCESS
2024-12-28 10:20:27,800 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:20:27,908 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 10:20:27,908 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 10:20:29,777 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 10:20:29,819 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 10:20:29,822 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 10:20:30,824 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 10:20:33,612 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 10:20:37,582 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 10:20:39,861 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 10:20:42,302 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 10:20:42,302 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 10:20:43,611 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-28 10:20:43,646 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-28 10:20:43,648 - ERROR - [pid 27574] Worker Worker(salt=8254480920, workers=1, host=Nanas.local, username=fajarianatm, pid=27574) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) record "old" has no field "customer_zip_code"
CONTEXT:  SQL expression "(
        NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code OR
        NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
        NEW.customer_state IS DISTINCT FROM OLD.customer_state
    )"
PL/pgSQL function final.update_dim_customers() line 4 at IF

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-28 10:20:43,670 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:20:43,676 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-28 10:20:43,676 - DEBUG - Asking scheduler for work...
2024-12-28 10:20:43,678 - DEBUG - Done
2024-12-28 10:20:43,678 - DEBUG - There are no more tasks to run at this time
2024-12-28 10:20:43,678 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-28 10:20:43,678 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-28 10:20:43,678 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-28 10:20:43,678 - INFO - Worker Worker(salt=8254480920, workers=1, host=Nanas.local, username=fajarianatm, pid=27574) was stopped. Shutting down Keep-Alive thread
2024-12-28 10:20:43,679 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 10:22:14,221 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 10:22:14,682 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 10:22:14,721 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 10:22:14,724 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 10:22:14,976 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 10:22:15,476 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 10:22:16,092 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 10:22:16,477 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 10:22:16,930 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 10:22:16,930 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 10:22:16,934 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 10:22:16,942 - INFO - [pid 28864] Worker Worker(salt=2900259114, workers=1, host=Nanas.local, username=fajarianatm, pid=28864) done      Extract()
2024-12-28 10:22:16,942 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:22:16,944 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 10:22:16,944 - DEBUG - Asking scheduler for work...
2024-12-28 10:22:16,945 - DEBUG - Pending tasks: 2
2024-12-28 10:22:16,945 - INFO - [pid 28864] Worker Worker(salt=2900259114, workers=1, host=Nanas.local, username=fajarianatm, pid=28864) running   Load()
2024-12-28 10:22:16,948 - INFO - Read Load Query - SUCCESS
2024-12-28 10:22:17,636 - INFO - Read Extracted Data - SUCCESS
2024-12-28 10:22:17,637 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:22:17,727 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 10:22:17,727 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 10:22:19,550 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 10:22:19,634 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 10:22:19,637 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 10:22:20,720 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 10:22:23,561 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 10:22:27,398 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 10:22:29,610 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 10:22:31,905 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 10:22:31,905 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 10:22:39,000 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-28 10:22:39,005 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-28 10:22:39,062 - INFO - [pid 28864] Worker Worker(salt=2900259114, workers=1, host=Nanas.local, username=fajarianatm, pid=28864) done      Load()
2024-12-28 10:22:39,063 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:22:39,066 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-28 10:22:39,066 - DEBUG - Asking scheduler for work...
2024-12-28 10:22:39,068 - DEBUG - Pending tasks: 1
2024-12-28 10:22:39,068 - INFO - [pid 28864] Worker Worker(salt=2900259114, workers=1, host=Nanas.local, username=fajarianatm, pid=28864) running   Transform()
2024-12-28 10:22:39,070 - INFO - Read Transform Query - SUCCESS
2024-12-28 10:22:39,071 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:22:39,071 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-28 10:22:39,626 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-28 10:22:39,677 - ERROR - Transform Tables - FAILED
2024-12-28 10:22:39,680 - ERROR - [pid 28864] Worker Worker(salt=2900259114, workers=1, host=Nanas.local, username=fajarianatm, pid=28864) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InvalidSchemaName: schema "staging" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.InvalidSchemaName) schema "staging" does not exist

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code_prefix AS customer_zip_code,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,  
    NULL AS expired_at,
    1 AS version_id  
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Periksa apakah customer_nk sudah ada sebagai data aktif
    IF NOT EXISTS (
        SELECT 1
        FROM final.dim_customers
        WHERE customer_nk = NEW.customer_id
          AND current_flag = 'current'
    ) THEN
        -- Jika customer_nk belum ada, lakukan insert
        INSERT INTO final.dim_customers (
            customer_id,
            customer_nk,
            customer_zip_code,
            customer_city,
            customer_state,
            current_flag,
            created_at,
            expired_at,
            version_id
        )
        VALUES (
            NEW.id,
            NEW.customer_id,
            NEW.customer_zip_code_prefix,
            NEW.customer_city,
            NEW.customer_state,
            'current', -- Tandai sebagai data aktif
            NOW(),
            NULL,
            1
        );
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Masukkan data baru jika customer_nk belum ada dengan current_flag = 'current'
    INSERT INTO final.dim_customers (
        customer_id, customer_nk, customer_zip_code, customer_city, customer_state, 
        current_flag, created_at, version_id
    )
    SELECT 
        NEW.id AS customer_id, 
        NEW.customer_id AS customer_nk, 
        NEW.customer_zip_code_prefix AS customer_zip_code, 
        NEW.customer_city, 
        NEW.customer_state, 
        'current' AS current_flag, 
        NOW() AS created_at,
        COALESCE(MAX(version_id), 0) + 1
    FROM final.dim_customers
    WHERE NOT EXISTS (
        SELECT 1 
        FROM final.dim_customers 
        WHERE customer_nk = NEW.customer_id 
        AND current_flag = 'current'
    );

    -- Update data lama menjadi expired jika ada perubahan pada kolom yang relevan
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code_prefix OR
            NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
            NEW.customer_state IS DISTINCT FROM OLD.customer_state
        );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Pasang trigger pada tabel staging.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON staging.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-28 10:22:39,699 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:22:39,703 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-28 10:22:39,703 - DEBUG - Asking scheduler for work...
2024-12-28 10:22:39,705 - DEBUG - Done
2024-12-28 10:22:39,705 - DEBUG - There are no more tasks to run at this time
2024-12-28 10:22:39,705 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-28 10:22:39,705 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-28 10:22:39,705 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-28 10:22:39,705 - INFO - Worker Worker(salt=2900259114, workers=1, host=Nanas.local, username=fajarianatm, pid=28864) was stopped. Shutting down Keep-Alive thread
2024-12-28 10:22:39,706 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 10:24:16,654 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 10:24:17,090 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 10:24:17,129 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 10:24:17,133 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 10:24:17,315 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 10:24:17,808 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 10:24:18,350 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 10:24:18,720 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 10:24:19,095 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 10:24:19,095 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 10:24:19,101 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 10:24:19,109 - INFO - [pid 29738] Worker Worker(salt=4916229618, workers=1, host=Nanas.local, username=fajarianatm, pid=29738) done      Extract()
2024-12-28 10:24:19,109 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:24:19,111 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 10:24:19,111 - DEBUG - Asking scheduler for work...
2024-12-28 10:24:19,112 - DEBUG - Pending tasks: 2
2024-12-28 10:24:19,112 - INFO - [pid 29738] Worker Worker(salt=4916229618, workers=1, host=Nanas.local, username=fajarianatm, pid=29738) running   Load()
2024-12-28 10:24:19,115 - INFO - Read Load Query - SUCCESS
2024-12-28 10:24:19,774 - INFO - Read Extracted Data - SUCCESS
2024-12-28 10:24:19,775 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:24:19,869 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 10:24:19,869 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 10:24:21,691 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 10:24:21,734 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 10:24:21,737 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 10:24:22,774 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 10:24:25,539 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 10:24:29,667 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 10:24:32,041 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 10:24:34,444 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 10:24:34,444 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 10:24:41,486 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-28 10:24:41,506 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-28 10:24:41,567 - INFO - [pid 29738] Worker Worker(salt=4916229618, workers=1, host=Nanas.local, username=fajarianatm, pid=29738) done      Load()
2024-12-28 10:24:41,567 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:24:41,571 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-28 10:24:41,571 - DEBUG - Asking scheduler for work...
2024-12-28 10:24:41,572 - DEBUG - Pending tasks: 1
2024-12-28 10:24:41,572 - INFO - [pid 29738] Worker Worker(salt=4916229618, workers=1, host=Nanas.local, username=fajarianatm, pid=29738) running   Transform()
2024-12-28 10:24:41,574 - INFO - Read Transform Query - SUCCESS
2024-12-28 10:24:41,575 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:24:41,575 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-28 10:24:42,107 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-28 10:24:42,124 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-28 10:24:42,268 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-28 10:24:42,275 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-28 10:24:42,553 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-28 10:24:42,597 - ERROR - Transform Tables - FAILED
2024-12-28 10:24:42,600 - ERROR - [pid 29738] Worker Worker(salt=4916229618, workers=1, host=Nanas.local, username=fajarianatm, pid=29738) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.CardinalityViolation: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 124, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.CardinalityViolation) ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

[SQL:  WITH stg_fct_reviews AS (
    SELECT 
        sor.review_id AS review_nk,
        sor.order_id AS order_nk,
        fdc.customer_id AS customer_id,
        CASE
            WHEN sor.review_score BETWEEN 1 AND 2 THEN 'negative'
            WHEN sor.review_score = 3 THEN 'netral'
            WHEN sor.review_score BETWEEN 4 AND 5 THEN 'positive'
            ELSE 'unknown'
        END AS sentiment,
        sop.payment_sequential AS payment_sequential,
        sop.payment_type AS payment_type,
        sop.payment_installments AS payment_installments,
        sop.payment_value AS payment_value,
        sor.review_score AS review_score,
        sor.review_comment_title AS review_comment_title,
        sor.review_comment_message AS review_comment_message,
        sor.review_creation_date AS review_creation_date
    FROM stg.order_reviews sor

    JOIN stg.orders so
        ON so.order_id = sor.order_id

    JOIN stg.order_payments sop
        ON sop.order_id = so.order_id

    JOIN final.dim_customers fdc
        ON fdc.customer_nk = so.customer_id
    
)

INSERT INTO final.fct_reviews (
    review_nk,
    order_nk,
    customer_id,
    sentiment,
    payment_sequential,
    payment_type,
    payment_installments,
    payment_value,
    review_score,
    review_comment_title,
    review_comment_message,
    review_creation_date
)

SELECT *
FROM stg_fct_reviews

ON CONFLICT(review_nk, order_nk)
DO UPDATE SET
    customer_id = EXCLUDED.customer_id,
    sentiment = EXCLUDED.sentiment,
    payment_sequential = EXCLUDED.payment_sequential,
    payment_type = EXCLUDED.payment_type,
    payment_installments = EXCLUDED.payment_installments,
    payment_value = EXCLUDED.payment_value,
    review_score = EXCLUDED.review_score,
    review_comment_title = EXCLUDED.review_comment_title,
    review_comment_message = EXCLUDED.review_comment_message,
    review_creation_date = EXCLUDED.review_creation_date,
    updated_at = CASE 
                    WHEN final.fct_reviews.customer_id <> EXCLUDED.customer_id
                        OR final.fct_reviews.sentiment <> EXCLUDED.sentiment
                        OR final.fct_reviews.payment_sequential <> EXCLUDED.payment_sequential
                        OR final.fct_reviews.payment_type <> EXCLUDED.payment_type
                        OR final.fct_reviews.payment_installments <> EXCLUDED.payment_installments
                        OR final.fct_reviews.payment_value <> EXCLUDED.payment_value
                        OR final.fct_reviews.review_score <> EXCLUDED.review_score
                        OR final.fct_reviews.review_comment_title <> EXCLUDED.review_comment_title
                        OR final.fct_reviews.review_comment_message <> EXCLUDED.review_comment_message
                        OR final.fct_reviews.review_creation_date <> EXCLUDED.review_creation_date
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_reviews.updated_at
                 END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-28 10:24:42,630 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:24:42,636 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-28 10:24:42,636 - DEBUG - Asking scheduler for work...
2024-12-28 10:24:42,637 - DEBUG - Done
2024-12-28 10:24:42,637 - DEBUG - There are no more tasks to run at this time
2024-12-28 10:24:42,637 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-28 10:24:42,637 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-28 10:24:42,637 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-28 10:24:42,637 - INFO - Worker Worker(salt=4916229618, workers=1, host=Nanas.local, username=fajarianatm, pid=29738) was stopped. Shutting down Keep-Alive thread
2024-12-28 10:24:42,638 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 10:41:51,273 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 10:41:51,913 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 10:41:51,953 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 10:41:51,957 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 10:41:52,131 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 10:41:52,621 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 10:41:53,184 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 10:41:53,528 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 10:41:53,947 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 10:41:53,947 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 10:41:53,951 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 10:41:53,959 - INFO - [pid 37050] Worker Worker(salt=1992790832, workers=1, host=Nanas.local, username=fajarianatm, pid=37050) done      Extract()
2024-12-28 10:41:53,959 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:41:53,962 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 10:41:53,962 - DEBUG - Asking scheduler for work...
2024-12-28 10:41:53,963 - DEBUG - Pending tasks: 2
2024-12-28 10:41:53,964 - INFO - [pid 37050] Worker Worker(salt=1992790832, workers=1, host=Nanas.local, username=fajarianatm, pid=37050) running   Load()
2024-12-28 10:41:53,966 - INFO - Read Load Query - SUCCESS
2024-12-28 10:41:54,606 - INFO - Read Extracted Data - SUCCESS
2024-12-28 10:41:54,607 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:41:54,748 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 10:41:54,748 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 10:41:56,778 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 10:41:56,823 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 10:41:56,826 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 10:41:57,890 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 10:42:00,838 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 10:42:04,800 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 10:42:07,194 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 10:42:09,834 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 10:42:09,835 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 10:42:11,356 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-28 10:42:11,389 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-28 10:42:11,393 - ERROR - [pid 37050] Worker Worker(salt=1992790832, workers=1, host=Nanas.local, username=fajarianatm, pid=37050) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id, version_id)=(e2fdab09-5d7c-4b7c-9021-46aa42233a7f, 1) already exists.
CONTEXT:  SQL statement "INSERT INTO final.dim_customers (
        customer_id, customer_nk, customer_zip_code, customer_city, customer_state, 
        current_flag, created_at, version_id
    )
    SELECT 
        NEW.id AS customer_id, 
        NEW.customer_id AS customer_nk, 
        NEW.customer_zip_code_prefix AS customer_zip_code, 
        NEW.customer_city, 
        NEW.customer_state, 
        'current' AS current_flag, 
        NOW() AS created_at,
        COALESCE(MAX(version_id), 0) + 1
    FROM final.dim_customers
    WHERE NOT EXISTS (
        SELECT 1 
        FROM final.dim_customers 
        WHERE customer_nk = NEW.customer_id 
        AND current_flag = 'current'
    )"
PL/pgSQL function final.update_dim_customers() line 4 at SQL statement


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id, version_id)=(e2fdab09-5d7c-4b7c-9021-46aa42233a7f, 1) already exists.
CONTEXT:  SQL statement "INSERT INTO final.dim_customers (
        customer_id, customer_nk, customer_zip_code, customer_city, customer_state, 
        current_flag, created_at, version_id
    )
    SELECT 
        NEW.id AS customer_id, 
        NEW.customer_id AS customer_nk, 
        NEW.customer_zip_code_prefix AS customer_zip_code, 
        NEW.customer_city, 
        NEW.customer_state, 
        'current' AS current_flag, 
        NOW() AS created_at,
        COALESCE(MAX(version_id), 0) + 1
    FROM final.dim_customers
    WHERE NOT EXISTS (
        SELECT 1 
        FROM final.dim_customers 
        WHERE customer_nk = NEW.customer_id 
        AND current_flag = 'current'
    )"
PL/pgSQL function final.update_dim_customers() line 4 at SQL statement

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-28 10:42:11,417 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:42:11,424 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-28 10:42:11,424 - DEBUG - Asking scheduler for work...
2024-12-28 10:42:11,426 - DEBUG - Done
2024-12-28 10:42:11,426 - DEBUG - There are no more tasks to run at this time
2024-12-28 10:42:11,426 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-28 10:42:11,427 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-28 10:42:11,427 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-28 10:42:11,427 - INFO - Worker Worker(salt=1992790832, workers=1, host=Nanas.local, username=fajarianatm, pid=37050) was stopped. Shutting down Keep-Alive thread
2024-12-28 10:42:11,428 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 10:50:34,557 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 10:50:34,977 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 10:50:35,017 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 10:50:35,021 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 10:50:35,211 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 10:50:35,732 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 10:50:36,283 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 10:50:36,639 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 10:50:37,045 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 10:50:37,045 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 10:50:37,050 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 10:50:37,057 - INFO - [pid 40624] Worker Worker(salt=8985016930, workers=1, host=Nanas.local, username=fajarianatm, pid=40624) done      Extract()
2024-12-28 10:50:37,058 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:50:37,060 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 10:50:37,060 - DEBUG - Asking scheduler for work...
2024-12-28 10:50:37,061 - DEBUG - Pending tasks: 2
2024-12-28 10:50:37,061 - INFO - [pid 40624] Worker Worker(salt=8985016930, workers=1, host=Nanas.local, username=fajarianatm, pid=40624) running   Load()
2024-12-28 10:50:37,063 - INFO - Read Load Query - SUCCESS
2024-12-28 10:50:37,714 - INFO - Read Extracted Data - SUCCESS
2024-12-28 10:50:37,714 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:50:37,821 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 10:50:37,822 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 10:50:39,607 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 10:50:39,651 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 10:50:39,655 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 10:50:40,679 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 10:50:43,530 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 10:50:47,497 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 10:50:49,860 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 10:50:52,355 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 10:50:52,355 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 10:50:53,722 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-28 10:50:53,771 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-28 10:50:53,775 - ERROR - [pid 40624] Worker Worker(salt=8985016930, workers=1, host=Nanas.local, username=fajarianatm, pid=40624) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id, version_id)=(e2fdab09-5d7c-4b7c-9021-46aa42233a7f, 1) already exists.
CONTEXT:  SQL statement "INSERT INTO final.dim_customers (
        customer_id, customer_nk, customer_zip_code, customer_city, customer_state, 
        current_flag, created_at, version_id
    )
    SELECT 
        NEW.id AS customer_id, 
        NEW.customer_id AS customer_nk, 
        NEW.customer_zip_code_prefix AS customer_zip_code, 
        NEW.customer_city, 
        NEW.customer_state, 
        'current' AS current_flag, 
        NOW() AS created_at,
        COALESCE(MAX(version_id), 0) + 1
    FROM final.dim_customers
    WHERE NOT EXISTS (
        SELECT 1 
        FROM final.dim_customers 
        WHERE customer_nk = NEW.customer_id 
        AND current_flag = 'current'
    )"
PL/pgSQL function final.update_dim_customers() line 4 at SQL statement


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id, version_id)=(e2fdab09-5d7c-4b7c-9021-46aa42233a7f, 1) already exists.
CONTEXT:  SQL statement "INSERT INTO final.dim_customers (
        customer_id, customer_nk, customer_zip_code, customer_city, customer_state, 
        current_flag, created_at, version_id
    )
    SELECT 
        NEW.id AS customer_id, 
        NEW.customer_id AS customer_nk, 
        NEW.customer_zip_code_prefix AS customer_zip_code, 
        NEW.customer_city, 
        NEW.customer_state, 
        'current' AS current_flag, 
        NOW() AS created_at,
        COALESCE(MAX(version_id), 0) + 1
    FROM final.dim_customers
    WHERE NOT EXISTS (
        SELECT 1 
        FROM final.dim_customers 
        WHERE customer_nk = NEW.customer_id 
        AND current_flag = 'current'
    )"
PL/pgSQL function final.update_dim_customers() line 4 at SQL statement

[SQL: INSERT INTO stg.customers
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id, 
    customer_unique_id, 
    customer_zip_code_prefix, 
    customer_city, 
    customer_state
FROM
    src.customers

ON CONFLICT(customer_id)
DO UPDATE SET
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,
    updated_at = CASE 
                    WHEN stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix
                        OR stg.customers.customer_city <> EXCLUDED.customer_city
                        OR stg.customers.customer_state <> EXCLUDED.customer_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.customers.updated_at
                 END;

]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-28 10:50:53,796 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:50:53,805 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-28 10:50:53,805 - DEBUG - Asking scheduler for work...
2024-12-28 10:50:53,807 - DEBUG - Done
2024-12-28 10:50:53,807 - DEBUG - There are no more tasks to run at this time
2024-12-28 10:50:53,807 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-28 10:50:53,807 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-28 10:50:53,807 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-28 10:50:53,808 - INFO - Worker Worker(salt=8985016930, workers=1, host=Nanas.local, username=fajarianatm, pid=40624) was stopped. Shutting down Keep-Alive thread
2024-12-28 10:50:53,808 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 10:52:56,559 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 10:52:57,034 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 10:52:57,080 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 10:52:57,083 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 10:52:57,267 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 10:52:57,758 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 10:52:58,364 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 10:52:58,704 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 10:52:59,128 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 10:52:59,128 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 10:52:59,130 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 10:52:59,137 - INFO - [pid 41904] Worker Worker(salt=812258725, workers=1, host=Nanas.local, username=fajarianatm, pid=41904) done      Extract()
2024-12-28 10:52:59,138 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:52:59,140 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 10:52:59,140 - DEBUG - Asking scheduler for work...
2024-12-28 10:52:59,141 - DEBUG - Pending tasks: 2
2024-12-28 10:52:59,141 - INFO - [pid 41904] Worker Worker(salt=812258725, workers=1, host=Nanas.local, username=fajarianatm, pid=41904) running   Load()
2024-12-28 10:52:59,144 - INFO - Read Load Query - SUCCESS
2024-12-28 10:52:59,795 - INFO - Read Extracted Data - SUCCESS
2024-12-28 10:52:59,795 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:52:59,883 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 10:52:59,883 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 10:53:01,694 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 10:53:01,796 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 10:53:01,799 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 10:53:02,816 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 10:53:05,564 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 10:53:09,389 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 10:53:11,566 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 10:53:13,894 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 10:53:13,894 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 10:53:20,841 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-28 10:53:20,850 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-28 10:53:20,901 - INFO - [pid 41904] Worker Worker(salt=812258725, workers=1, host=Nanas.local, username=fajarianatm, pid=41904) done      Load()
2024-12-28 10:53:20,901 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:53:20,904 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-28 10:53:20,904 - DEBUG - Asking scheduler for work...
2024-12-28 10:53:20,906 - DEBUG - Pending tasks: 1
2024-12-28 10:53:20,906 - INFO - [pid 41904] Worker Worker(salt=812258725, workers=1, host=Nanas.local, username=fajarianatm, pid=41904) running   Transform()
2024-12-28 10:53:20,909 - INFO - Read Transform Query - SUCCESS
2024-12-28 10:53:20,910 - INFO - Connect to DWH - SUCCESS
2024-12-28 10:53:20,910 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-28 10:53:21,616 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-28 10:53:21,632 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-28 10:53:21,846 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-28 10:53:22,261 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-28 10:53:23,532 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-28 10:53:23,590 - ERROR - Transform Tables - FAILED
2024-12-28 10:53:23,594 - ERROR - [pid 41904] Worker Worker(salt=812258725, workers=1, host=Nanas.local, username=fajarianatm, pid=41904) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "payment_sequential" of relation "fct_reviews" violates not-null constraint
DETAIL:  Failing row contains (69199d7f-a3c8-4a36-9f3e-e23da25e168a, 6916ca4502d6d3bfd39818759d55d536, bfbd0f9bdef84302105ad712db648a6c, 8664e931-dcbc-4244-8637-4d677e2a513f, negative, null, null, null, null, 1, null, nao recebi o produto e nem resposta da empresa, 2016-10-07 18:32:28, 2024-12-28 03:53:21.853624, 2024-12-28 03:53:21.853624).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 124, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "payment_sequential" of relation "fct_reviews" violates not-null constraint
DETAIL:  Failing row contains (69199d7f-a3c8-4a36-9f3e-e23da25e168a, 6916ca4502d6d3bfd39818759d55d536, bfbd0f9bdef84302105ad712db648a6c, 8664e931-dcbc-4244-8637-4d677e2a513f, negative, null, null, null, null, 1, null, nao recebi o produto e nem resposta da empresa, 2016-10-07 18:32:28, 2024-12-28 03:53:21.853624, 2024-12-28 03:53:21.853624).

[SQL: WITH ranked_payments AS (
    SELECT 
        op.order_id,
        op.payment_sequential,
        op.payment_type,
        op.payment_installments,
        op.payment_value,
        ROW_NUMBER() OVER (PARTITION BY op.order_id ORDER BY op.payment_sequential ASC) AS rn
    FROM stg.order_payments op
),
filtered_payments AS (
    SELECT *
    FROM ranked_payments
    WHERE rn = 1 -- Hanya ambil baris pertama untuk setiap order_id
),
stg_fct_reviews AS (
    SELECT 
        orw.review_id AS review_nk,
        orw.order_id AS order_nk,
        fdc.customer_id AS customer_id,
        CASE
            WHEN orw.review_score BETWEEN 1 AND 2 THEN 'negative'
            WHEN orw.review_score = 3 THEN 'neutral'
            WHEN orw.review_score BETWEEN 4 AND 5 THEN 'positive'
            ELSE 'unknown'
        END AS sentiment,
        fp.payment_sequential,
        fp.payment_type,
        fp.payment_installments,
        fp.payment_value,
        orw.review_score,
        orw.review_comment_title,
        orw.review_comment_message,
        orw.review_creation_date
    FROM stg.order_reviews orw
    JOIN stg.orders so
        ON so.order_id = orw.order_id
    LEFT JOIN filtered_payments fp
        ON fp.order_id = so.order_id
    LEFT JOIN final.dim_customers fdc
        ON fdc.customer_nk = so.customer_id
)
INSERT INTO final.fct_reviews (
    review_nk,
    order_nk,
    customer_id,
    sentiment,
    payment_sequential,
    payment_type,
    payment_installments,
    payment_value,
    review_score,
    review_comment_title,
    review_comment_message,
    review_creation_date
)
SELECT *
FROM stg_fct_reviews
ON CONFLICT (review_nk, order_nk)
DO UPDATE SET
    customer_id = EXCLUDED.customer_id,
    sentiment = EXCLUDED.sentiment,
    payment_sequential = EXCLUDED.payment_sequential,
    payment_type = EXCLUDED.payment_type,
    payment_installments = EXCLUDED.payment_installments,
    payment_value = EXCLUDED.payment_value,
    review_score = EXCLUDED.review_score,
    review_comment_title = EXCLUDED.review_comment_title,
    review_comment_message = EXCLUDED.review_comment_message,
    review_creation_date = EXCLUDED.review_creation_date,
    updated_at = CASE 
                    WHEN final.fct_reviews.customer_id <> EXCLUDED.customer_id
                        OR final.fct_reviews.sentiment <> EXCLUDED.sentiment
                        OR final.fct_reviews.payment_sequential <> EXCLUDED.payment_sequential
                        OR final.fct_reviews.payment_type <> EXCLUDED.payment_type
                        OR final.fct_reviews.payment_installments <> EXCLUDED.payment_installments
                        OR final.fct_reviews.payment_value <> EXCLUDED.payment_value
                        OR final.fct_reviews.review_score <> EXCLUDED.review_score
                        OR final.fct_reviews.review_comment_title <> EXCLUDED.review_comment_title
                        OR final.fct_reviews.review_comment_message <> EXCLUDED.review_comment_message
                        OR final.fct_reviews.review_creation_date <> EXCLUDED.review_creation_date
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_reviews.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-28 10:53:23,617 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 10:53:23,622 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-28 10:53:23,622 - DEBUG - Asking scheduler for work...
2024-12-28 10:53:23,624 - DEBUG - Done
2024-12-28 10:53:23,624 - DEBUG - There are no more tasks to run at this time
2024-12-28 10:53:23,625 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-28 10:53:23,625 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-28 10:53:23,625 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-28 10:53:23,625 - INFO - Worker Worker(salt=812258725, workers=1, host=Nanas.local, username=fajarianatm, pid=41904) was stopped. Shutting down Keep-Alive thread
2024-12-28 10:53:23,627 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 11:05:47,954 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 11:05:48,411 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 11:05:48,448 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 11:05:48,451 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 11:05:48,611 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 11:05:49,099 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 11:05:49,641 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 11:05:49,984 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 11:05:50,384 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 11:05:50,384 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 11:05:50,387 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 11:05:50,394 - INFO - [pid 47108] Worker Worker(salt=3973804560, workers=1, host=Nanas.local, username=fajarianatm, pid=47108) done      Extract()
2024-12-28 11:05:50,395 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 11:05:50,397 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 11:05:50,397 - DEBUG - Asking scheduler for work...
2024-12-28 11:05:50,399 - DEBUG - Pending tasks: 2
2024-12-28 11:05:50,399 - INFO - [pid 47108] Worker Worker(salt=3973804560, workers=1, host=Nanas.local, username=fajarianatm, pid=47108) running   Load()
2024-12-28 11:05:50,401 - INFO - Read Load Query - SUCCESS
2024-12-28 11:05:51,077 - INFO - Read Extracted Data - SUCCESS
2024-12-28 11:05:51,078 - INFO - Connect to DWH - SUCCESS
2024-12-28 11:05:51,187 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 11:05:51,187 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 11:05:52,965 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 11:05:53,009 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 11:05:53,012 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 11:05:54,115 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 11:05:56,933 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 11:06:00,887 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 11:06:03,169 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 11:06:05,519 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 11:06:05,519 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 11:11:28,844 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-28 11:11:28,919 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-28 11:11:28,922 - ERROR - [pid 47108] Worker Worker(salt=3973804560, workers=1, host=Nanas.local, username=fajarianatm, pid=47108) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: record "old" has no field "seller_zip_code"
CONTEXT:  SQL expression "(
        NEW.seller_zip_code_prefix IS DISTINCT FROM OLD.seller_zip_code OR
        NEW.seller_city IS DISTINCT FROM OLD.seller_city OR
        NEW.seller_state IS DISTINCT FROM OLD.seller_state
    )"
PL/pgSQL function final.update_dim_sellers() line 4 at IF


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) record "old" has no field "seller_zip_code"
CONTEXT:  SQL expression "(
        NEW.seller_zip_code_prefix IS DISTINCT FROM OLD.seller_zip_code OR
        NEW.seller_city IS DISTINCT FROM OLD.seller_city OR
        NEW.seller_state IS DISTINCT FROM OLD.seller_state
    )"
PL/pgSQL function final.update_dim_sellers() line 4 at IF

[SQL: INSERT INTO stg.sellers
    (seller_id, seller_zip_code_prefix, seller_city, seller_state)

SELECT
    seller_id,
    seller_zip_code_prefix,
    seller_city,
    seller_state
FROM src.sellers

ON CONFLICT(seller_id)
DO UPDATE SET
    seller_zip_code_prefix = EXCLUDED.seller_zip_code_prefix,
    seller_city = EXCLUDED.seller_city,
    seller_state = EXCLUDED.seller_state,
    updated_at = CASE 
                    WHEN stg.sellers.seller_zip_code_prefix <> EXCLUDED.seller_zip_code_prefix
                        OR stg.sellers.seller_city <> EXCLUDED.seller_city
                        OR stg.sellers.seller_state <> EXCLUDED.seller_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.sellers.updated_at
                 END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-28 11:11:28,942 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 11:11:28,948 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-28 11:11:28,948 - DEBUG - Asking scheduler for work...
2024-12-28 11:11:28,949 - DEBUG - Done
2024-12-28 11:11:28,949 - DEBUG - There are no more tasks to run at this time
2024-12-28 11:11:28,949 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-28 11:11:28,949 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-28 11:11:28,949 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-28 11:11:28,949 - INFO - Worker Worker(salt=3973804560, workers=1, host=Nanas.local, username=fajarianatm, pid=47108) was stopped. Shutting down Keep-Alive thread
2024-12-28 11:11:28,950 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 11:12:23,836 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 11:12:24,421 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 11:12:24,459 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 11:12:24,462 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 11:12:24,638 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 11:12:25,153 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 11:12:25,703 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 11:12:26,086 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 11:12:26,489 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 11:12:26,489 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 11:12:26,494 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 11:12:26,501 - INFO - [pid 49988] Worker Worker(salt=7863334077, workers=1, host=Nanas.local, username=fajarianatm, pid=49988) done      Extract()
2024-12-28 11:12:26,502 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 11:12:26,504 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 11:12:26,504 - DEBUG - Asking scheduler for work...
2024-12-28 11:12:26,505 - DEBUG - Pending tasks: 2
2024-12-28 11:12:26,505 - INFO - [pid 49988] Worker Worker(salt=7863334077, workers=1, host=Nanas.local, username=fajarianatm, pid=49988) running   Load()
2024-12-28 11:12:26,507 - INFO - Read Load Query - SUCCESS
2024-12-28 11:12:27,161 - INFO - Read Extracted Data - SUCCESS
2024-12-28 11:12:27,162 - INFO - Connect to DWH - SUCCESS
2024-12-28 11:12:27,281 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 11:12:27,281 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 11:12:29,100 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 11:12:29,141 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 11:12:29,145 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 11:12:30,188 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 11:12:33,075 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 11:12:37,396 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 11:12:40,029 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 11:12:42,673 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 11:12:42,673 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 11:18:03,600 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2024-12-28 11:18:03,658 - ERROR - LOAD All Tables To DWH - FAILED
2024-12-28 11:18:03,661 - ERROR - [pid 49988] Worker Worker(salt=7863334077, workers=1, host=Nanas.local, username=fajarianatm, pid=49988) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: record "old" has no field "seller_zip_code"
CONTEXT:  SQL expression "(
        NEW.seller_zip_code_prefix IS DISTINCT FROM OLD.seller_zip_code OR
        NEW.seller_city IS DISTINCT FROM OLD.seller_city OR
        NEW.seller_state IS DISTINCT FROM OLD.seller_state
    )"
PL/pgSQL function final.update_dim_sellers() line 4 at IF


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 247, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) record "old" has no field "seller_zip_code"
CONTEXT:  SQL expression "(
        NEW.seller_zip_code_prefix IS DISTINCT FROM OLD.seller_zip_code OR
        NEW.seller_city IS DISTINCT FROM OLD.seller_city OR
        NEW.seller_state IS DISTINCT FROM OLD.seller_state
    )"
PL/pgSQL function final.update_dim_sellers() line 4 at IF

[SQL: INSERT INTO stg.sellers
    (seller_id, seller_zip_code_prefix, seller_city, seller_state)

SELECT
    seller_id,
    seller_zip_code_prefix,
    seller_city,
    seller_state
FROM src.sellers

ON CONFLICT(seller_id)
DO UPDATE SET
    seller_zip_code_prefix = EXCLUDED.seller_zip_code_prefix,
    seller_city = EXCLUDED.seller_city,
    seller_state = EXCLUDED.seller_state,
    updated_at = CASE 
                    WHEN stg.sellers.seller_zip_code_prefix <> EXCLUDED.seller_zip_code_prefix
                        OR stg.sellers.seller_city <> EXCLUDED.seller_city
                        OR stg.sellers.seller_state <> EXCLUDED.seller_state
                    THEN CURRENT_TIMESTAMP
                    ELSE stg.sellers.updated_at
                 END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 258, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 297, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-12-28 11:18:03,684 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 11:18:03,692 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-28 11:18:03,692 - DEBUG - Asking scheduler for work...
2024-12-28 11:18:03,693 - DEBUG - Done
2024-12-28 11:18:03,694 - DEBUG - There are no more tasks to run at this time
2024-12-28 11:18:03,694 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-28 11:18:03,694 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-28 11:18:03,694 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-28 11:18:03,694 - INFO - Worker Worker(salt=7863334077, workers=1, host=Nanas.local, username=fajarianatm, pid=49988) was stopped. Shutting down Keep-Alive thread
2024-12-28 11:18:03,695 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 11:21:57,541 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 11:21:57,970 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 11:21:58,020 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 11:21:58,025 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 11:21:58,209 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 11:21:58,678 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 11:21:59,242 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 11:21:59,594 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 11:21:59,994 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 11:21:59,994 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 11:21:59,997 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 11:22:00,005 - INFO - [pid 54307] Worker Worker(salt=8354822478, workers=1, host=Nanas.local, username=fajarianatm, pid=54307) done      Extract()
2024-12-28 11:22:00,005 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 11:22:00,008 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 11:22:00,008 - DEBUG - Asking scheduler for work...
2024-12-28 11:22:00,010 - DEBUG - Pending tasks: 2
2024-12-28 11:22:00,010 - INFO - [pid 54307] Worker Worker(salt=8354822478, workers=1, host=Nanas.local, username=fajarianatm, pid=54307) running   Load()
2024-12-28 11:22:00,012 - INFO - Read Load Query - SUCCESS
2024-12-28 11:22:00,669 - INFO - Read Extracted Data - SUCCESS
2024-12-28 11:22:00,670 - INFO - Connect to DWH - SUCCESS
2024-12-28 11:22:00,744 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 11:22:00,744 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 11:22:02,643 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 11:22:02,733 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 11:22:02,736 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 11:22:03,773 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 11:22:06,671 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 11:22:10,543 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 11:22:12,748 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 11:22:15,139 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 11:22:15,139 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 11:22:22,988 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-28 11:22:23,031 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-28 11:22:23,082 - INFO - [pid 54307] Worker Worker(salt=8354822478, workers=1, host=Nanas.local, username=fajarianatm, pid=54307) done      Load()
2024-12-28 11:22:23,083 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 11:22:23,086 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-28 11:22:23,086 - DEBUG - Asking scheduler for work...
2024-12-28 11:22:23,087 - DEBUG - Pending tasks: 1
2024-12-28 11:22:23,088 - INFO - [pid 54307] Worker Worker(salt=8354822478, workers=1, host=Nanas.local, username=fajarianatm, pid=54307) running   Transform()
2024-12-28 11:22:23,092 - INFO - Read Transform Query - SUCCESS
2024-12-28 11:22:23,093 - INFO - Connect to DWH - SUCCESS
2024-12-28 11:22:23,093 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-28 11:22:23,917 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-28 11:22:23,931 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-28 11:22:24,151 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-28 11:22:24,532 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-28 11:22:26,322 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-28 11:22:26,369 - ERROR - Transform Tables - FAILED
2024-12-28 11:22:26,373 - ERROR - [pid 54307] Worker Worker(salt=8354822478, workers=1, host=Nanas.local, username=fajarianatm, pid=54307) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "payment_sequential" of relation "fct_reviews" violates not-null constraint
DETAIL:  Failing row contains (ce7dc99e-047d-41e3-b9e5-049646c3f5e0, 6916ca4502d6d3bfd39818759d55d536, bfbd0f9bdef84302105ad712db648a6c, 5b47e2aa-cc0f-48ea-b0a6-507ee65bfec1, negative, null, null, null, null, 1, null, nao recebi o produto e nem resposta da empresa, 2016-10-07 18:32:28, 2024-12-28 04:22:24.158547, 2024-12-28 04:22:24.158547).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 124, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "payment_sequential" of relation "fct_reviews" violates not-null constraint
DETAIL:  Failing row contains (ce7dc99e-047d-41e3-b9e5-049646c3f5e0, 6916ca4502d6d3bfd39818759d55d536, bfbd0f9bdef84302105ad712db648a6c, 5b47e2aa-cc0f-48ea-b0a6-507ee65bfec1, negative, null, null, null, null, 1, null, nao recebi o produto e nem resposta da empresa, 2016-10-07 18:32:28, 2024-12-28 04:22:24.158547, 2024-12-28 04:22:24.158547).

[SQL: WITH ranked_payments AS (
    SELECT 
        op.order_id,
        op.payment_sequential,
        op.payment_type,
        op.payment_installments,
        op.payment_value,
        ROW_NUMBER() OVER (PARTITION BY op.order_id ORDER BY op.payment_sequential ASC) AS rn
    FROM stg.order_payments op
),
filtered_payments AS (
    SELECT
        rp.order_id,
        COALESCE(rp.payment_sequential, 0) AS payment_sequential, -- Nilai default
        COALESCE(rp.payment_type, 'unknown') AS payment_type,     -- Sesuaikan nilai default
        COALESCE(rp.payment_installments, 0) AS payment_installments,
        COALESCE(rp.payment_value, 0.0) AS payment_value
    FROM ranked_payments rp
    WHERE rp.rn = 1 -- Ambil baris pertama untuk setiap order_id
),
stg_fct_reviews AS (
    SELECT 
        orw.review_id AS review_nk,
        orw.order_id AS order_nk,
        fdc.customer_id AS customer_id,
        CASE
            WHEN orw.review_score BETWEEN 1 AND 2 THEN 'negative'
            WHEN orw.review_score = 3 THEN 'neutral'
            WHEN orw.review_score BETWEEN 4 AND 5 THEN 'positive'
            ELSE 'unknown'
        END AS sentiment,
        fp.payment_sequential,
        fp.payment_type,
        fp.payment_installments,
        fp.payment_value,
        orw.review_score,
        orw.review_comment_title,
        orw.review_comment_message,
        orw.review_creation_date
    FROM stg.order_reviews orw
    JOIN stg.orders so
        ON so.order_id = orw.order_id
    LEFT JOIN filtered_payments fp
        ON fp.order_id = so.order_id
    LEFT JOIN final.dim_customers fdc
        ON fdc.customer_nk = so.customer_id
)
INSERT INTO final.fct_reviews (
    review_nk,
    order_nk,
    customer_id,
    sentiment,
    payment_sequential,
    payment_type,
    payment_installments,
    payment_value,
    review_score,
    review_comment_title,
    review_comment_message,
    review_creation_date
)
SELECT *
FROM stg_fct_reviews
ON CONFLICT (review_nk, order_nk)
DO UPDATE SET
    customer_id = EXCLUDED.customer_id,
    sentiment = EXCLUDED.sentiment,
    payment_sequential = EXCLUDED.payment_sequential,
    payment_type = EXCLUDED.payment_type,
    payment_installments = EXCLUDED.payment_installments,
    payment_value = EXCLUDED.payment_value,
    review_score = EXCLUDED.review_score,
    review_comment_title = EXCLUDED.review_comment_title,
    review_comment_message = EXCLUDED.review_comment_message,
    review_creation_date = EXCLUDED.review_creation_date,
    updated_at = CASE 
                    WHEN final.fct_reviews.customer_id <> EXCLUDED.customer_id
                        OR final.fct_reviews.sentiment <> EXCLUDED.sentiment
                        OR final.fct_reviews.payment_sequential <> EXCLUDED.payment_sequential
                        OR final.fct_reviews.payment_type <> EXCLUDED.payment_type
                        OR final.fct_reviews.payment_installments <> EXCLUDED.payment_installments
                        OR final.fct_reviews.payment_value <> EXCLUDED.payment_value
                        OR final.fct_reviews.review_score <> EXCLUDED.review_score
                        OR final.fct_reviews.review_comment_title <> EXCLUDED.review_comment_title
                        OR final.fct_reviews.review_comment_message <> EXCLUDED.review_comment_message
                        OR final.fct_reviews.review_creation_date <> EXCLUDED.review_creation_date
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_reviews.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-28 11:22:26,400 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 11:22:26,418 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-28 11:22:26,419 - DEBUG - Asking scheduler for work...
2024-12-28 11:22:26,456 - DEBUG - Done
2024-12-28 11:22:26,456 - DEBUG - There are no more tasks to run at this time
2024-12-28 11:22:26,456 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-28 11:22:26,456 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-28 11:22:26,456 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-28 11:22:26,457 - INFO - Worker Worker(salt=8354822478, workers=1, host=Nanas.local, username=fajarianatm, pid=54307) was stopped. Shutting down Keep-Alive thread
2024-12-28 11:22:26,459 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 14:28:11,429 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 14:28:11,994 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 14:28:12,038 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 14:28:12,043 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 14:28:12,224 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 14:28:12,781 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 14:28:13,353 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 14:28:13,704 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 14:28:14,116 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 14:28:14,116 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 14:28:14,121 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 14:28:14,130 - INFO - [pid 66349] Worker Worker(salt=7049654786, workers=1, host=Nanas.local, username=fajarianatm, pid=66349) done      Extract()
2024-12-28 14:28:14,130 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 14:28:14,133 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 14:28:14,133 - DEBUG - Asking scheduler for work...
2024-12-28 14:28:14,134 - DEBUG - Pending tasks: 2
2024-12-28 14:28:14,134 - INFO - [pid 66349] Worker Worker(salt=7049654786, workers=1, host=Nanas.local, username=fajarianatm, pid=66349) running   Load()
2024-12-28 14:28:14,137 - INFO - Read Load Query - SUCCESS
2024-12-28 14:28:14,801 - INFO - Read Extracted Data - SUCCESS
2024-12-28 14:28:14,802 - INFO - Connect to DWH - SUCCESS
2024-12-28 14:28:14,883 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 14:28:14,883 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 14:28:16,717 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 14:28:16,824 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 14:28:16,827 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 14:28:17,883 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 14:28:20,880 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 14:28:25,050 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 14:28:27,396 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 14:28:29,994 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 14:28:29,994 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 14:28:37,741 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-28 14:28:37,750 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-28 14:28:37,794 - INFO - [pid 66349] Worker Worker(salt=7049654786, workers=1, host=Nanas.local, username=fajarianatm, pid=66349) done      Load()
2024-12-28 14:28:37,795 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 14:28:37,798 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-28 14:28:37,798 - DEBUG - Asking scheduler for work...
2024-12-28 14:28:37,799 - DEBUG - Pending tasks: 1
2024-12-28 14:28:37,799 - INFO - [pid 66349] Worker Worker(salt=7049654786, workers=1, host=Nanas.local, username=fajarianatm, pid=66349) running   Transform()
2024-12-28 14:28:37,802 - INFO - Read Transform Query - SUCCESS
2024-12-28 14:28:37,803 - INFO - Connect to DWH - SUCCESS
2024-12-28 14:28:37,803 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-28 14:28:38,513 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-28 14:28:38,529 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-28 14:28:38,694 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-28 14:28:39,050 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-28 14:28:41,901 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-28 14:28:41,906 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-28 14:28:41,951 - ERROR - Transform Tables - FAILED
2024-12-28 14:28:41,954 - ERROR - [pid 66349] Worker Worker(salt=7049654786, workers=1, host=Nanas.local, username=fajarianatm, pid=66349) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: missing FROM-clause entry for table "cps"
LINE 44: ...       JOIN final.dim_date dd ON dd.date_actual = cps.order_...
                                                              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) missing FROM-clause entry for table "cps"
LINE 44: ...       JOIN final.dim_date dd ON dd.date_actual = cps.order_...
                                                              ^

[SQL: -- stg.orders, stg.order_items, final.dim_products, final.dim_sellers
WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.product_id,
            COUNT(soi.product_id) AS sales_quantity
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1,2
    ),

    final_fct_sales_daily AS (
        SELECT
            soi.order_id AS order_nk,
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            (cps.sales_quantity * soi.price) AS sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        JOIN final.dim_date dd ON dd.date_actual = cps.order_date
        JOIN final.dim_products dp ON dp.product_id = soi.product_id
        JOIN final.dim_sellers ds ON ds.seller_id = soi.seller_id
        JOIN cnt_product_sales cps ON cps.product_id = dp.product_id
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)

SELECT *
FROM final_fct_sales_daily

ON CONFLICT(order_nk, date_id)
DO UPDATE SET
    product_id = EXCLUDED.product_id,
    seller_id = EXCLUDED.seller_id,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.product_id <> EXCLUDED.product_id
                        OR final.fct_sales_daily.seller_id <> EXCLUDED.seller_id
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-28 14:28:41,974 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 14:28:41,982 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-28 14:28:41,982 - DEBUG - Asking scheduler for work...
2024-12-28 14:28:41,983 - DEBUG - Done
2024-12-28 14:28:41,983 - DEBUG - There are no more tasks to run at this time
2024-12-28 14:28:41,983 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-28 14:28:41,983 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-28 14:28:41,983 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-28 14:28:41,984 - INFO - Worker Worker(salt=7049654786, workers=1, host=Nanas.local, username=fajarianatm, pid=66349) was stopped. Shutting down Keep-Alive thread
2024-12-28 14:28:41,984 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 14:35:14,429 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 14:35:14,884 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 14:35:14,923 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 14:35:14,927 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 14:35:15,109 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 14:35:15,604 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 14:35:16,164 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 14:35:16,509 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 14:35:16,907 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 14:35:16,907 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 14:35:16,911 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 14:35:16,919 - INFO - [pid 69311] Worker Worker(salt=7248157622, workers=1, host=Nanas.local, username=fajarianatm, pid=69311) done      Extract()
2024-12-28 14:35:16,920 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 14:35:16,922 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 14:35:16,922 - DEBUG - Asking scheduler for work...
2024-12-28 14:35:16,923 - DEBUG - Pending tasks: 2
2024-12-28 14:35:16,923 - INFO - [pid 69311] Worker Worker(salt=7248157622, workers=1, host=Nanas.local, username=fajarianatm, pid=69311) running   Load()
2024-12-28 14:35:16,925 - INFO - Read Load Query - SUCCESS
2024-12-28 14:35:17,605 - INFO - Read Extracted Data - SUCCESS
2024-12-28 14:35:17,605 - INFO - Connect to DWH - SUCCESS
2024-12-28 14:35:17,705 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 14:35:17,705 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 14:35:19,489 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 14:35:19,529 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 14:35:19,532 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 14:35:20,591 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 14:35:23,474 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 14:35:27,593 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 14:35:30,120 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 14:35:33,031 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 14:35:33,032 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-28 14:47:08,181 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-28 14:47:08,229 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-28 14:47:08,309 - INFO - [pid 69311] Worker Worker(salt=7248157622, workers=1, host=Nanas.local, username=fajarianatm, pid=69311) done      Load()
2024-12-28 14:47:08,312 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 14:47:08,316 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-28 14:47:08,316 - DEBUG - Asking scheduler for work...
2024-12-28 14:47:08,318 - DEBUG - Pending tasks: 1
2024-12-28 14:47:08,318 - INFO - [pid 69311] Worker Worker(salt=7248157622, workers=1, host=Nanas.local, username=fajarianatm, pid=69311) running   Transform()
2024-12-28 14:47:08,321 - INFO - Read Transform Query - SUCCESS
2024-12-28 14:47:08,323 - INFO - Connect to DWH - SUCCESS
2024-12-28 14:47:08,323 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-28 14:47:08,525 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-28 14:47:08,587 - ERROR - Transform Tables - FAILED
2024-12-28 14:47:08,590 - ERROR - [pid 69311] Worker Worker(salt=7248157622, workers=1, host=Nanas.local, username=fajarianatm, pid=69311) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id, version_id)=(9ee11893-7962-4599-829d-ea2b7ba31434, 1) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id, version_id)=(9ee11893-7962-4599-829d-ea2b7ba31434, 1) already exists.

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code_prefix AS customer_zip_code,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,  
    NULL AS expired_at,
    1 AS version_id  
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Periksa apakah customer_nk sudah ada sebagai data aktif
    IF NOT EXISTS (
        SELECT 1
        FROM final.dim_customers
        WHERE customer_nk = NEW.customer_id
          AND current_flag = 'current'
    ) THEN
        -- Jika customer_nk belum ada, lakukan insert
        INSERT INTO final.dim_customers (
            customer_id,
            customer_nk,
            customer_zip_code,
            customer_city,
            customer_state,
            current_flag,
            created_at,
            expired_at,
            version_id
        )
        VALUES (
            NEW.id,
            NEW.customer_id,
            NEW.customer_zip_code_prefix,
            NEW.customer_city,
            NEW.customer_state,
            'current', -- Tandai sebagai data aktif
            NOW(),
            NULL,
            1
        );
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Masukkan data baru jika customer_nk belum ada dengan current_flag = 'current'

    INSERT INTO final.dim_customers (
    customer_id, customer_nk, customer_zip_code, customer_city, customer_state, 
    current_flag, created_at, version_id
    )
    SELECT 
        NEW.id AS customer_id, 
        NEW.customer_id AS customer_nk, 
        NEW.customer_zip_code_prefix AS customer_zip_code, 
        NEW.customer_city, 
        NEW.customer_state, 
        'current' AS current_flag, 
        NOW() AS created_at,
        COALESCE((
            SELECT MAX(version_id) 
            FROM final.dim_customers 
            WHERE customer_id = NEW.id
        ), 0) + 1 AS version_id
    FROM final.dim_customers
    WHERE NOT EXISTS (
        SELECT 1 
        FROM final.dim_customers 
        WHERE customer_nk = NEW.customer_id 
        AND current_flag = 'current'
    );

    -- Update data lama menjadi expired jika ada perubahan pada kolom yang relevan
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM OLD.customer_zip_code_prefix OR
            NEW.customer_city IS DISTINCT FROM OLD.customer_city OR
            NEW.customer_state IS DISTINCT FROM OLD.customer_state
        );

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-28 14:47:08,612 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 14:47:08,618 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-28 14:47:08,619 - DEBUG - Asking scheduler for work...
2024-12-28 14:47:08,620 - DEBUG - Done
2024-12-28 14:47:08,620 - DEBUG - There are no more tasks to run at this time
2024-12-28 14:47:08,620 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-28 14:47:08,621 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-28 14:47:08,621 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-28 14:47:08,621 - INFO - Worker Worker(salt=7248157622, workers=1, host=Nanas.local, username=fajarianatm, pid=69311) was stopped. Shutting down Keep-Alive thread
2024-12-28 14:47:08,622 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-28 23:46:04,964 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-28 23:46:05,461 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-28 23:46:05,503 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-28 23:46:05,507 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-28 23:46:05,692 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-28 23:46:06,275 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-28 23:46:06,896 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-28 23:46:07,254 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-28 23:46:07,695 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-28 23:46:07,695 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-28 23:46:07,697 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-28 23:46:07,704 - INFO - [pid 24395] Worker Worker(salt=3113413389, workers=1, host=192.168.0.105, username=fajarianatm, pid=24395) done      Extract()
2024-12-28 23:46:07,704 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-28 23:46:07,707 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-28 23:46:07,707 - DEBUG - Asking scheduler for work...
2024-12-28 23:46:07,708 - DEBUG - Pending tasks: 2
2024-12-28 23:46:07,708 - INFO - [pid 24395] Worker Worker(salt=3113413389, workers=1, host=192.168.0.105, username=fajarianatm, pid=24395) running   Load()
2024-12-28 23:46:07,710 - INFO - Read Load Query - SUCCESS
2024-12-28 23:46:08,349 - INFO - Read Extracted Data - SUCCESS
2024-12-28 23:46:08,349 - INFO - Connect to DWH - SUCCESS
2024-12-28 23:46:08,504 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-28 23:46:08,504 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-28 23:46:10,553 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-28 23:46:10,598 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-28 23:46:10,601 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-28 23:46:11,719 - INFO - LOAD 'src.products' - SUCCESS
2024-12-28 23:46:14,592 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-28 23:46:18,701 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-28 23:46:21,081 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-28 23:46:23,684 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-28 23:46:23,684 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 00:43:50,498 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 00:43:50,524 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 00:43:50,578 - INFO - [pid 24395] Worker Worker(salt=3113413389, workers=1, host=192.168.0.105, username=fajarianatm, pid=24395) done      Load()
2024-12-29 00:43:50,579 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 00:43:50,582 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 00:43:50,582 - DEBUG - Asking scheduler for work...
2024-12-29 00:43:50,583 - DEBUG - Pending tasks: 1
2024-12-29 00:43:50,583 - INFO - [pid 24395] Worker Worker(salt=3113413389, workers=1, host=192.168.0.105, username=fajarianatm, pid=24395) running   Transform()
2024-12-29 00:43:50,586 - INFO - Read Transform Query - SUCCESS
2024-12-29 00:43:50,586 - INFO - Connect to DWH - SUCCESS
2024-12-29 00:43:50,587 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 00:43:50,618 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-29 00:43:50,651 - ERROR - Transform Tables - FAILED
2024-12-29 00:43:50,653 - ERROR - [pid 24395] Worker Worker(salt=3113413389, workers=1, host=192.168.0.105, username=fajarianatm, pid=24395) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id, version_id)=(bba61078-9ebb-4db4-99f3-f088c37cbecf, 1) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dim_customers_pkey"
DETAIL:  Key (customer_id, version_id)=(bba61078-9ebb-4db4-99f3-f088c37cbecf, 1) already exists.

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    c.id AS customer_id,
    c.customer_id AS customer_nk,
    c.customer_zip_code_prefix AS customer_zip_code,
    c.customer_city,
    c.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,  
    NULL AS expired_at,
    1 AS version_id  
FROM stg.customers c;

-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        COALESCE((
            SELECT MAX(version_id)
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ), 0) + 1 -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-29 00:43:50,670 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 00:43:50,677 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-29 00:43:50,677 - DEBUG - Asking scheduler for work...
2024-12-29 00:43:50,679 - DEBUG - Done
2024-12-29 00:43:50,679 - DEBUG - There are no more tasks to run at this time
2024-12-29 00:43:50,679 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-29 00:43:50,679 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-29 00:43:50,679 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-29 00:43:50,679 - INFO - Worker Worker(salt=3113413389, workers=1, host=192.168.0.105, username=fajarianatm, pid=24395) was stopped. Shutting down Keep-Alive thread
2024-12-29 00:43:50,680 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-29 09:28:39,177 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-29 09:28:39,783 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-29 09:28:39,817 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-29 09:28:39,820 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-29 09:28:39,979 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-29 09:28:40,619 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-29 09:28:41,169 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-29 09:28:41,544 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-29 09:28:41,948 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-29 09:28:41,948 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-29 09:28:41,953 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-29 09:28:41,960 - INFO - [pid 43007] Worker Worker(salt=3070293744, workers=1, host=192.168.0.105, username=fajarianatm, pid=43007) done      Extract()
2024-12-29 09:28:41,961 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 09:28:41,964 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-29 09:28:41,964 - DEBUG - Asking scheduler for work...
2024-12-29 09:28:41,965 - DEBUG - Pending tasks: 2
2024-12-29 09:28:41,965 - INFO - [pid 43007] Worker Worker(salt=3070293744, workers=1, host=192.168.0.105, username=fajarianatm, pid=43007) running   Load()
2024-12-29 09:28:41,967 - INFO - Read Load Query - SUCCESS
2024-12-29 09:28:42,637 - INFO - Read Extracted Data - SUCCESS
2024-12-29 09:28:42,638 - INFO - Connect to DWH - SUCCESS
2024-12-29 09:28:42,733 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-29 09:28:42,733 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-29 09:28:44,544 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-29 09:28:44,645 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-29 09:28:44,649 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-29 09:28:45,682 - INFO - LOAD 'src.products' - SUCCESS
2024-12-29 09:28:48,686 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-29 09:28:52,759 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-29 09:28:54,999 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-29 09:28:57,390 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-29 09:28:57,390 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 09:29:04,749 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 09:29:04,769 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 09:29:04,823 - INFO - [pid 43007] Worker Worker(salt=3070293744, workers=1, host=192.168.0.105, username=fajarianatm, pid=43007) done      Load()
2024-12-29 09:29:04,824 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 09:29:04,827 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 09:29:04,827 - DEBUG - Asking scheduler for work...
2024-12-29 09:29:04,828 - DEBUG - Pending tasks: 1
2024-12-29 09:29:04,829 - INFO - [pid 43007] Worker Worker(salt=3070293744, workers=1, host=192.168.0.105, username=fajarianatm, pid=43007) running   Transform()
2024-12-29 09:29:04,830 - INFO - Read Transform Query - SUCCESS
2024-12-29 09:29:04,831 - INFO - Connect to DWH - SUCCESS
2024-12-29 09:29:04,831 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 09:29:05,782 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-29 09:29:05,819 - ERROR - Transform Tables - FAILED
2024-12-29 09:29:05,822 - ERROR - [pid 43007] Worker Worker(salt=3070293744, workers=1, host=192.168.0.105, username=fajarianatm, pid=43007) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: function final.update_dim_customers() does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) function final.update_dim_customers() does not exist

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
-- Filter data staging untuk validasi
WITH valid_customers AS (
    SELECT
        c.id AS customer_id,
        c.customer_id AS customer_nk,
        c.customer_zip_code_prefix AS customer_zip_code,
        c.customer_city,
        c.customer_state
    FROM stg.customers c
    LEFT JOIN final.dim_customers d
        ON c.id = d.customer_id
        AND d.current_flag = 'current'
    WHERE d.customer_id IS NULL -- Pelanggan baru
       OR (
           c.customer_zip_code_prefix IS DISTINCT FROM d.customer_zip_code
           OR c.customer_city IS DISTINCT FROM d.customer_city
           OR c.customer_state IS DISTINCT FROM d.customer_state
       )
)
-- Insert valid data into dim_customers
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vc.customer_id,
    vc.customer_nk,
    vc.customer_zip_code,
    vc.customer_city,
    vc.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,
    NULL AS expired_at,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_customers d
        WHERE d.customer_id = vc.customer_id
    ), 0) + 1 AS version_id
FROM valid_customers vc;


-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ) -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;



-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-29 09:29:05,844 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 09:29:05,849 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-29 09:29:05,849 - DEBUG - Asking scheduler for work...
2024-12-29 09:29:05,851 - DEBUG - Done
2024-12-29 09:29:05,851 - DEBUG - There are no more tasks to run at this time
2024-12-29 09:29:05,851 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-29 09:29:05,851 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-29 09:29:05,851 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-29 09:29:05,851 - INFO - Worker Worker(salt=3070293744, workers=1, host=192.168.0.105, username=fajarianatm, pid=43007) was stopped. Shutting down Keep-Alive thread
2024-12-29 09:29:05,852 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-29 09:32:28,065 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-29 09:32:28,523 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-29 09:32:28,563 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-29 09:32:28,567 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-29 09:32:28,753 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-29 09:32:29,299 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-29 09:32:29,895 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-29 09:32:30,256 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-29 09:32:30,699 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-29 09:32:30,699 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-29 09:32:30,704 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-29 09:32:30,711 - INFO - [pid 44618] Worker Worker(salt=6266329511, workers=1, host=192.168.0.105, username=fajarianatm, pid=44618) done      Extract()
2024-12-29 09:32:30,711 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 09:32:30,713 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-29 09:32:30,714 - DEBUG - Asking scheduler for work...
2024-12-29 09:32:30,715 - DEBUG - Pending tasks: 2
2024-12-29 09:32:30,717 - INFO - [pid 44618] Worker Worker(salt=6266329511, workers=1, host=192.168.0.105, username=fajarianatm, pid=44618) running   Load()
2024-12-29 09:32:30,720 - INFO - Read Load Query - SUCCESS
2024-12-29 09:32:31,369 - INFO - Read Extracted Data - SUCCESS
2024-12-29 09:32:31,370 - INFO - Connect to DWH - SUCCESS
2024-12-29 09:32:31,459 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-29 09:32:31,459 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-29 09:32:33,309 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-29 09:32:33,346 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-29 09:32:33,349 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-29 09:32:34,367 - INFO - LOAD 'src.products' - SUCCESS
2024-12-29 09:32:37,136 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-29 09:32:41,290 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-29 09:32:43,641 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-29 09:32:46,173 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-29 09:32:46,173 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 09:32:54,226 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 09:32:54,248 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 09:32:54,304 - INFO - [pid 44618] Worker Worker(salt=6266329511, workers=1, host=192.168.0.105, username=fajarianatm, pid=44618) done      Load()
2024-12-29 09:32:54,305 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 09:32:54,308 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 09:32:54,308 - DEBUG - Asking scheduler for work...
2024-12-29 09:32:54,310 - DEBUG - Pending tasks: 1
2024-12-29 09:32:54,310 - INFO - [pid 44618] Worker Worker(salt=6266329511, workers=1, host=192.168.0.105, username=fajarianatm, pid=44618) running   Transform()
2024-12-29 09:32:54,312 - INFO - Read Transform Query - SUCCESS
2024-12-29 09:32:54,313 - INFO - Connect to DWH - SUCCESS
2024-12-29 09:32:54,313 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 09:33:46,424 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-29 09:33:46,440 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-29 09:33:46,551 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-29 09:33:46,559 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-29 09:33:48,356 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-29 09:33:48,360 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-29 09:33:48,426 - ERROR - Transform Tables - FAILED
2024-12-29 09:33:48,429 - ERROR - [pid 44618] Worker Worker(salt=6266329511, workers=1, host=192.168.0.105, username=fajarianatm, pid=44618) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: operator does not exist: uuid = text
LINE 44: ...      JOIN final.dim_products dp ON dp.product_id = soi.prod...
                                                              ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: uuid = text
LINE 44: ...      JOIN final.dim_products dp ON dp.product_id = soi.prod...
                                                              ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.product_id,
            COUNT(soi.product_id) AS sales_quantity
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1,2
    ),

    final_fct_sales_daily AS (
        SELECT
            soi.order_id AS order_nk,
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            (cps.sales_quantity * soi.price) AS sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        JOIN final.dim_date dd ON dd.date_actual = DATE(so.order_purchase_timestamp)  -- Menggunakan order_purchase_timestamp yang sudah didefinisikan
        JOIN final.dim_products dp ON dp.product_id = soi.product_id
        JOIN final.dim_sellers ds ON ds.seller_id = soi.seller_id
        JOIN cnt_product_sales cps ON cps.product_id = dp.product_id AND cps.order_date = dd.date_actual  -- Penyesuaian join dengan order_date
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)

SELECT *
FROM final_fct_sales_daily

ON CONFLICT(order_nk, date_id)
DO UPDATE SET
    product_id = EXCLUDED.product_id,
    seller_id = EXCLUDED.seller_id,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.product_id <> EXCLUDED.product_id
                        OR final.fct_sales_daily.seller_id <> EXCLUDED.seller_id
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-29 09:33:48,459 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 09:33:48,476 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-29 09:33:48,477 - DEBUG - Asking scheduler for work...
2024-12-29 09:33:48,478 - DEBUG - Done
2024-12-29 09:33:48,478 - DEBUG - There are no more tasks to run at this time
2024-12-29 09:33:48,478 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-29 09:33:48,478 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-29 09:33:48,478 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-29 09:33:48,478 - INFO - Worker Worker(salt=6266329511, workers=1, host=192.168.0.105, username=fajarianatm, pid=44618) was stopped. Shutting down Keep-Alive thread
2024-12-29 09:33:48,479 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-29 09:37:29,616 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-29 09:37:30,070 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-29 09:37:30,109 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-29 09:37:30,114 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-29 09:37:30,296 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-29 09:37:30,827 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-29 09:37:31,385 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-29 09:37:31,743 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-29 09:37:32,160 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-29 09:37:32,161 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-29 09:37:32,164 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-29 09:37:32,173 - INFO - [pid 46716] Worker Worker(salt=1904888476, workers=1, host=192.168.0.105, username=fajarianatm, pid=46716) done      Extract()
2024-12-29 09:37:32,173 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 09:37:32,176 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-29 09:37:32,176 - DEBUG - Asking scheduler for work...
2024-12-29 09:37:32,177 - DEBUG - Pending tasks: 2
2024-12-29 09:37:32,177 - INFO - [pid 46716] Worker Worker(salt=1904888476, workers=1, host=192.168.0.105, username=fajarianatm, pid=46716) running   Load()
2024-12-29 09:37:32,180 - INFO - Read Load Query - SUCCESS
2024-12-29 09:37:32,867 - INFO - Read Extracted Data - SUCCESS
2024-12-29 09:37:32,868 - INFO - Connect to DWH - SUCCESS
2024-12-29 09:37:32,982 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-29 09:37:32,982 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-29 09:37:34,908 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-29 09:37:34,954 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-29 09:37:34,958 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-29 09:37:36,043 - INFO - LOAD 'src.products' - SUCCESS
2024-12-29 09:37:38,993 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-29 09:37:42,938 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-29 09:37:45,121 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-29 09:37:47,451 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-29 09:37:47,451 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 10:00:34,786 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 10:00:34,814 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 10:00:34,876 - INFO - [pid 46716] Worker Worker(salt=1904888476, workers=1, host=192.168.0.105, username=fajarianatm, pid=46716) done      Load()
2024-12-29 10:00:34,877 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:00:34,880 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 10:00:34,880 - DEBUG - Asking scheduler for work...
2024-12-29 10:00:34,882 - DEBUG - Pending tasks: 1
2024-12-29 10:00:34,882 - INFO - [pid 46716] Worker Worker(salt=1904888476, workers=1, host=192.168.0.105, username=fajarianatm, pid=46716) running   Transform()
2024-12-29 10:00:34,884 - INFO - Read Transform Query - SUCCESS
2024-12-29 10:00:34,885 - INFO - Connect to DWH - SUCCESS
2024-12-29 10:00:34,885 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 10:00:35,480 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-29 10:00:35,517 - ERROR - Transform Tables - FAILED
2024-12-29 10:00:35,520 - ERROR - [pid 46716] Worker Worker(salt=1904888476, workers=1, host=192.168.0.105, username=fajarianatm, pid=46716) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DuplicateObject: trigger "customer_insert_trigger" for relation "customers" already exists


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateObject) trigger "customer_insert_trigger" for relation "customers" already exists

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
-- Filter data staging untuk validasi
WITH valid_customers AS (
    SELECT
        c.id AS customer_id,
        c.customer_id AS customer_nk,
        c.customer_zip_code_prefix AS customer_zip_code,
        c.customer_city,
        c.customer_state
    FROM stg.customers c
    LEFT JOIN final.dim_customers d
        ON c.id = d.customer_id
        AND d.current_flag = 'current'
    WHERE d.customer_id IS NULL -- Pelanggan baru
       OR (
           c.customer_zip_code_prefix IS DISTINCT FROM d.customer_zip_code
           OR c.customer_city IS DISTINCT FROM d.customer_city
           OR c.customer_state IS DISTINCT FROM d.customer_state
       )
)
-- Insert valid data into dim_customers
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vc.customer_id,
    vc.customer_nk,
    vc.customer_zip_code,
    vc.customer_city,
    vc.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,
    NULL AS expired_at,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_customers d
        WHERE d.customer_id = vc.customer_id
    ), 0) + 1 AS version_id
FROM valid_customers vc;


-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ) -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;



-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-29 10:00:35,539 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:00:35,543 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-29 10:00:35,543 - DEBUG - Asking scheduler for work...
2024-12-29 10:00:35,544 - DEBUG - Done
2024-12-29 10:00:35,545 - DEBUG - There are no more tasks to run at this time
2024-12-29 10:00:35,545 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-29 10:00:35,545 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-29 10:00:35,545 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-29 10:00:35,545 - INFO - Worker Worker(salt=1904888476, workers=1, host=192.168.0.105, username=fajarianatm, pid=46716) was stopped. Shutting down Keep-Alive thread
2024-12-29 10:00:35,545 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-29 10:08:15,234 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-29 10:08:15,687 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-29 10:08:15,722 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-29 10:08:15,726 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-29 10:08:15,908 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-29 10:08:16,415 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-29 10:08:16,996 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-29 10:08:17,349 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-29 10:08:17,762 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-29 10:08:17,763 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-29 10:08:17,765 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-29 10:08:17,773 - INFO - [pid 60074] Worker Worker(salt=8548484566, workers=1, host=192.168.0.105, username=fajarianatm, pid=60074) done      Extract()
2024-12-29 10:08:17,773 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:08:17,775 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-29 10:08:17,775 - DEBUG - Asking scheduler for work...
2024-12-29 10:08:17,777 - DEBUG - Pending tasks: 2
2024-12-29 10:08:17,777 - INFO - [pid 60074] Worker Worker(salt=8548484566, workers=1, host=192.168.0.105, username=fajarianatm, pid=60074) running   Load()
2024-12-29 10:08:17,779 - INFO - Read Load Query - SUCCESS
2024-12-29 10:08:18,490 - INFO - Read Extracted Data - SUCCESS
2024-12-29 10:08:18,492 - INFO - Connect to DWH - SUCCESS
2024-12-29 10:08:18,543 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-29 10:08:18,543 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-29 10:08:20,314 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-29 10:08:20,379 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-29 10:08:20,383 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-29 10:08:21,369 - INFO - LOAD 'src.products' - SUCCESS
2024-12-29 10:08:24,164 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-29 10:08:28,159 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-29 10:08:30,362 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-29 10:08:32,712 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-29 10:08:32,713 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 10:08:39,730 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 10:08:39,739 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 10:08:39,797 - INFO - [pid 60074] Worker Worker(salt=8548484566, workers=1, host=192.168.0.105, username=fajarianatm, pid=60074) done      Load()
2024-12-29 10:08:39,798 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:08:39,801 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 10:08:39,801 - DEBUG - Asking scheduler for work...
2024-12-29 10:08:39,803 - DEBUG - Pending tasks: 1
2024-12-29 10:08:39,803 - INFO - [pid 60074] Worker Worker(salt=8548484566, workers=1, host=192.168.0.105, username=fajarianatm, pid=60074) running   Transform()
2024-12-29 10:08:39,805 - INFO - Read Transform Query - SUCCESS
2024-12-29 10:08:39,806 - INFO - Connect to DWH - SUCCESS
2024-12-29 10:08:39,806 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 10:08:40,677 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-29 10:08:40,691 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-29 10:08:40,806 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-29 10:08:40,975 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-29 10:08:43,261 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-29 10:08:43,264 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-29 10:08:43,300 - ERROR - Transform Tables - FAILED
2024-12-29 10:08:43,303 - ERROR - [pid 60074] Worker Worker(salt=8548484566, workers=1, host=192.168.0.105, username=fajarianatm, pid=60074) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: operator does not exist: uuid = text
LINE 44: ...      JOIN final.dim_products dp ON dp.product_id = soi.prod...
                                                              ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: uuid = text
LINE 44: ...      JOIN final.dim_products dp ON dp.product_id = soi.prod...
                                                              ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.product_id,
            COUNT(soi.product_id) AS sales_quantity
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1,2
    ),

    final_fct_sales_daily AS (
        SELECT
            soi.order_id AS order_nk,
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            (cps.sales_quantity * soi.price) AS sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        JOIN final.dim_date dd ON dd.date_actual = DATE(so.order_purchase_timestamp)  -- Menggunakan order_purchase_timestamp yang sudah didefinisikan
        JOIN final.dim_products dp ON dp.product_id = soi.product_id
        JOIN final.dim_sellers ds ON ds.seller_id = soi.seller_id
        JOIN cnt_product_sales cps ON cps.product_id = dp.product_id AND cps.order_date = dd.date_actual  -- Penyesuaian join dengan order_date
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)

SELECT *
FROM final_fct_sales_daily

ON CONFLICT(order_nk, date_id)
DO UPDATE SET
    product_id = EXCLUDED.product_id,
    seller_id = EXCLUDED.seller_id,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.product_id <> EXCLUDED.product_id
                        OR final.fct_sales_daily.seller_id <> EXCLUDED.seller_id
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-29 10:08:43,327 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:08:43,332 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-29 10:08:43,332 - DEBUG - Asking scheduler for work...
2024-12-29 10:08:43,333 - DEBUG - Done
2024-12-29 10:08:43,333 - DEBUG - There are no more tasks to run at this time
2024-12-29 10:08:43,333 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-29 10:08:43,333 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-29 10:08:43,333 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-29 10:08:43,333 - INFO - Worker Worker(salt=8548484566, workers=1, host=192.168.0.105, username=fajarianatm, pid=60074) was stopped. Shutting down Keep-Alive thread
2024-12-29 10:08:43,334 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-29 10:11:19,441 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-29 10:11:19,870 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-29 10:11:19,912 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-29 10:11:19,915 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-29 10:11:20,094 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-29 10:11:20,570 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-29 10:11:21,115 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-29 10:11:21,460 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-29 10:11:21,858 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-29 10:11:21,858 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-29 10:11:21,864 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-29 10:11:21,871 - INFO - [pid 61374] Worker Worker(salt=8932275094, workers=1, host=192.168.0.105, username=fajarianatm, pid=61374) done      Extract()
2024-12-29 10:11:21,871 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:11:21,873 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-29 10:11:21,873 - DEBUG - Asking scheduler for work...
2024-12-29 10:11:21,874 - DEBUG - Pending tasks: 2
2024-12-29 10:11:21,874 - INFO - [pid 61374] Worker Worker(salt=8932275094, workers=1, host=192.168.0.105, username=fajarianatm, pid=61374) running   Load()
2024-12-29 10:11:21,877 - INFO - Read Load Query - SUCCESS
2024-12-29 10:11:22,529 - INFO - Read Extracted Data - SUCCESS
2024-12-29 10:11:22,529 - INFO - Connect to DWH - SUCCESS
2024-12-29 10:11:22,628 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-29 10:11:22,628 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-29 10:11:24,449 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-29 10:11:24,488 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-29 10:11:24,491 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-29 10:11:25,507 - INFO - LOAD 'src.products' - SUCCESS
2024-12-29 10:11:28,425 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-29 10:11:32,538 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-29 10:11:34,968 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-29 10:11:37,625 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-29 10:11:37,625 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 10:34:42,863 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 10:34:42,885 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 10:34:42,983 - INFO - [pid 61374] Worker Worker(salt=8932275094, workers=1, host=192.168.0.105, username=fajarianatm, pid=61374) done      Load()
2024-12-29 10:34:42,984 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:34:42,987 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 10:34:42,987 - DEBUG - Asking scheduler for work...
2024-12-29 10:34:42,989 - DEBUG - Pending tasks: 1
2024-12-29 10:34:42,989 - INFO - [pid 61374] Worker Worker(salt=8932275094, workers=1, host=192.168.0.105, username=fajarianatm, pid=61374) running   Transform()
2024-12-29 10:34:42,991 - INFO - Read Transform Query - SUCCESS
2024-12-29 10:34:42,992 - INFO - Connect to DWH - SUCCESS
2024-12-29 10:34:42,992 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 10:34:43,737 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-29 10:34:43,777 - ERROR - Transform Tables - FAILED
2024-12-29 10:34:43,779 - ERROR - [pid 61374] Worker Worker(salt=8932275094, workers=1, host=192.168.0.105, username=fajarianatm, pid=61374) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DuplicateObject: trigger "customer_insert_trigger" for relation "customers" already exists


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateObject) trigger "customer_insert_trigger" for relation "customers" already exists

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
-- Filter data staging untuk validasi
WITH valid_customers AS (
    SELECT
        c.id AS customer_id,
        c.customer_id AS customer_nk,
        c.customer_zip_code_prefix AS customer_zip_code,
        c.customer_city,
        c.customer_state
    FROM stg.customers c
    LEFT JOIN final.dim_customers d
        ON c.id = d.customer_id
        AND d.current_flag = 'current'
    WHERE d.customer_id IS NULL -- Pelanggan baru
       OR (
           c.customer_zip_code_prefix IS DISTINCT FROM d.customer_zip_code
           OR c.customer_city IS DISTINCT FROM d.customer_city
           OR c.customer_state IS DISTINCT FROM d.customer_state
       )
)
-- Insert valid data into dim_customers
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vc.customer_id,
    vc.customer_nk,
    vc.customer_zip_code,
    vc.customer_city,
    vc.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,
    NULL AS expired_at,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_customers d
        WHERE d.customer_id = vc.customer_id
    ), 0) + 1 AS version_id
FROM valid_customers vc;


-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ) -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;



-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-29 10:34:43,800 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:34:43,804 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-29 10:34:43,804 - DEBUG - Asking scheduler for work...
2024-12-29 10:34:43,805 - DEBUG - Done
2024-12-29 10:34:43,806 - DEBUG - There are no more tasks to run at this time
2024-12-29 10:34:43,806 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-29 10:34:43,806 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-29 10:34:43,806 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-29 10:34:43,806 - INFO - Worker Worker(salt=8932275094, workers=1, host=192.168.0.105, username=fajarianatm, pid=61374) was stopped. Shutting down Keep-Alive thread
2024-12-29 10:34:43,807 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-29 10:39:53,043 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-29 10:39:53,478 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-29 10:39:53,549 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-29 10:39:53,552 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-29 10:39:53,722 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-29 10:39:54,214 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-29 10:39:54,783 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-29 10:39:55,132 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-29 10:39:55,534 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-29 10:39:55,534 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-29 10:39:55,536 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-29 10:39:55,543 - INFO - [pid 73641] Worker Worker(salt=6671386315, workers=1, host=192.168.0.105, username=fajarianatm, pid=73641) done      Extract()
2024-12-29 10:39:55,544 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:39:55,546 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-29 10:39:55,546 - DEBUG - Asking scheduler for work...
2024-12-29 10:39:55,548 - DEBUG - Pending tasks: 2
2024-12-29 10:39:55,548 - INFO - [pid 73641] Worker Worker(salt=6671386315, workers=1, host=192.168.0.105, username=fajarianatm, pid=73641) running   Load()
2024-12-29 10:39:55,550 - INFO - Read Load Query - SUCCESS
2024-12-29 10:39:56,200 - INFO - Read Extracted Data - SUCCESS
2024-12-29 10:39:56,200 - INFO - Connect to DWH - SUCCESS
2024-12-29 10:39:56,283 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-29 10:39:56,283 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-29 10:39:58,142 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-29 10:39:58,188 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-29 10:39:58,192 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-29 10:39:59,257 - INFO - LOAD 'src.products' - SUCCESS
2024-12-29 10:40:02,107 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-29 10:40:05,945 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-29 10:40:08,132 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-29 10:40:10,589 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-29 10:40:10,589 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 10:40:17,404 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 10:40:17,417 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 10:40:17,482 - INFO - [pid 73641] Worker Worker(salt=6671386315, workers=1, host=192.168.0.105, username=fajarianatm, pid=73641) done      Load()
2024-12-29 10:40:17,482 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:40:17,485 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 10:40:17,485 - DEBUG - Asking scheduler for work...
2024-12-29 10:40:17,486 - DEBUG - Pending tasks: 1
2024-12-29 10:40:17,486 - INFO - [pid 73641] Worker Worker(salt=6671386315, workers=1, host=192.168.0.105, username=fajarianatm, pid=73641) running   Transform()
2024-12-29 10:40:17,488 - INFO - Read Transform Query - SUCCESS
2024-12-29 10:40:17,489 - INFO - Connect to DWH - SUCCESS
2024-12-29 10:40:17,489 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 10:40:18,441 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-29 10:40:18,461 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-29 10:40:18,627 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-29 10:40:18,773 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-29 10:40:21,127 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-29 10:40:21,132 - INFO - Transform to 'final.fct_sales_daily' - SUCCESS
2024-12-29 10:40:21,136 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-29 10:40:21,180 - ERROR - Transform Tables - FAILED
2024-12-29 10:40:21,183 - ERROR - [pid 73641] Worker Worker(salt=6671386315, workers=1, host=192.168.0.105, username=fajarianatm, pid=73641) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column dd1.order_purchase_timestamp does not exist
LINE 22:             dd1.order_purchase_timestamp AS order_purchase_a...
                     ^
HINT:  Perhaps you meant to reference the column "so.order_purchase_timestamp".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 134, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column dd1.order_purchase_timestamp does not exist
LINE 22:             dd1.order_purchase_timestamp AS order_purchase_a...
                     ^
HINT:  Perhaps you meant to reference the column "so.order_purchase_timestamp".

[SQL: -- stg.orders, stg.order_items, final.dim_date
WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
        WHERE order_status = 'delivered'
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_date AS (
        SELECT *
        FROM final.dim_date
    ),

    final_fct_delivery_performance AS (
        SELECT 
            so.order_id AS order_nk,
            dd1.order_purchase_timestamp AS order_purchase_at,
            dd2.order_approved_at AS order_approved_at,
            dd3.shipping_limit_date AS shipping_limit_date,
            dd4.order_delivered_carrier_date AS order_carrier_date,
            dd5.order_delivered_customer_date AS order_delivered_customer_date,
            dd6.order_estimated_delivery_date AS order_estimated_delivery_date,
            so.order_status AS order_status,
            (so.order_approved_at - so.order_purchase_timestamp) AS purchase_to_approval_days,
            (so.order_delivered_carrier_date - so.order_approved_at) AS approval_to_shipping_days,
            (so.order_delivered_customer_date - order_delivered_carrier_date) AS shipping_to_delivery_days,
            (so.order_delivered_customer_date - order_estimated_delivery_date) AS delivery_to_estimated_days,
            (so.order_delivered_customer_date - order_approved_at) AS purchase_to_delivered_days,
            (soi.shipping_limit_date - order_delivered_carrier_date) AS shipping_limit_to_carrier_days

        FROM stg.orders so
        JOIN stg.order_items soi 
            ON soi.order_id = so.order_id
        JOIN final.dim_date dd1 
            ON dd1.date_actual = DATE(so.order_purchase_timestamp)
        JOIN final.dim_date dd2
            ON dd2.date_actual = DATE(so.order_approved_at)
        JOIN final.dim_date dd3
            ON dd3.date_actual = DATE(soi.shipping_limit_date)
        JOIN final.dim_date dd4
            ON dd4.date_actual = DATE(so.order_delivered_carrier_date)
        JOIN final.dim_date dd5
            ON dd5.date_actual = DATE(so.order_delivered_customer_date)
        JOIN final.dim_date dd6
            ON dd6.date_actual = DATE(so.order_estimated_delivery_date)
    )

INSERT INTO final.fct_delivery_performance (
    order_nk,
    order_purchase_at,
    order_approved_at,
    shipping_limit_date,
    order_carrier_date,
    order_delivered_customer_date,
    order_estimated_delivery_date,
    order_status,
    purchase_to_approval_days,
    approval_to_shipping_days,
    shipping_to_delivery_days,
    delivery_to_estimated_days,
    purchase_to_delivery_days,
    shipping_limit_to_carrier_days
)

SELECT *
FROM final_fct_delivery_performance

ON CONFLICT(order_nk)
DO UPDATE SET
    order_purchase_at = EXCLUDED.order_purchase_at,
    order_approved_at = EXCLUDED.order_approved_at,
    shipping_limit_date = EXCLUDED.shipping_limit_date,
    order_carrier_date = EXCLUDED.order_carrier_date,
    order_delivered_customer_date = EXCLUDED.order_delivered_customer_date,
    order_estimated_delivery_date = EXCLUDED.order_estimated_delivery_date,
    order_status = EXCLUDED.order_status,
    purchase_to_approval_days = EXCLUDED.purchase_to_approval_days,
    approval_to_shipping_days = EXCLUDED.approval_to_shipping_days,
    shipping_to_delivery_days = EXCLUDED.shipping_to_delivery_days,
    delivery_to_estimated_days = EXCLUDED.delivery_to_estimated_days,
    purchase_to_delivery_days = EXCLUDED.purchase_to_delivery_days,
    shipping_limit_to_carrier_days = EXCLUDED.shipping_limit_to_carrier_days,
    updated_at = CASE 
                    WHEN
                        final.fct_delivery_performance.order_purchase_at <> EXCLUDED.order_purchase_at
                        OR final.fct_delivery_performance.order_approved_at <> EXCLUDED.order_approved_at
                        OR final.fct_delivery_performance.shipping_limit_date <> EXCLUDED.shipping_limit_date
                        OR final.fct_delivery_performance.order_carrier_date <> EXCLUDED.order_carrier_date
                        OR final.fct_delivery_performance.order_delivered_customer_date <> EXCLUDED.order_delivered_customer_date
                        OR final.fct_delivery_performance.order_estimated_delivery_date <> EXCLUDED.order_estimated_delivery_date
                        OR final.fct_delivery_performance.order_status <> EXCLUDED.order_status
                        OR final.fct_delivery_performance.purchase_to_approval_days <> EXCLUDED.purchase_to_approval_days
                        OR final.fct_delivery_performance.approval_to_shipping_days <> EXCLUDED.approval_to_shipping_days
                        OR final.fct_delivery_performance.shipping_to_delivery_days <> EXCLUDED.shipping_to_delivery_days
                        OR final.fct_delivery_performance.delivery_to_estimated_days <> EXCLUDED.delivery_to_estimated_days
                        OR final.fct_delivery_performance.purchase_to_delivery_days <> EXCLUDED.purchase_to_delivery_days
                        OR final.fct_delivery_performance.shipping_limit_to_carrier_days <> EXCLUDED.shipping_limit_to_carrier_days
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_delivery_performance.updated_at
                 END;










]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-29 10:40:21,243 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:40:21,275 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-29 10:40:21,276 - DEBUG - Asking scheduler for work...
2024-12-29 10:40:21,283 - DEBUG - Done
2024-12-29 10:40:21,283 - DEBUG - There are no more tasks to run at this time
2024-12-29 10:40:21,283 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-29 10:40:21,283 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-29 10:40:21,283 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-29 10:40:21,283 - INFO - Worker Worker(salt=6671386315, workers=1, host=192.168.0.105, username=fajarianatm, pid=73641) was stopped. Shutting down Keep-Alive thread
2024-12-29 10:40:21,284 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-29 10:52:43,160 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-29 10:52:43,711 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-29 10:52:43,749 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-29 10:52:43,753 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-29 10:52:43,925 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-29 10:52:44,404 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-29 10:52:44,953 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-29 10:52:45,296 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-29 10:52:45,690 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-29 10:52:45,691 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-29 10:52:45,694 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-29 10:52:45,701 - INFO - [pid 78949] Worker Worker(salt=5326928903, workers=1, host=192.168.0.105, username=fajarianatm, pid=78949) done      Extract()
2024-12-29 10:52:45,701 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 10:52:45,703 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-29 10:52:45,703 - DEBUG - Asking scheduler for work...
2024-12-29 10:52:45,705 - DEBUG - Pending tasks: 2
2024-12-29 10:52:45,705 - INFO - [pid 78949] Worker Worker(salt=5326928903, workers=1, host=192.168.0.105, username=fajarianatm, pid=78949) running   Load()
2024-12-29 10:52:45,707 - INFO - Read Load Query - SUCCESS
2024-12-29 10:52:46,422 - INFO - Read Extracted Data - SUCCESS
2024-12-29 10:52:46,423 - INFO - Connect to DWH - SUCCESS
2024-12-29 10:52:46,523 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-29 10:52:46,523 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-29 10:52:48,411 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-29 10:52:48,457 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-29 10:52:48,461 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-29 10:52:49,543 - INFO - LOAD 'src.products' - SUCCESS
2024-12-29 10:52:52,212 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-29 10:52:55,952 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-29 10:52:58,120 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-29 10:53:00,433 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-29 10:53:00,433 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 11:15:21,075 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 11:15:21,091 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 11:15:21,159 - INFO - [pid 78949] Worker Worker(salt=5326928903, workers=1, host=192.168.0.105, username=fajarianatm, pid=78949) done      Load()
2024-12-29 11:15:21,159 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 11:15:21,162 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 11:15:21,162 - DEBUG - Asking scheduler for work...
2024-12-29 11:15:21,164 - DEBUG - Pending tasks: 1
2024-12-29 11:15:21,164 - INFO - [pid 78949] Worker Worker(salt=5326928903, workers=1, host=192.168.0.105, username=fajarianatm, pid=78949) running   Transform()
2024-12-29 11:15:21,166 - INFO - Read Transform Query - SUCCESS
2024-12-29 11:15:21,167 - INFO - Connect to DWH - SUCCESS
2024-12-29 11:15:21,168 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 11:15:21,632 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-29 11:15:21,668 - ERROR - Transform Tables - FAILED
2024-12-29 11:15:21,671 - ERROR - [pid 78949] Worker Worker(salt=5326928903, workers=1, host=192.168.0.105, username=fajarianatm, pid=78949) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DuplicateObject: trigger "customer_insert_trigger" for relation "customers" already exists


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateObject) trigger "customer_insert_trigger" for relation "customers" already exists

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
-- Filter data staging untuk validasi
WITH valid_customers AS (
    SELECT
        c.id AS customer_id,
        c.customer_id AS customer_nk,
        c.customer_zip_code_prefix AS customer_zip_code,
        c.customer_city,
        c.customer_state
    FROM stg.customers c
    LEFT JOIN final.dim_customers d
        ON c.id = d.customer_id
        AND d.current_flag = 'current'
    WHERE d.customer_id IS NULL -- Pelanggan baru
       OR (
           c.customer_zip_code_prefix IS DISTINCT FROM d.customer_zip_code
           OR c.customer_city IS DISTINCT FROM d.customer_city
           OR c.customer_state IS DISTINCT FROM d.customer_state
       )
)
-- Insert valid data into dim_customers
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vc.customer_id,
    vc.customer_nk,
    vc.customer_zip_code,
    vc.customer_city,
    vc.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,
    NULL AS expired_at,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_customers d
        WHERE d.customer_id = vc.customer_id
    ), 0) + 1 AS version_id
FROM valid_customers vc;


-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ) -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;



-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-29 11:15:21,690 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 11:15:21,695 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-29 11:15:21,695 - DEBUG - Asking scheduler for work...
2024-12-29 11:15:21,697 - DEBUG - Done
2024-12-29 11:15:21,697 - DEBUG - There are no more tasks to run at this time
2024-12-29 11:15:21,697 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-29 11:15:21,697 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-29 11:15:21,697 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-29 11:15:21,697 - INFO - Worker Worker(salt=5326928903, workers=1, host=192.168.0.105, username=fajarianatm, pid=78949) was stopped. Shutting down Keep-Alive thread
2024-12-29 11:15:21,697 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-29 11:16:49,901 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-29 11:16:50,347 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-29 11:16:50,382 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-29 11:16:50,387 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-29 11:16:50,573 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-29 11:16:51,064 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-29 11:16:51,633 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-29 11:16:52,014 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-29 11:16:52,498 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-29 11:16:52,498 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-29 11:16:52,500 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-29 11:16:52,509 - INFO - [pid 89330] Worker Worker(salt=2768779846, workers=1, host=192.168.0.105, username=fajarianatm, pid=89330) done      Extract()
2024-12-29 11:16:52,509 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 11:16:52,512 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-29 11:16:52,512 - DEBUG - Asking scheduler for work...
2024-12-29 11:16:52,513 - DEBUG - Pending tasks: 2
2024-12-29 11:16:52,513 - INFO - [pid 89330] Worker Worker(salt=2768779846, workers=1, host=192.168.0.105, username=fajarianatm, pid=89330) running   Load()
2024-12-29 11:16:52,516 - INFO - Read Load Query - SUCCESS
2024-12-29 11:16:53,228 - INFO - Read Extracted Data - SUCCESS
2024-12-29 11:16:53,229 - INFO - Connect to DWH - SUCCESS
2024-12-29 11:16:53,291 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-29 11:16:53,291 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-29 11:16:54,986 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-29 11:16:55,041 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-29 11:16:55,044 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-29 11:16:56,046 - INFO - LOAD 'src.products' - SUCCESS
2024-12-29 11:16:59,005 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-29 11:17:02,922 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-29 11:17:05,125 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-29 11:17:07,551 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-29 11:17:07,551 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-29 11:17:14,628 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-29 11:17:14,636 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-29 11:17:14,690 - INFO - [pid 89330] Worker Worker(salt=2768779846, workers=1, host=192.168.0.105, username=fajarianatm, pid=89330) done      Load()
2024-12-29 11:17:14,691 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 11:17:14,694 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-29 11:17:14,694 - DEBUG - Asking scheduler for work...
2024-12-29 11:17:14,695 - DEBUG - Pending tasks: 1
2024-12-29 11:17:14,695 - INFO - [pid 89330] Worker Worker(salt=2768779846, workers=1, host=192.168.0.105, username=fajarianatm, pid=89330) running   Transform()
2024-12-29 11:17:14,697 - INFO - Read Transform Query - SUCCESS
2024-12-29 11:17:14,698 - INFO - Connect to DWH - SUCCESS
2024-12-29 11:17:14,698 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-29 11:17:15,457 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-29 11:17:15,470 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-29 11:17:15,588 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-29 11:17:15,733 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-29 11:17:18,070 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-29 11:17:18,073 - INFO - Transform to 'final.fct_sales_daily' - SUCCESS
2024-12-29 11:17:18,077 - INFO - Transform to 'final.fct_delivery_performance' - SUCCESS
2024-12-29 11:17:18,080 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS
2024-12-29 11:17:18,084 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-12-29 11:17:18,084 - INFO - [pid 89330] Worker Worker(salt=2768779846, workers=1, host=192.168.0.105, username=fajarianatm, pid=89330) done      Transform()
2024-12-29 11:17:18,085 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-29 11:17:18,087 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-12-29 11:17:18,087 - DEBUG - Asking scheduler for work...
2024-12-29 11:17:18,088 - DEBUG - Done
2024-12-29 11:17:18,088 - DEBUG - There are no more tasks to run at this time
2024-12-29 11:17:18,088 - INFO - Worker Worker(salt=2768779846, workers=1, host=192.168.0.105, username=fajarianatm, pid=89330) was stopped. Shutting down Keep-Alive thread
2024-12-29 11:17:18,091 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-12-30 00:40:19,608 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 00:40:20,502 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 00:40:20,549 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 00:40:20,552 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 00:40:20,748 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 00:40:21,456 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 00:40:22,191 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 00:40:22,633 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 00:40:23,236 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 00:40:23,236 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 00:40:23,252 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 00:40:23,262 - INFO - [pid 33576] Worker Worker(salt=8759278640, workers=1, host=192.168.0.100, username=fajarianatm, pid=33576) done      Extract()
2024-12-30 00:40:23,263 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 00:40:23,265 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 00:40:23,265 - DEBUG - Asking scheduler for work...
2024-12-30 00:40:23,267 - DEBUG - Pending tasks: 2
2024-12-30 00:40:23,267 - INFO - [pid 33576] Worker Worker(salt=8759278640, workers=1, host=192.168.0.100, username=fajarianatm, pid=33576) running   Load()
2024-12-30 00:40:23,269 - INFO - Read Load Query - SUCCESS
2024-12-30 00:40:23,934 - INFO - Read Extracted Data - SUCCESS
2024-12-30 00:40:23,935 - INFO - Connect to DWH - SUCCESS
2024-12-30 00:40:24,110 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 00:40:24,111 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 00:40:26,274 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 00:40:26,319 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 00:40:26,322 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 00:40:27,469 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 00:40:30,581 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 00:40:35,088 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 00:40:38,063 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 00:40:40,954 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 00:40:40,955 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 01:04:29,239 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 01:04:29,295 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 01:04:29,634 - INFO - [pid 33576] Worker Worker(salt=8759278640, workers=1, host=192.168.0.100, username=fajarianatm, pid=33576) done      Load()
2024-12-30 01:04:29,636 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:04:29,640 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 01:04:29,641 - DEBUG - Asking scheduler for work...
2024-12-30 01:04:29,643 - DEBUG - Pending tasks: 1
2024-12-30 01:04:29,643 - INFO - [pid 33576] Worker Worker(salt=8759278640, workers=1, host=192.168.0.100, username=fajarianatm, pid=33576) running   Transform()
2024-12-30 01:04:29,645 - INFO - Read Transform Query - SUCCESS
2024-12-30 01:04:29,648 - INFO - Connect to DWH - SUCCESS
2024-12-30 01:04:29,648 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 01:04:30,747 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 01:04:30,819 - ERROR - Transform Tables - FAILED
2024-12-30 01:04:30,822 - ERROR - [pid 33576] Worker Worker(salt=8759278640, workers=1, host=192.168.0.100, username=fajarianatm, pid=33576) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DuplicateObject: trigger "customer_insert_trigger" for relation "customers" already exists


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateObject) trigger "customer_insert_trigger" for relation "customers" already exists

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
-- Filter data staging untuk validasi
WITH valid_customers AS (
    SELECT
        c.id AS customer_id,
        c.customer_id AS customer_nk,
        c.customer_zip_code_prefix AS customer_zip_code,
        c.customer_city,
        c.customer_state
    FROM stg.customers c
    LEFT JOIN final.dim_customers d
        ON c.id = d.customer_id
        AND d.current_flag = 'current'
    WHERE d.customer_id IS NULL -- Pelanggan baru
       OR (
           c.customer_zip_code_prefix IS DISTINCT FROM d.customer_zip_code
           OR c.customer_city IS DISTINCT FROM d.customer_city
           OR c.customer_state IS DISTINCT FROM d.customer_state
       )
)
-- Insert valid data into dim_customers
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vc.customer_id,
    vc.customer_nk,
    vc.customer_zip_code,
    vc.customer_city,
    vc.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,
    NULL AS expired_at,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_customers d
        WHERE d.customer_id = vc.customer_id
    ), 0) + 1 AS version_id
FROM valid_customers vc;


-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ) -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;



-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 01:04:30,849 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:04:30,881 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 01:04:30,882 - DEBUG - Asking scheduler for work...
2024-12-30 01:04:30,918 - DEBUG - Done
2024-12-30 01:04:30,918 - DEBUG - There are no more tasks to run at this time
2024-12-30 01:04:30,919 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 01:04:30,919 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 01:04:30,919 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 01:04:30,927 - INFO - Worker Worker(salt=8759278640, workers=1, host=192.168.0.100, username=fajarianatm, pid=33576) was stopped. Shutting down Keep-Alive thread
2024-12-30 01:04:30,935 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 01:06:53,689 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 01:06:54,146 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 01:06:54,183 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 01:06:54,188 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 01:06:54,384 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 01:06:54,887 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 01:06:55,474 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 01:06:55,844 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 01:06:56,311 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 01:06:56,312 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 01:06:56,317 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 01:06:56,324 - INFO - [pid 45312] Worker Worker(salt=256770887, workers=1, host=192.168.0.100, username=fajarianatm, pid=45312) done      Extract()
2024-12-30 01:06:56,325 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:06:56,328 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 01:06:56,328 - DEBUG - Asking scheduler for work...
2024-12-30 01:06:56,330 - DEBUG - Pending tasks: 2
2024-12-30 01:06:56,330 - INFO - [pid 45312] Worker Worker(salt=256770887, workers=1, host=192.168.0.100, username=fajarianatm, pid=45312) running   Load()
2024-12-30 01:06:56,332 - INFO - Read Load Query - SUCCESS
2024-12-30 01:06:57,042 - INFO - Read Extracted Data - SUCCESS
2024-12-30 01:06:57,043 - INFO - Connect to DWH - SUCCESS
2024-12-30 01:06:57,153 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 01:06:57,153 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 01:06:59,270 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 01:06:59,319 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 01:06:59,322 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 01:07:00,555 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 01:07:03,444 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 01:07:08,054 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 01:07:10,459 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 01:07:12,894 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 01:07:12,894 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 01:07:20,545 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 01:07:20,561 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 01:07:20,613 - INFO - [pid 45312] Worker Worker(salt=256770887, workers=1, host=192.168.0.100, username=fajarianatm, pid=45312) done      Load()
2024-12-30 01:07:20,613 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:07:20,617 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 01:07:20,617 - DEBUG - Asking scheduler for work...
2024-12-30 01:07:20,619 - DEBUG - Pending tasks: 1
2024-12-30 01:07:20,619 - INFO - [pid 45312] Worker Worker(salt=256770887, workers=1, host=192.168.0.100, username=fajarianatm, pid=45312) running   Transform()
2024-12-30 01:07:20,621 - INFO - Read Transform Query - SUCCESS
2024-12-30 01:07:20,622 - INFO - Connect to DWH - SUCCESS
2024-12-30 01:07:20,622 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 01:07:21,624 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 01:07:21,639 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 01:07:21,759 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 01:07:21,928 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 01:07:24,341 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 01:07:24,345 - INFO - Transform to 'final.fct_sales_daily' - SUCCESS
2024-12-30 01:07:24,347 - INFO - Transform to 'final.fct_delivery_performance' - SUCCESS
2024-12-30 01:07:24,350 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS
2024-12-30 01:07:24,354 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-12-30 01:07:24,354 - INFO - [pid 45312] Worker Worker(salt=256770887, workers=1, host=192.168.0.100, username=fajarianatm, pid=45312) done      Transform()
2024-12-30 01:07:24,355 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:07:24,359 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-12-30 01:07:24,359 - DEBUG - Asking scheduler for work...
2024-12-30 01:07:24,361 - DEBUG - Done
2024-12-30 01:07:24,361 - DEBUG - There are no more tasks to run at this time
2024-12-30 01:07:24,361 - INFO - Worker Worker(salt=256770887, workers=1, host=192.168.0.100, username=fajarianatm, pid=45312) was stopped. Shutting down Keep-Alive thread
2024-12-30 01:07:24,364 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-12-30 01:34:52,636 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 01:34:53,409 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 01:34:53,451 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 01:34:53,455 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 01:34:53,657 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 01:34:54,254 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 01:34:55,014 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 01:34:55,464 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 01:34:55,993 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 01:34:55,993 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 01:34:55,998 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 01:34:56,006 - INFO - [pid 56687] Worker Worker(salt=1170136235, workers=1, host=192.168.0.100, username=fajarianatm, pid=56687) done      Extract()
2024-12-30 01:34:56,006 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:34:56,009 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 01:34:56,009 - DEBUG - Asking scheduler for work...
2024-12-30 01:34:56,010 - DEBUG - Pending tasks: 2
2024-12-30 01:34:56,010 - INFO - [pid 56687] Worker Worker(salt=1170136235, workers=1, host=192.168.0.100, username=fajarianatm, pid=56687) running   Load()
2024-12-30 01:34:56,012 - INFO - Read Load Query - SUCCESS
2024-12-30 01:34:56,691 - INFO - Read Extracted Data - SUCCESS
2024-12-30 01:34:56,692 - INFO - Connect to DWH - SUCCESS
2024-12-30 01:34:56,866 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 01:34:56,866 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 01:34:59,108 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 01:34:59,162 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 01:34:59,166 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 01:35:00,386 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 01:35:03,563 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 01:35:07,687 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 01:35:10,108 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 01:35:12,659 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 01:35:12,659 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 01:38:01,284 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:38:01,288 - INFO - Retrying attempt 2 of 3 (max)
2024-12-30 01:38:01,288 - INFO - Wait for 30 seconds
2024-12-30 01:38:31,300 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:38:31,301 - INFO - Retrying attempt 3 of 3 (max)
2024-12-30 01:38:31,302 - INFO - Wait for 30 seconds
2024-12-30 01:39:01,308 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:39:01,310 - INFO - Retrying attempt 4 of 3 (max)
2024-12-30 01:39:01,310 - INFO - Wait for 30 seconds
2024-12-30 01:39:01,310 - WARNING - Failed pinging scheduler
2024-12-30 01:39:02,316 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:39:02,316 - INFO - Retrying attempt 2 of 3 (max)
2024-12-30 01:39:02,316 - INFO - Wait for 30 seconds
2024-12-30 01:39:32,325 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:39:32,327 - INFO - Retrying attempt 3 of 3 (max)
2024-12-30 01:39:32,327 - INFO - Wait for 30 seconds
2024-12-30 01:40:02,333 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:40:02,335 - INFO - Retrying attempt 4 of 3 (max)
2024-12-30 01:40:02,335 - INFO - Wait for 30 seconds
2024-12-30 01:40:02,336 - WARNING - Failed pinging scheduler
2024-12-30 01:40:03,338 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:40:03,338 - INFO - Retrying attempt 2 of 3 (max)
2024-12-30 01:40:03,338 - INFO - Wait for 30 seconds
2024-12-30 01:40:33,346 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:40:33,349 - INFO - Retrying attempt 3 of 3 (max)
2024-12-30 01:40:33,350 - INFO - Wait for 30 seconds
2024-12-30 01:41:03,361 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:41:03,363 - INFO - Retrying attempt 4 of 3 (max)
2024-12-30 01:41:03,363 - INFO - Wait for 30 seconds
2024-12-30 01:41:03,363 - WARNING - Failed pinging scheduler
2024-12-30 01:41:04,370 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:41:04,371 - INFO - Retrying attempt 2 of 3 (max)
2024-12-30 01:41:04,371 - INFO - Wait for 30 seconds
2024-12-30 01:41:34,386 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:41:34,388 - INFO - Retrying attempt 3 of 3 (max)
2024-12-30 01:41:34,388 - INFO - Wait for 30 seconds
2024-12-30 01:42:04,395 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:42:04,396 - INFO - Retrying attempt 4 of 3 (max)
2024-12-30 01:42:04,396 - INFO - Wait for 30 seconds
2024-12-30 01:42:04,397 - WARNING - Failed pinging scheduler
2024-12-30 01:42:05,408 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:42:05,414 - INFO - Retrying attempt 2 of 3 (max)
2024-12-30 01:42:05,414 - INFO - Wait for 30 seconds
2024-12-30 01:42:35,425 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:42:35,427 - INFO - Retrying attempt 3 of 3 (max)
2024-12-30 01:42:35,427 - INFO - Wait for 30 seconds
2024-12-30 01:43:05,434 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:43:05,435 - INFO - Retrying attempt 4 of 3 (max)
2024-12-30 01:43:05,435 - INFO - Wait for 30 seconds
2024-12-30 01:43:05,436 - WARNING - Failed pinging scheduler
2024-12-30 01:43:06,442 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:43:06,443 - INFO - Retrying attempt 2 of 3 (max)
2024-12-30 01:43:06,443 - INFO - Wait for 30 seconds
2024-12-30 01:43:36,449 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:43:36,451 - INFO - Retrying attempt 3 of 3 (max)
2024-12-30 01:43:36,451 - INFO - Wait for 30 seconds
2024-12-30 01:44:06,460 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:44:06,461 - INFO - Retrying attempt 4 of 3 (max)
2024-12-30 01:44:06,461 - INFO - Wait for 30 seconds
2024-12-30 01:44:06,461 - WARNING - Failed pinging scheduler
2024-12-30 01:44:07,468 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:44:07,468 - INFO - Retrying attempt 2 of 3 (max)
2024-12-30 01:44:07,468 - INFO - Wait for 30 seconds
2024-12-30 01:44:37,479 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:44:37,481 - INFO - Retrying attempt 3 of 3 (max)
2024-12-30 01:44:37,481 - INFO - Wait for 30 seconds
2024-12-30 01:45:07,491 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:45:07,493 - INFO - Retrying attempt 4 of 3 (max)
2024-12-30 01:45:07,493 - INFO - Wait for 30 seconds
2024-12-30 01:45:07,493 - WARNING - Failed pinging scheduler
2024-12-30 01:45:08,497 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:45:08,498 - INFO - Retrying attempt 2 of 3 (max)
2024-12-30 01:45:08,498 - INFO - Wait for 30 seconds
2024-12-30 01:45:38,505 - WARNING - Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
2024-12-30 01:45:38,506 - INFO - Retrying attempt 3 of 3 (max)
2024-12-30 01:45:38,506 - INFO - Wait for 30 seconds
2024-12-30 01:54:37,340 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 01:54:37,813 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 01:54:37,852 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 01:54:37,856 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 01:54:38,115 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 01:54:38,682 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 01:54:39,341 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 01:54:39,744 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 01:54:40,402 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 01:54:40,403 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 01:54:40,412 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 01:54:40,428 - INFO - [pid 65279] Worker Worker(salt=2881689109, workers=1, host=192.168.0.100, username=fajarianatm, pid=65279) done      Extract()
2024-12-30 01:54:40,429 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:54:40,431 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 01:54:40,431 - DEBUG - Asking scheduler for work...
2024-12-30 01:54:40,433 - DEBUG - Pending tasks: 2
2024-12-30 01:54:40,433 - INFO - [pid 65279] Worker Worker(salt=2881689109, workers=1, host=192.168.0.100, username=fajarianatm, pid=65279) running   Load()
2024-12-30 01:54:40,435 - INFO - Read Load Query - SUCCESS
2024-12-30 01:54:41,138 - INFO - Read Extracted Data - SUCCESS
2024-12-30 01:54:41,139 - INFO - Connect to DWH - SUCCESS
2024-12-30 01:54:41,243 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 01:54:41,243 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 01:54:43,081 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 01:54:43,183 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 01:54:43,187 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 01:54:44,226 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 01:54:47,221 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 01:54:51,785 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 01:54:54,252 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 01:54:57,033 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 01:54:57,034 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 01:55:06,522 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 01:55:06,530 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 01:55:06,593 - INFO - [pid 65279] Worker Worker(salt=2881689109, workers=1, host=192.168.0.100, username=fajarianatm, pid=65279) done      Load()
2024-12-30 01:55:06,593 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:55:06,597 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 01:55:06,597 - DEBUG - Asking scheduler for work...
2024-12-30 01:55:06,598 - DEBUG - Pending tasks: 1
2024-12-30 01:55:06,599 - INFO - [pid 65279] Worker Worker(salt=2881689109, workers=1, host=192.168.0.100, username=fajarianatm, pid=65279) running   Transform()
2024-12-30 01:55:06,600 - INFO - Read Transform Query - SUCCESS
2024-12-30 01:55:06,602 - INFO - Connect to DWH - SUCCESS
2024-12-30 01:55:06,602 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 01:55:07,807 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 01:55:07,880 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 01:55:08,019 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 01:55:12,074 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 01:55:14,585 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 01:55:15,118 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 01:55:15,167 - ERROR - Transform Tables - FAILED
2024-12-30 01:55:15,171 - ERROR - [pid 65279] Worker Worker(salt=2881689109, workers=1, host=192.168.0.100, username=fajarianatm, pid=65279) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.CardinalityViolation: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.CardinalityViolation) ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.product_id,
            COUNT(soi.product_id) AS sales_quantity
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1,2
    ),

    final_fct_sales_daily AS (
        SELECT
            soi.order_id AS order_nk,
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            (cps.sales_quantity * soi.price) AS sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        JOIN final.dim_date dd ON dd.date_actual = DATE(so.order_purchase_timestamp)  -- Menggunakan order_purchase_timestamp yang sudah didefinisikan
        JOIN final.dim_products dp ON dp.product_nk = soi.product_id
        JOIN final.dim_sellers ds ON ds.seller_nk = soi.seller_id
        JOIN cnt_product_sales cps ON cps.product_id = dp.product_nk AND cps.order_date = dd.date_actual  -- Penyesuaian join dengan order_date
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)

SELECT *
FROM final_fct_sales_daily

ON CONFLICT(order_nk, date_id)
DO UPDATE SET
    product_id = EXCLUDED.product_id,
    seller_id = EXCLUDED.seller_id,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.product_id <> EXCLUDED.product_id
                        OR final.fct_sales_daily.seller_id <> EXCLUDED.seller_id
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 01:55:15,200 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 01:55:15,210 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 01:55:15,210 - DEBUG - Asking scheduler for work...
2024-12-30 01:55:15,211 - DEBUG - Done
2024-12-30 01:55:15,211 - DEBUG - There are no more tasks to run at this time
2024-12-30 01:55:15,211 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 01:55:15,211 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 01:55:15,211 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 01:55:15,211 - INFO - Worker Worker(salt=2881689109, workers=1, host=192.168.0.100, username=fajarianatm, pid=65279) was stopped. Shutting down Keep-Alive thread
2024-12-30 01:55:15,212 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 02:08:02,306 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 02:08:02,960 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 02:08:03,000 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 02:08:03,003 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 02:08:03,181 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 02:08:03,667 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 02:08:04,238 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 02:08:04,580 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 02:08:04,989 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 02:08:04,989 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 02:08:04,994 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 02:08:05,001 - INFO - [pid 70955] Worker Worker(salt=3448012548, workers=1, host=192.168.0.100, username=fajarianatm, pid=70955) done      Extract()
2024-12-30 02:08:05,001 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:08:05,004 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 02:08:05,004 - DEBUG - Asking scheduler for work...
2024-12-30 02:08:05,005 - DEBUG - Pending tasks: 2
2024-12-30 02:08:05,005 - INFO - [pid 70955] Worker Worker(salt=3448012548, workers=1, host=192.168.0.100, username=fajarianatm, pid=70955) running   Load()
2024-12-30 02:08:05,007 - INFO - Read Load Query - SUCCESS
2024-12-30 02:08:05,672 - INFO - Read Extracted Data - SUCCESS
2024-12-30 02:08:05,672 - INFO - Connect to DWH - SUCCESS
2024-12-30 02:08:05,781 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 02:08:05,781 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 02:08:07,712 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 02:08:07,759 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 02:08:07,762 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 02:08:08,847 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 02:08:12,033 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 02:08:16,253 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 02:08:18,759 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 02:08:22,003 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 02:08:22,004 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 02:08:30,671 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 02:08:30,698 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 02:08:30,754 - INFO - [pid 70955] Worker Worker(salt=3448012548, workers=1, host=192.168.0.100, username=fajarianatm, pid=70955) done      Load()
2024-12-30 02:08:30,755 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:08:30,758 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 02:08:30,758 - DEBUG - Asking scheduler for work...
2024-12-30 02:08:30,760 - DEBUG - Pending tasks: 1
2024-12-30 02:08:30,760 - INFO - [pid 70955] Worker Worker(salt=3448012548, workers=1, host=192.168.0.100, username=fajarianatm, pid=70955) running   Transform()
2024-12-30 02:08:30,762 - INFO - Read Transform Query - SUCCESS
2024-12-30 02:08:30,763 - INFO - Connect to DWH - SUCCESS
2024-12-30 02:08:30,763 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 02:08:31,823 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 02:08:31,842 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 02:08:31,955 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 02:08:36,235 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 02:08:38,853 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 02:08:39,520 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 02:08:39,569 - ERROR - Transform Tables - FAILED
2024-12-30 02:08:39,577 - ERROR - [pid 70955] Worker Worker(salt=3448012548, workers=1, host=192.168.0.100, username=fajarianatm, pid=70955) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "order_nk" of relation "fct_sales_daily" violates not-null constraint
DETAIL:  Failing row contains (026a8e89-c779-430a-80ff-a30e07497308, null, 20180520, 82211577-ce81-4426-8b9d-9f291cd2a3ac, f3ba4506-5dd1-4776-a765-025d4837b33a, 1, 101.65, 2024-12-29 19:08:31.957263, 2024-12-29 19:08:31.957263).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "order_nk" of relation "fct_sales_daily" violates not-null constraint
DETAIL:  Failing row contains (026a8e89-c779-430a-80ff-a30e07497308, null, 20180520, 82211577-ce81-4426-8b9d-9f291cd2a3ac, f3ba4506-5dd1-4776-a765-025d4837b33a, 1, 101.65, 2024-12-29 19:08:31.957263, 2024-12-29 19:08:31.957263).

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.product_id,
            soi.seller_id,
            COUNT(soi.product_id) AS sales_quantity,
            SUM(soi.price) AS total_sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1, 2, 3
    ),

    final_fct_sales_daily AS (
        SELECT
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            cps.total_sales_value AS sales_value
        FROM cnt_product_sales cps
        JOIN final.dim_date dd ON dd.date_actual = cps.order_date
        JOIN final.dim_products dp ON dp.product_nk = cps.product_id
        JOIN final.dim_sellers ds ON ds.seller_nk = cps.seller_id
    )

INSERT INTO final.fct_sales_daily(
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)
SELECT *
FROM final_fct_sales_daily
ON CONFLICT(date_id, product_id, seller_id)
DO UPDATE SET
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 02:08:39,605 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:08:39,643 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 02:08:39,644 - DEBUG - Asking scheduler for work...
2024-12-30 02:08:39,653 - DEBUG - Done
2024-12-30 02:08:39,653 - DEBUG - There are no more tasks to run at this time
2024-12-30 02:08:39,653 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 02:08:39,653 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 02:08:39,654 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 02:08:39,654 - INFO - Worker Worker(salt=3448012548, workers=1, host=192.168.0.100, username=fajarianatm, pid=70955) was stopped. Shutting down Keep-Alive thread
2024-12-30 02:08:39,673 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 02:21:07,501 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 02:21:07,973 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 02:21:08,008 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 02:21:08,012 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 02:21:08,191 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 02:21:08,706 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 02:21:09,287 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 02:21:09,640 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 02:21:10,077 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 02:21:10,077 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 02:21:10,080 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 02:21:10,088 - INFO - [pid 76340] Worker Worker(salt=479383501, workers=1, host=192.168.0.100, username=fajarianatm, pid=76340) done      Extract()
2024-12-30 02:21:10,088 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:21:10,091 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 02:21:10,091 - DEBUG - Asking scheduler for work...
2024-12-30 02:21:10,092 - DEBUG - Pending tasks: 2
2024-12-30 02:21:10,092 - INFO - [pid 76340] Worker Worker(salt=479383501, workers=1, host=192.168.0.100, username=fajarianatm, pid=76340) running   Load()
2024-12-30 02:21:10,094 - INFO - Read Load Query - SUCCESS
2024-12-30 02:21:10,751 - INFO - Read Extracted Data - SUCCESS
2024-12-30 02:21:10,752 - INFO - Connect to DWH - SUCCESS
2024-12-30 02:21:10,908 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 02:21:10,908 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 02:21:12,862 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 02:21:12,906 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 02:21:12,909 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 02:21:14,034 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 02:21:17,501 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 02:21:21,615 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 02:21:24,475 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 02:21:27,331 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 02:21:27,331 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 02:33:39,673 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 02:33:39,707 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 02:33:39,806 - INFO - [pid 76340] Worker Worker(salt=479383501, workers=1, host=192.168.0.100, username=fajarianatm, pid=76340) done      Load()
2024-12-30 02:33:39,807 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:33:39,810 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 02:33:39,810 - DEBUG - Asking scheduler for work...
2024-12-30 02:33:39,812 - DEBUG - Pending tasks: 1
2024-12-30 02:33:39,812 - INFO - [pid 76340] Worker Worker(salt=479383501, workers=1, host=192.168.0.100, username=fajarianatm, pid=76340) running   Transform()
2024-12-30 02:33:39,814 - INFO - Read Transform Query - SUCCESS
2024-12-30 02:33:39,816 - INFO - Connect to DWH - SUCCESS
2024-12-30 02:33:39,816 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 02:33:40,762 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 02:33:40,817 - ERROR - Transform Tables - FAILED
2024-12-30 02:33:40,820 - ERROR - [pid 76340] Worker Worker(salt=479383501, workers=1, host=192.168.0.100, username=fajarianatm, pid=76340) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DuplicateObject: trigger "customer_insert_trigger" for relation "customers" already exists


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateObject) trigger "customer_insert_trigger" for relation "customers" already exists

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
-- Filter data staging untuk validasi
WITH valid_customers AS (
    SELECT
        c.id AS customer_id,
        c.customer_id AS customer_nk,
        c.customer_zip_code_prefix AS customer_zip_code,
        c.customer_city,
        c.customer_state
    FROM stg.customers c
    LEFT JOIN final.dim_customers d
        ON c.id = d.customer_id
        AND d.current_flag = 'current'
    WHERE d.customer_id IS NULL -- Pelanggan baru
       OR (
           c.customer_zip_code_prefix IS DISTINCT FROM d.customer_zip_code
           OR c.customer_city IS DISTINCT FROM d.customer_city
           OR c.customer_state IS DISTINCT FROM d.customer_state
       )
)
-- Insert valid data into dim_customers
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vc.customer_id,
    vc.customer_nk,
    vc.customer_zip_code,
    vc.customer_city,
    vc.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,
    NULL AS expired_at,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_customers d
        WHERE d.customer_id = vc.customer_id
    ), 0) + 1 AS version_id
FROM valid_customers vc;


-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ) -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;



-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 02:33:40,850 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:33:40,864 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 02:33:40,864 - DEBUG - Asking scheduler for work...
2024-12-30 02:33:40,865 - DEBUG - Done
2024-12-30 02:33:40,865 - DEBUG - There are no more tasks to run at this time
2024-12-30 02:33:40,865 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 02:33:40,865 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 02:33:40,865 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 02:33:40,865 - INFO - Worker Worker(salt=479383501, workers=1, host=192.168.0.100, username=fajarianatm, pid=76340) was stopped. Shutting down Keep-Alive thread
2024-12-30 02:33:40,866 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 02:34:45,208 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 02:34:45,692 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 02:34:45,730 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 02:34:45,734 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 02:34:46,013 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 02:34:46,528 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 02:34:47,111 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 02:34:47,483 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 02:34:47,893 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 02:34:47,893 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 02:34:47,895 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 02:34:47,902 - INFO - [pid 82301] Worker Worker(salt=1805428067, workers=1, host=192.168.0.100, username=fajarianatm, pid=82301) done      Extract()
2024-12-30 02:34:47,903 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:34:47,905 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 02:34:47,905 - DEBUG - Asking scheduler for work...
2024-12-30 02:34:47,907 - DEBUG - Pending tasks: 2
2024-12-30 02:34:47,907 - INFO - [pid 82301] Worker Worker(salt=1805428067, workers=1, host=192.168.0.100, username=fajarianatm, pid=82301) running   Load()
2024-12-30 02:34:47,909 - INFO - Read Load Query - SUCCESS
2024-12-30 02:34:48,572 - INFO - Read Extracted Data - SUCCESS
2024-12-30 02:34:48,572 - INFO - Connect to DWH - SUCCESS
2024-12-30 02:34:48,658 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 02:34:48,658 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 02:34:50,489 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 02:34:50,533 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 02:34:50,536 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 02:34:51,617 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 02:34:54,519 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 02:34:58,491 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 02:35:00,727 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 02:35:03,141 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 02:35:03,141 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 02:35:11,104 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 02:35:11,116 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 02:35:11,175 - INFO - [pid 82301] Worker Worker(salt=1805428067, workers=1, host=192.168.0.100, username=fajarianatm, pid=82301) done      Load()
2024-12-30 02:35:11,176 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:35:11,179 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 02:35:11,179 - DEBUG - Asking scheduler for work...
2024-12-30 02:35:11,180 - DEBUG - Pending tasks: 1
2024-12-30 02:35:11,180 - INFO - [pid 82301] Worker Worker(salt=1805428067, workers=1, host=192.168.0.100, username=fajarianatm, pid=82301) running   Transform()
2024-12-30 02:35:11,182 - INFO - Read Transform Query - SUCCESS
2024-12-30 02:35:11,183 - INFO - Connect to DWH - SUCCESS
2024-12-30 02:35:11,183 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 02:35:12,050 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 02:35:12,069 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 02:35:12,216 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 02:35:16,286 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 02:35:18,344 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 02:35:18,357 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 02:35:18,391 - ERROR - Transform Tables - FAILED
2024-12-30 02:35:18,394 - ERROR - [pid 82301] Worker Worker(salt=1805428067, workers=1, host=192.168.0.100, username=fajarianatm, pid=82301) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.SyntaxError: syntax error at or near "."
LINE 26:             soi.product_id,
                        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.SyntaxError) syntax error at or near "."
LINE 26:             soi.product_id,
                        ^

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.order_id
            soi.product_id,
            soi.seller_id,
            COUNT(soi.product_id) AS sales_quantity,
            SUM(soi.price) AS total_sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1, 2, 3
    ),

    final_fct_sales_daily AS (
        SELECT
            cps.order_id AS order_nk
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            cps.total_sales_value AS sales_value
        FROM cnt_product_sales cps
        JOIN stg.order_items
        JOIN final.dim_date dd ON dd.date_actual = cps.order_date
        JOIN final.dim_products dp ON dp.product_nk = cps.product_id
        JOIN final.dim_sellers ds ON ds.seller_nk = cps.seller_id
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)
SELECT *
FROM final_fct_sales_daily
ON CONFLICT(date_id, product_id, seller_id)
DO UPDATE SET
    order_nk = EXCLUDED.order_nk,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.order_nk <> EXCLUDED.order_nk
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 02:35:18,419 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:35:18,424 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 02:35:18,425 - DEBUG - Asking scheduler for work...
2024-12-30 02:35:18,427 - DEBUG - Done
2024-12-30 02:35:18,427 - DEBUG - There are no more tasks to run at this time
2024-12-30 02:35:18,427 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 02:35:18,427 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 02:35:18,427 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 02:35:18,427 - INFO - Worker Worker(salt=1805428067, workers=1, host=192.168.0.100, username=fajarianatm, pid=82301) was stopped. Shutting down Keep-Alive thread
2024-12-30 02:35:18,429 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 02:36:49,637 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 02:36:50,089 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 02:36:50,127 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 02:36:50,131 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 02:36:50,317 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 02:36:50,810 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 02:36:51,352 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 02:36:51,696 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 02:36:52,095 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 02:36:52,095 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 02:36:52,099 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 02:36:52,107 - INFO - [pid 83196] Worker Worker(salt=4604599970, workers=1, host=192.168.0.100, username=fajarianatm, pid=83196) done      Extract()
2024-12-30 02:36:52,107 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:36:52,109 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 02:36:52,109 - DEBUG - Asking scheduler for work...
2024-12-30 02:36:52,110 - DEBUG - Pending tasks: 2
2024-12-30 02:36:52,110 - INFO - [pid 83196] Worker Worker(salt=4604599970, workers=1, host=192.168.0.100, username=fajarianatm, pid=83196) running   Load()
2024-12-30 02:36:52,112 - INFO - Read Load Query - SUCCESS
2024-12-30 02:36:52,774 - INFO - Read Extracted Data - SUCCESS
2024-12-30 02:36:52,774 - INFO - Connect to DWH - SUCCESS
2024-12-30 02:36:52,892 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 02:36:52,892 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 02:36:54,746 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 02:36:54,790 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 02:36:54,793 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 02:36:55,871 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 02:36:58,871 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 02:37:02,828 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 02:37:05,142 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 02:37:07,843 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 02:37:07,843 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 02:49:19,840 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 02:49:19,860 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 02:49:19,925 - INFO - [pid 83196] Worker Worker(salt=4604599970, workers=1, host=192.168.0.100, username=fajarianatm, pid=83196) done      Load()
2024-12-30 02:49:19,925 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:49:19,929 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 02:49:19,929 - DEBUG - Asking scheduler for work...
2024-12-30 02:49:19,932 - DEBUG - Pending tasks: 1
2024-12-30 02:49:19,932 - INFO - [pid 83196] Worker Worker(salt=4604599970, workers=1, host=192.168.0.100, username=fajarianatm, pid=83196) running   Transform()
2024-12-30 02:49:19,934 - INFO - Read Transform Query - SUCCESS
2024-12-30 02:49:19,935 - INFO - Connect to DWH - SUCCESS
2024-12-30 02:49:19,935 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 02:49:20,473 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 02:49:20,508 - ERROR - Transform Tables - FAILED
2024-12-30 02:49:20,511 - ERROR - [pid 83196] Worker Worker(salt=4604599970, workers=1, host=192.168.0.100, username=fajarianatm, pid=83196) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DuplicateObject: trigger "customer_insert_trigger" for relation "customers" already exists


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateObject) trigger "customer_insert_trigger" for relation "customers" already exists

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
-- Filter data staging untuk validasi
WITH valid_customers AS (
    SELECT
        c.id AS customer_id,
        c.customer_id AS customer_nk,
        c.customer_zip_code_prefix AS customer_zip_code,
        c.customer_city,
        c.customer_state
    FROM stg.customers c
    LEFT JOIN final.dim_customers d
        ON c.id = d.customer_id
        AND d.current_flag = 'current'
    WHERE d.customer_id IS NULL -- Pelanggan baru
       OR (
           c.customer_zip_code_prefix IS DISTINCT FROM d.customer_zip_code
           OR c.customer_city IS DISTINCT FROM d.customer_city
           OR c.customer_state IS DISTINCT FROM d.customer_state
       )
)
-- Insert valid data into dim_customers
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vc.customer_id,
    vc.customer_nk,
    vc.customer_zip_code,
    vc.customer_city,
    vc.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,
    NULL AS expired_at,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_customers d
        WHERE d.customer_id = vc.customer_id
    ), 0) + 1 AS version_id
FROM valid_customers vc;


-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ) -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;



-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 02:49:20,529 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 02:49:20,535 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 02:49:20,536 - DEBUG - Asking scheduler for work...
2024-12-30 02:49:20,537 - DEBUG - Done
2024-12-30 02:49:20,537 - DEBUG - There are no more tasks to run at this time
2024-12-30 02:49:20,537 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 02:49:20,537 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 02:49:20,537 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 02:49:20,538 - INFO - Worker Worker(salt=4604599970, workers=1, host=192.168.0.100, username=fajarianatm, pid=83196) was stopped. Shutting down Keep-Alive thread
2024-12-30 02:49:20,539 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 16:38:04,187 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 16:38:04,646 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 16:38:04,679 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 16:38:04,684 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 16:38:04,862 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 16:38:05,338 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 16:38:05,900 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 16:38:06,251 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 16:38:06,730 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 16:38:06,730 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 16:38:06,739 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 16:38:06,746 - INFO - [pid 74686] Worker Worker(salt=1960343713, workers=1, host=192.168.0.100, username=fajarianatm, pid=74686) done      Extract()
2024-12-30 16:38:06,746 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:38:06,749 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 16:38:06,749 - DEBUG - Asking scheduler for work...
2024-12-30 16:38:06,751 - DEBUG - Pending tasks: 2
2024-12-30 16:38:06,751 - INFO - [pid 74686] Worker Worker(salt=1960343713, workers=1, host=192.168.0.100, username=fajarianatm, pid=74686) running   Load()
2024-12-30 16:38:06,753 - INFO - Read Load Query - SUCCESS
2024-12-30 16:38:07,436 - INFO - Read Extracted Data - SUCCESS
2024-12-30 16:38:07,437 - INFO - Connect to DWH - SUCCESS
2024-12-30 16:38:07,538 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 16:38:07,538 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 16:38:09,509 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 16:38:09,553 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 16:38:09,557 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 16:38:10,659 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 16:38:13,670 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 16:38:17,742 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 16:38:20,091 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 16:38:22,719 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 16:38:22,719 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 16:38:31,815 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 16:38:31,830 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 16:38:31,890 - INFO - [pid 74686] Worker Worker(salt=1960343713, workers=1, host=192.168.0.100, username=fajarianatm, pid=74686) done      Load()
2024-12-30 16:38:31,891 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:38:31,894 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 16:38:31,894 - DEBUG - Asking scheduler for work...
2024-12-30 16:38:31,895 - DEBUG - Pending tasks: 1
2024-12-30 16:38:31,896 - INFO - [pid 74686] Worker Worker(salt=1960343713, workers=1, host=192.168.0.100, username=fajarianatm, pid=74686) running   Transform()
2024-12-30 16:38:31,898 - INFO - Read Transform Query - SUCCESS
2024-12-30 16:38:31,899 - INFO - Connect to DWH - SUCCESS
2024-12-30 16:38:31,899 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 16:38:33,023 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 16:38:33,041 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 16:38:33,369 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 16:38:38,414 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 16:38:40,779 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 16:38:40,782 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 16:38:40,827 - ERROR - Transform Tables - FAILED
2024-12-30 16:38:40,830 - ERROR - [pid 74686] Worker Worker(salt=1960343713, workers=1, host=192.168.0.100, username=fajarianatm, pid=74686) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.SyntaxError: syntax error at or near "dd"
LINE 39:             dd.date_id AS date_id,
                     ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.SyntaxError) syntax error at or near "dd"
LINE 39:             dd.date_id AS date_id,
                     ^

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.order_id,
            soi.product_id,
            soi.seller_id,
            COUNT(soi.product_id) AS sales_quantity,
            SUM(soi.price) AS total_sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1, 2, 3
    ),

    final_fct_sales_daily AS (
        SELECT
            cps.order_id AS order_nk
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            cps.total_sales_value AS sales_value
        FROM cnt_product_sales cps
        JOIN stg.order_items
        JOIN final.dim_date dd ON dd.date_actual = cps.order_date
        JOIN final.dim_products dp ON dp.product_nk = cps.product_id
        JOIN final.dim_sellers ds ON ds.seller_nk = cps.seller_id
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)
SELECT *
FROM final_fct_sales_daily
ON CONFLICT(date_id, product_id, seller_id)
DO UPDATE SET
    order_nk = EXCLUDED.order_nk,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.order_nk <> EXCLUDED.order_nk
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 16:38:40,854 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:38:40,862 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 16:38:40,862 - DEBUG - Asking scheduler for work...
2024-12-30 16:38:40,864 - DEBUG - Done
2024-12-30 16:38:40,864 - DEBUG - There are no more tasks to run at this time
2024-12-30 16:38:40,864 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 16:38:40,864 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 16:38:40,864 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 16:38:40,864 - INFO - Worker Worker(salt=1960343713, workers=1, host=192.168.0.100, username=fajarianatm, pid=74686) was stopped. Shutting down Keep-Alive thread
2024-12-30 16:38:40,865 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 16:41:19,882 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 16:41:20,334 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 16:41:20,373 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 16:41:20,377 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 16:41:20,562 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 16:41:21,064 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 16:41:21,620 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 16:41:22,043 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 16:41:22,445 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 16:41:22,445 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 16:41:22,448 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 16:41:22,456 - INFO - [pid 76139] Worker Worker(salt=4442389107, workers=1, host=192.168.0.100, username=fajarianatm, pid=76139) done      Extract()
2024-12-30 16:41:22,456 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:41:22,459 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 16:41:22,459 - DEBUG - Asking scheduler for work...
2024-12-30 16:41:22,460 - DEBUG - Pending tasks: 2
2024-12-30 16:41:22,460 - INFO - [pid 76139] Worker Worker(salt=4442389107, workers=1, host=192.168.0.100, username=fajarianatm, pid=76139) running   Load()
2024-12-30 16:41:22,462 - INFO - Read Load Query - SUCCESS
2024-12-30 16:41:23,121 - INFO - Read Extracted Data - SUCCESS
2024-12-30 16:41:23,122 - INFO - Connect to DWH - SUCCESS
2024-12-30 16:41:23,211 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 16:41:23,211 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 16:41:25,042 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 16:41:25,083 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 16:41:25,086 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 16:41:26,132 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 16:41:28,906 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 16:41:32,715 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 16:41:34,876 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 16:41:37,240 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 16:41:37,240 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 16:41:44,637 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 16:41:44,644 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 16:41:44,706 - INFO - [pid 76139] Worker Worker(salt=4442389107, workers=1, host=192.168.0.100, username=fajarianatm, pid=76139) done      Load()
2024-12-30 16:41:44,707 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:41:44,710 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 16:41:44,710 - DEBUG - Asking scheduler for work...
2024-12-30 16:41:44,712 - DEBUG - Pending tasks: 1
2024-12-30 16:41:44,712 - INFO - [pid 76139] Worker Worker(salt=4442389107, workers=1, host=192.168.0.100, username=fajarianatm, pid=76139) running   Transform()
2024-12-30 16:41:44,715 - INFO - Read Transform Query - SUCCESS
2024-12-30 16:41:44,715 - INFO - Connect to DWH - SUCCESS
2024-12-30 16:41:44,715 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 16:41:45,398 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 16:41:45,411 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 16:41:45,535 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 16:41:49,116 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 16:41:51,253 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 16:41:51,256 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 16:41:51,292 - ERROR - Transform Tables - FAILED
2024-12-30 16:41:51,294 - ERROR - [pid 76139] Worker Worker(salt=4442389107, workers=1, host=192.168.0.100, username=fajarianatm, pid=76139) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.SyntaxError: syntax error at or near ")"
LINE 49:     )
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.SyntaxError) syntax error at or near ")"
LINE 49:     )
             ^

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.order_id,
            soi.product_id,
            soi.seller_id,
            COUNT(soi.product_id) AS sales_quantity,
            SUM(soi.price) AS total_sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1, 2, 3
    ),

    final_fct_sales_daily AS (
        SELECT
            cps.order_id AS order_nk,
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            cps.total_sales_value AS sales_value
        FROM cnt_product_sales cps
        JOIN stg.order_items
        JOIN final.dim_date dd ON dd.date_actual = cps.order_date
        JOIN final.dim_products dp ON dp.product_nk = cps.product_id
        JOIN final.dim_sellers ds ON ds.seller_nk = cps.seller_id
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)
SELECT *
FROM final_fct_sales_daily
ON CONFLICT(date_id, product_id, seller_id)
DO UPDATE SET
    order_nk = EXCLUDED.order_nk,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.order_nk <> EXCLUDED.order_nk
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 16:41:51,318 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:41:51,323 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 16:41:51,323 - DEBUG - Asking scheduler for work...
2024-12-30 16:41:51,325 - DEBUG - Done
2024-12-30 16:41:51,325 - DEBUG - There are no more tasks to run at this time
2024-12-30 16:41:51,325 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 16:41:51,325 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 16:41:51,325 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 16:41:51,325 - INFO - Worker Worker(salt=4442389107, workers=1, host=192.168.0.100, username=fajarianatm, pid=76139) was stopped. Shutting down Keep-Alive thread
2024-12-30 16:41:51,326 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 16:46:29,796 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 16:46:30,292 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 16:46:30,333 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 16:46:30,336 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 16:46:30,644 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 16:46:31,204 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 16:46:31,889 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 16:46:32,256 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 16:46:32,730 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 16:46:32,730 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 16:46:32,735 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 16:46:32,743 - INFO - [pid 78339] Worker Worker(salt=911034967, workers=1, host=192.168.0.100, username=fajarianatm, pid=78339) done      Extract()
2024-12-30 16:46:32,743 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:46:32,746 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 16:46:32,746 - DEBUG - Asking scheduler for work...
2024-12-30 16:46:32,747 - DEBUG - Pending tasks: 2
2024-12-30 16:46:32,747 - INFO - [pid 78339] Worker Worker(salt=911034967, workers=1, host=192.168.0.100, username=fajarianatm, pid=78339) running   Load()
2024-12-30 16:46:32,750 - INFO - Read Load Query - SUCCESS
2024-12-30 16:46:33,430 - INFO - Read Extracted Data - SUCCESS
2024-12-30 16:46:33,430 - INFO - Connect to DWH - SUCCESS
2024-12-30 16:46:33,526 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 16:46:33,526 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 16:46:35,268 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 16:46:35,308 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 16:46:35,312 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 16:46:36,326 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 16:46:39,105 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 16:46:42,979 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 16:46:45,186 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 16:46:47,473 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 16:46:47,473 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 16:46:54,834 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 16:46:54,840 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 16:46:54,894 - INFO - [pid 78339] Worker Worker(salt=911034967, workers=1, host=192.168.0.100, username=fajarianatm, pid=78339) done      Load()
2024-12-30 16:46:54,894 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:46:54,897 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 16:46:54,897 - DEBUG - Asking scheduler for work...
2024-12-30 16:46:54,899 - DEBUG - Pending tasks: 1
2024-12-30 16:46:54,899 - INFO - [pid 78339] Worker Worker(salt=911034967, workers=1, host=192.168.0.100, username=fajarianatm, pid=78339) running   Transform()
2024-12-30 16:46:54,902 - INFO - Read Transform Query - SUCCESS
2024-12-30 16:46:54,903 - INFO - Connect to DWH - SUCCESS
2024-12-30 16:46:54,903 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 16:46:55,592 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 16:46:55,613 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 16:46:55,725 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 16:46:59,339 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 16:47:01,347 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 16:47:01,355 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 16:47:01,405 - ERROR - Transform Tables - FAILED
2024-12-30 16:47:01,409 - ERROR - [pid 78339] Worker Worker(salt=911034967, workers=1, host=192.168.0.100, username=fajarianatm, pid=78339) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.GroupingError: column "soi.seller_id" must appear in the GROUP BY clause or be used in an aggregate function
LINE 27:             soi.seller_id,
                     ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.GroupingError) column "soi.seller_id" must appear in the GROUP BY clause or be used in an aggregate function
LINE 27:             soi.seller_id,
                     ^

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.order_id,
            soi.product_id,
            soi.seller_id,
            COUNT(soi.product_id) AS sales_quantity,
            SUM(soi.price) AS total_sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1, 2, 3
    ),

    final_fct_sales_daily AS (
        SELECT
            cps.order_id AS order_nk,
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            cps.total_sales_value AS sales_value
        FROM cnt_product_sales cps
        -- Removed JOIN stg.order_items (this is redundant and unrelated)
        JOIN final.dim_date dd ON dd.date_actual = cps.order_date
        JOIN final.dim_products dp ON dp.product_nk = cps.product_id
        JOIN final.dim_sellers ds ON ds.seller_nk = cps.seller_id
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)
SELECT *
FROM final_fct_sales_daily
ON CONFLICT(date_id, product_id, seller_id)
DO UPDATE SET
    order_nk = EXCLUDED.order_nk,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.order_nk <> EXCLUDED.order_nk
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 16:47:01,433 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:47:01,439 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 16:47:01,439 - DEBUG - Asking scheduler for work...
2024-12-30 16:47:01,440 - DEBUG - Done
2024-12-30 16:47:01,440 - DEBUG - There are no more tasks to run at this time
2024-12-30 16:47:01,440 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 16:47:01,440 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 16:47:01,440 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 16:47:01,440 - INFO - Worker Worker(salt=911034967, workers=1, host=192.168.0.100, username=fajarianatm, pid=78339) was stopped. Shutting down Keep-Alive thread
2024-12-30 16:47:01,441 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 16:48:42,348 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 16:48:42,786 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 16:48:42,823 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 16:48:42,826 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 16:48:43,001 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 16:48:43,470 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 16:48:44,005 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 16:48:44,352 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 16:48:44,754 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 16:48:44,754 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 16:48:44,757 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 16:48:44,765 - INFO - [pid 79318] Worker Worker(salt=3150528971, workers=1, host=192.168.0.100, username=fajarianatm, pid=79318) done      Extract()
2024-12-30 16:48:44,765 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 16:48:44,767 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 16:48:44,767 - DEBUG - Asking scheduler for work...
2024-12-30 16:48:44,768 - DEBUG - Pending tasks: 2
2024-12-30 16:48:44,768 - INFO - [pid 79318] Worker Worker(salt=3150528971, workers=1, host=192.168.0.100, username=fajarianatm, pid=79318) running   Load()
2024-12-30 16:48:44,770 - INFO - Read Load Query - SUCCESS
2024-12-30 16:48:45,438 - INFO - Read Extracted Data - SUCCESS
2024-12-30 16:48:45,439 - INFO - Connect to DWH - SUCCESS
2024-12-30 16:48:45,528 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 16:48:45,528 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 16:48:47,260 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 16:48:47,303 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 16:48:47,306 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 16:48:48,359 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 16:48:51,141 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 16:48:55,029 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 16:48:57,287 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 16:48:59,944 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 16:48:59,944 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 17:01:12,659 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 17:01:12,677 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 17:01:12,741 - INFO - [pid 79318] Worker Worker(salt=3150528971, workers=1, host=192.168.0.100, username=fajarianatm, pid=79318) done      Load()
2024-12-30 17:01:12,742 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 17:01:12,746 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 17:01:12,746 - DEBUG - Asking scheduler for work...
2024-12-30 17:01:12,748 - DEBUG - Pending tasks: 1
2024-12-30 17:01:12,748 - INFO - [pid 79318] Worker Worker(salt=3150528971, workers=1, host=192.168.0.100, username=fajarianatm, pid=79318) running   Transform()
2024-12-30 17:01:12,750 - INFO - Read Transform Query - SUCCESS
2024-12-30 17:01:12,751 - INFO - Connect to DWH - SUCCESS
2024-12-30 17:01:12,751 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 17:01:13,201 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 17:01:13,240 - ERROR - Transform Tables - FAILED
2024-12-30 17:01:13,243 - ERROR - [pid 79318] Worker Worker(salt=3150528971, workers=1, host=192.168.0.100, username=fajarianatm, pid=79318) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DuplicateObject: trigger "customer_insert_trigger" for relation "customers" already exists


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 101, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateObject) trigger "customer_insert_trigger" for relation "customers" already exists

[SQL: -- Step 1: Initial Load of dim_customers data
-- Insert initial data into dim_customers for the first time
-- Filter data staging untuk validasi
WITH valid_customers AS (
    SELECT
        c.id AS customer_id,
        c.customer_id AS customer_nk,
        c.customer_zip_code_prefix AS customer_zip_code,
        c.customer_city,
        c.customer_state
    FROM stg.customers c
    LEFT JOIN final.dim_customers d
        ON c.id = d.customer_id
        AND d.current_flag = 'current'
    WHERE d.customer_id IS NULL -- Pelanggan baru
       OR (
           c.customer_zip_code_prefix IS DISTINCT FROM d.customer_zip_code
           OR c.customer_city IS DISTINCT FROM d.customer_city
           OR c.customer_state IS DISTINCT FROM d.customer_state
       )
)
-- Insert valid data into dim_customers
INSERT INTO final.dim_customers (
    customer_id,
    customer_nk,
    customer_zip_code,
    customer_city,
    customer_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vc.customer_id,
    vc.customer_nk,
    vc.customer_zip_code,
    vc.customer_city,
    vc.customer_state,
    'current' AS current_flag,
    NOW() AS created_at,
    NULL AS expired_at,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_customers d
        WHERE d.customer_id = vc.customer_id
    ), 0) + 1 AS version_id
FROM valid_customers vc;


-- Verify the data inserted
SELECT * FROM final.dim_customers;

-- Step 2: Trigger Function to Insert New Data into dim_customers
CREATE OR REPLACE FUNCTION final.insert_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert data baru ke dalam dim_customers
    INSERT INTO final.dim_customers (
        customer_id,
        customer_nk,
        customer_zip_code,
        customer_city,
        customer_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.customer_id,
        NEW.customer_zip_code_prefix,
        NEW.customer_city,
        NEW.customer_state,
        'current', -- Set as current
        NOW(), -- Created at timestamp
        NULL, -- No expiration
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_customers
            WHERE customer_id = NEW.id
        ) -- Increment version_id
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;



-- Trigger untuk insert data baru
CREATE TRIGGER customer_insert_trigger
AFTER INSERT ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_customers();


-- Step 3: SCD Type 2 Update (Mark Old Record as Expired and Insert New Version)
CREATE OR REPLACE FUNCTION final.update_dim_customers()
RETURNS TRIGGER AS $$
BEGIN
    -- Update data lama menjadi expired
    UPDATE final.dim_customers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        customer_nk = NEW.customer_id
        AND current_flag = 'current'
        AND (
            NEW.customer_zip_code_prefix IS DISTINCT FROM customer_zip_code OR
            NEW.customer_city IS DISTINCT FROM customer_city OR
            NEW.customer_state IS DISTINCT FROM customer_state
        );

    -- Insert data baru (handled by insert_dim_customers trigger)
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;


-- Pasang trigger pada tabel stg.customers
CREATE TRIGGER trg_update_dim_customers
AFTER UPDATE ON stg.customers
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_customers();



]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 17:01:13,265 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 17:01:13,272 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 17:01:13,273 - DEBUG - Asking scheduler for work...
2024-12-30 17:01:13,274 - DEBUG - Done
2024-12-30 17:01:13,274 - DEBUG - There are no more tasks to run at this time
2024-12-30 17:01:13,274 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 17:01:13,275 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 17:01:13,275 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 17:01:13,275 - INFO - Worker Worker(salt=3150528971, workers=1, host=192.168.0.100, username=fajarianatm, pid=79318) was stopped. Shutting down Keep-Alive thread
2024-12-30 17:01:13,275 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 17:01:59,891 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 17:02:00,349 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 17:02:00,388 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 17:02:00,392 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 17:02:00,577 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 17:02:01,074 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 17:02:01,637 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 17:02:01,994 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 17:02:02,401 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 17:02:02,401 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 17:02:02,405 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 17:02:02,412 - INFO - [pid 85070] Worker Worker(salt=751024593, workers=1, host=192.168.0.100, username=fajarianatm, pid=85070) done      Extract()
2024-12-30 17:02:02,413 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 17:02:02,415 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 17:02:02,415 - DEBUG - Asking scheduler for work...
2024-12-30 17:02:02,417 - DEBUG - Pending tasks: 2
2024-12-30 17:02:02,417 - INFO - [pid 85070] Worker Worker(salt=751024593, workers=1, host=192.168.0.100, username=fajarianatm, pid=85070) running   Load()
2024-12-30 17:02:02,419 - INFO - Read Load Query - SUCCESS
2024-12-30 17:02:03,071 - INFO - Read Extracted Data - SUCCESS
2024-12-30 17:02:03,072 - INFO - Connect to DWH - SUCCESS
2024-12-30 17:02:03,160 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 17:02:03,161 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 17:02:04,956 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 17:02:04,999 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 17:02:05,002 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 17:02:06,040 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 17:02:08,825 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 17:02:12,768 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 17:02:15,051 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 17:02:17,433 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 17:02:17,433 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 17:02:25,157 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 17:02:25,164 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 17:02:25,240 - INFO - [pid 85070] Worker Worker(salt=751024593, workers=1, host=192.168.0.100, username=fajarianatm, pid=85070) done      Load()
2024-12-30 17:02:25,241 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 17:02:25,244 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 17:02:25,244 - DEBUG - Asking scheduler for work...
2024-12-30 17:02:25,246 - DEBUG - Pending tasks: 1
2024-12-30 17:02:25,246 - INFO - [pid 85070] Worker Worker(salt=751024593, workers=1, host=192.168.0.100, username=fajarianatm, pid=85070) running   Transform()
2024-12-30 17:02:25,249 - INFO - Read Transform Query - SUCCESS
2024-12-30 17:02:25,249 - INFO - Connect to DWH - SUCCESS
2024-12-30 17:02:25,250 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 17:02:26,026 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 17:02:26,045 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 17:02:26,171 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 17:02:30,103 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 17:02:32,115 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 17:02:32,657 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 17:02:32,701 - ERROR - Transform Tables - FAILED
2024-12-30 17:02:32,704 - ERROR - [pid 85070] Worker Worker(salt=751024593, workers=1, host=192.168.0.100, username=fajarianatm, pid=85070) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.CardinalityViolation: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.CardinalityViolation) ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    dim_sellers AS (
        SELECT *
        FROM final.dim_sellers
    ),
    
    cnt_product_sales AS (
        SELECT 
            DATE(so.order_purchase_timestamp) AS order_date,
            soi.order_id,
            soi.product_id,
            soi.seller_id,
            COUNT(soi.product_id) AS sales_quantity,
            SUM(soi.price) AS total_sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        WHERE so.order_status = 'delivered'
        GROUP BY 1, 2, 3, 4 -- Added soi.seller_id (column index 4) to GROUP BY
    ),

    final_fct_sales_daily AS (
        SELECT
            cps.order_id AS order_nk,
            dd.date_id AS date_id,
            dp.product_id AS product_id,
            ds.seller_id AS seller_id,
            cps.sales_quantity AS sales_quantity,
            cps.total_sales_value AS sales_value
        FROM cnt_product_sales cps
        JOIN final.dim_date dd ON dd.date_actual = cps.order_date
        JOIN final.dim_products dp ON dp.product_nk = cps.product_id
        JOIN final.dim_sellers ds ON ds.seller_nk = cps.seller_id
    )

INSERT INTO final.fct_sales_daily(
    order_nk,
    date_id,
    product_id,
    seller_id,
    sales_quantity,
    sales_value
)
SELECT *
FROM final_fct_sales_daily
ON CONFLICT(date_id, product_id, seller_id)
DO UPDATE SET
    order_nk = EXCLUDED.order_nk,
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.order_nk <> EXCLUDED.order_nk
                        OR final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 17:02:32,728 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 17:02:32,734 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 17:02:32,734 - DEBUG - Asking scheduler for work...
2024-12-30 17:02:32,737 - DEBUG - Done
2024-12-30 17:02:32,737 - DEBUG - There are no more tasks to run at this time
2024-12-30 17:02:32,737 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 17:02:32,737 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 17:02:32,737 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 17:02:32,737 - INFO - Worker Worker(salt=751024593, workers=1, host=192.168.0.100, username=fajarianatm, pid=85070) was stopped. Shutting down Keep-Alive thread
2024-12-30 17:02:32,738 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 21:04:00,919 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 21:04:01,622 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 21:04:01,665 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 21:04:01,672 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 21:04:01,845 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 21:04:02,324 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 21:04:02,889 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 21:04:03,248 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 21:04:03,664 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 21:04:03,664 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 21:04:03,668 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 21:04:03,675 - INFO - [pid 1843] Worker Worker(salt=7732759194, workers=1, host=192.168.0.100, username=fajarianatm, pid=1843) done      Extract()
2024-12-30 21:04:03,676 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 21:04:03,678 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 21:04:03,678 - DEBUG - Asking scheduler for work...
2024-12-30 21:04:03,679 - DEBUG - Pending tasks: 2
2024-12-30 21:04:03,679 - INFO - [pid 1843] Worker Worker(salt=7732759194, workers=1, host=192.168.0.100, username=fajarianatm, pid=1843) running   Load()
2024-12-30 21:04:03,682 - INFO - Read Load Query - SUCCESS
2024-12-30 21:04:04,363 - INFO - Read Extracted Data - SUCCESS
2024-12-30 21:04:04,364 - INFO - Connect to DWH - SUCCESS
2024-12-30 21:04:04,425 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 21:04:04,425 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 21:04:06,227 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 21:04:06,267 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 21:04:06,270 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 21:04:07,298 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 21:04:10,173 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 21:04:14,312 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 21:04:16,673 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 21:04:19,079 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 21:04:19,079 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 21:04:27,386 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 21:04:27,394 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 21:04:27,449 - INFO - [pid 1843] Worker Worker(salt=7732759194, workers=1, host=192.168.0.100, username=fajarianatm, pid=1843) done      Load()
2024-12-30 21:04:27,450 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 21:04:27,453 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 21:04:27,453 - DEBUG - Asking scheduler for work...
2024-12-30 21:04:27,455 - DEBUG - Pending tasks: 1
2024-12-30 21:04:27,455 - INFO - [pid 1843] Worker Worker(salt=7732759194, workers=1, host=192.168.0.100, username=fajarianatm, pid=1843) running   Transform()
2024-12-30 21:04:27,458 - INFO - Read Transform Query - SUCCESS
2024-12-30 21:04:27,459 - INFO - Connect to DWH - SUCCESS
2024-12-30 21:04:27,459 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 21:04:28,288 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 21:04:28,302 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 21:04:28,441 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 21:04:32,234 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 21:04:34,322 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 21:04:34,325 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 21:04:34,368 - ERROR - Transform Tables - FAILED
2024-12-30 21:04:34,374 - ERROR - [pid 1843] Worker Worker(salt=7732759194, workers=1, host=192.168.0.100, username=fajarianatm, pid=1843) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "order_date" of relation "fct_sales_daily" does not exist
LINE 32:     order_date,
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "order_date" of relation "fct_sales_daily" does not exist
LINE 32:     order_date,
             ^

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    cnt_product_sales AS (
        SELECT
            dd.date_actual AS order_date,
            dp.product_id,
            COUNT(dp.product_id) AS sales_quantity,
            SUM(soi.price) AS total_sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        JOIN final.dim_date dd ON dd.date_actual = DATE(so.order_purchase_timestamp)
        JOIN final.dim_products dp ON dp.product_nk = soi.product_id
        WHERE so.order_status = 'delivered'
        GROUP BY dd.date_actual, dp.product_id
    )

INSERT INTO final.fct_sales_daily (
    order_date,
    product_id,
    sales_quantity,
    sales_value
)
SELECT
    order_date,
    product_id,
    sales_quantity,
    total_sales_value
FROM cnt_product_sales
ON CONFLICT (order_date, product_id)
DO UPDATE SET
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 21:04:34,396 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 21:04:34,402 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 21:04:34,402 - DEBUG - Asking scheduler for work...
2024-12-30 21:04:34,404 - DEBUG - Done
2024-12-30 21:04:34,404 - DEBUG - There are no more tasks to run at this time
2024-12-30 21:04:34,404 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 21:04:34,404 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 21:04:34,404 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 21:04:34,404 - INFO - Worker Worker(salt=7732759194, workers=1, host=192.168.0.100, username=fajarianatm, pid=1843) was stopped. Shutting down Keep-Alive thread
2024-12-30 21:04:34,406 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 21:06:28,495 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 21:06:28,979 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 21:06:29,010 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 21:06:29,013 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 21:06:29,184 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 21:06:29,672 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 21:06:30,233 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 21:06:30,596 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 21:06:31,070 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 21:06:31,070 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 21:06:31,073 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 21:06:31,080 - INFO - [pid 2955] Worker Worker(salt=7481595210, workers=1, host=192.168.0.100, username=fajarianatm, pid=2955) done      Extract()
2024-12-30 21:06:31,080 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 21:06:31,083 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 21:06:31,083 - DEBUG - Asking scheduler for work...
2024-12-30 21:06:31,084 - DEBUG - Pending tasks: 2
2024-12-30 21:06:31,084 - INFO - [pid 2955] Worker Worker(salt=7481595210, workers=1, host=192.168.0.100, username=fajarianatm, pid=2955) running   Load()
2024-12-30 21:06:31,086 - INFO - Read Load Query - SUCCESS
2024-12-30 21:06:31,740 - INFO - Read Extracted Data - SUCCESS
2024-12-30 21:06:31,741 - INFO - Connect to DWH - SUCCESS
2024-12-30 21:06:31,778 - ERROR - Truncate Bookings Schema in DWH - FAILED
2024-12-30 21:06:31,802 - ERROR - [pid 2955] Worker Worker(salt=7481595210, workers=1, host=192.168.0.100, username=fajarianatm, pid=2955) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InvalidSchemaName: schema "src" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 130, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.InvalidSchemaName) schema "src" does not exist

[SQL: TRUNCATE TABLE src.order_items CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 142, in run
    raise Exception("Failed to Truncate Bookings Schema in DWH")
Exception: Failed to Truncate Bookings Schema in DWH
2024-12-30 21:06:31,816 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 21:06:31,821 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-30 21:06:31,821 - DEBUG - Asking scheduler for work...
2024-12-30 21:06:31,825 - DEBUG - Done
2024-12-30 21:06:31,825 - DEBUG - There are no more tasks to run at this time
2024-12-30 21:06:31,825 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-30 21:06:31,825 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-30 21:06:31,825 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-30 21:06:31,825 - INFO - Worker Worker(salt=7481595210, workers=1, host=192.168.0.100, username=fajarianatm, pid=2955) was stopped. Shutting down Keep-Alive thread
2024-12-30 21:06:31,826 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 21:07:42,151 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 21:07:42,577 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 21:07:42,617 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 21:07:42,619 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 21:07:42,888 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 21:07:43,380 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 21:07:43,939 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 21:07:44,293 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 21:07:44,695 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 21:07:44,695 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 21:07:44,699 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 21:07:44,707 - INFO - [pid 3772] Worker Worker(salt=9948825365, workers=1, host=192.168.0.100, username=fajarianatm, pid=3772) done      Extract()
2024-12-30 21:07:44,707 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 21:07:44,709 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 21:07:44,709 - DEBUG - Asking scheduler for work...
2024-12-30 21:07:44,711 - DEBUG - Pending tasks: 2
2024-12-30 21:07:44,711 - INFO - [pid 3772] Worker Worker(salt=9948825365, workers=1, host=192.168.0.100, username=fajarianatm, pid=3772) running   Load()
2024-12-30 21:07:44,713 - INFO - Read Load Query - SUCCESS
2024-12-30 21:07:45,390 - INFO - Read Extracted Data - SUCCESS
2024-12-30 21:07:45,391 - INFO - Connect to DWH - SUCCESS
2024-12-30 21:07:45,448 - ERROR - Truncate Bookings Schema in DWH - FAILED
2024-12-30 21:07:45,474 - ERROR - [pid 3772] Worker Worker(salt=9948825365, workers=1, host=192.168.0.100, username=fajarianatm, pid=3772) failed    Load()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InvalidSchemaName: schema "src" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 130, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.InvalidSchemaName) schema "src" does not exist

[SQL: TRUNCATE TABLE src.order_items CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/load.py", line 142, in run
    raise Exception("Failed to Truncate Bookings Schema in DWH")
Exception: Failed to Truncate Bookings Schema in DWH
2024-12-30 21:07:45,490 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 21:07:45,495 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-12-30 21:07:45,495 - DEBUG - Asking scheduler for work...
2024-12-30 21:07:45,498 - DEBUG - Done
2024-12-30 21:07:45,498 - DEBUG - There are no more tasks to run at this time
2024-12-30 21:07:45,498 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-12-30 21:07:45,498 - DEBUG - There are 2 pending tasks unique to this worker
2024-12-30 21:07:45,498 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-12-30 21:07:45,498 - INFO - Worker Worker(salt=9948825365, workers=1, host=192.168.0.100, username=fajarianatm, pid=3772) was stopped. Shutting down Keep-Alive thread
2024-12-30 21:07:45,498 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 22:10:50,641 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 22:10:51,212 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 22:10:51,260 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 22:10:51,264 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 22:10:51,440 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 22:10:51,943 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 22:10:52,507 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 22:10:52,853 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 22:10:53,280 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 22:10:53,280 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 22:10:53,286 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 22:10:53,295 - INFO - [pid 31534] Worker Worker(salt=3674310074, workers=1, host=192.168.0.100, username=fajarianatm, pid=31534) done      Extract()
2024-12-30 22:10:53,295 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:10:53,297 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 22:10:53,298 - DEBUG - Asking scheduler for work...
2024-12-30 22:10:53,299 - DEBUG - Pending tasks: 2
2024-12-30 22:10:53,299 - INFO - [pid 31534] Worker Worker(salt=3674310074, workers=1, host=192.168.0.100, username=fajarianatm, pid=31534) running   Load()
2024-12-30 22:10:53,301 - INFO - Read Load Query - SUCCESS
2024-12-30 22:10:53,960 - INFO - Read Extracted Data - SUCCESS
2024-12-30 22:10:53,960 - INFO - Connect to DWH - SUCCESS
2024-12-30 22:10:54,042 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 22:10:54,042 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 22:10:55,806 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 22:10:55,883 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 22:10:55,886 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 22:10:56,940 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 22:10:59,830 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 22:11:03,882 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 22:11:06,219 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 22:11:08,763 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 22:11:08,764 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 22:11:17,392 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 22:11:17,409 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 22:11:17,465 - INFO - [pid 31534] Worker Worker(salt=3674310074, workers=1, host=192.168.0.100, username=fajarianatm, pid=31534) done      Load()
2024-12-30 22:11:17,465 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:11:17,468 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 22:11:17,469 - DEBUG - Asking scheduler for work...
2024-12-30 22:11:17,470 - DEBUG - Pending tasks: 1
2024-12-30 22:11:17,470 - INFO - [pid 31534] Worker Worker(salt=3674310074, workers=1, host=192.168.0.100, username=fajarianatm, pid=31534) running   Transform()
2024-12-30 22:11:17,472 - INFO - Read Transform Query - SUCCESS
2024-12-30 22:11:17,473 - INFO - Connect to DWH - SUCCESS
2024-12-30 22:11:17,473 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 22:11:18,405 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 22:11:18,410 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 22:11:18,453 - ERROR - Transform Tables - FAILED
2024-12-30 22:11:18,456 - ERROR - [pid 31534] Worker Worker(salt=3674310074, workers=1, host=192.168.0.100, username=fajarianatm, pid=31534) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.DuplicateAlias: table name "d" specified more than once


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 106, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateAlias) table name "d" specified more than once

[SQL: -- Step 1: Initial Load of dim_sellers data
WITH valid_sellers AS (
    SELECT
        d.id AS seller_id,
        d.seller_id AS seller_nk,
        d.seller_zip_code_prefix AS seller_zip_code,
        d.seller_city,
        d.seller_state
    FROM stg.sellers d
    LEFT JOIN final.dim_sellers d
        ON d.id = d.seller_id
        AND d.current_flag = 'current'
    WHERE d.seller_id IS NULL
       OR (
           d.seller_zip_code_prefix IS DISTINCT FROM d.seller_zip_code
           OR d.seller_city IS DISTINCT FROM d.seller_city
           OR d.seller_state IS DISTINCT FROM d.seller_state
       )
)
INSERT INTO final.dim_sellers (
    seller_id,
    seller_nk,
    seller_zip_code,
    seller_city,
    seller_state,
    current_flag,
    created_at,
    expired_at,
    version_id
)
SELECT 
    vs.seller_id,
    vs.seller_nk,
    vs.seller_zip_code,
    vs.seller_city,
    vs.seller_state,
    'current',
    NOW(),
    NULL,
    COALESCE((
        SELECT MAX(version_id)
        FROM final.dim_sellers d
        WHERE d.seller_id = vs.seller_id
    ), 0) + 1
FROM valid_sellers vs;

-- Trigger Function: Insert new data into dim_sellers
CREATE OR REPLACE FUNCTION final.insert_dim_sellers()
RETURNS TRIGGER AS $$
BEGIN
    INSERT INTO final.dim_sellers (
        seller_id,
        seller_nk,
        seller_zip_code,
        seller_city,
        seller_state,
        current_flag,
        created_at,
        expired_at,
        version_id
    )
    VALUES (
        NEW.id,
        NEW.seller_id,
        NEW.seller_zip_code_prefix,
        NEW.seller_city,
        NEW.seller_state,
        'current',
        NOW(),
        NULL,
        (
            SELECT COALESCE(MAX(version_id), 0) + 1
            FROM final.dim_sellers
            WHERE seller_id = NEW.id
        )
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Remove and recreate seller_insert_trigger
DO $$
BEGIN
    IF EXISTS (
        SELECT 1
        FROM pg_trigger
        WHERE tgname = 'seller_insert_trigger'
    ) THEN
        DROP TRIGGER seller_insert_trigger ON stg.sellers;
    END IF;

    CREATE TRIGGER seller_insert_trigger
    AFTER INSERT ON stg.sellers
    FOR EACH ROW
    EXECUTE FUNCTION final.insert_dim_sellers();
END;
$$;

-- Trigger Function: SCD Type 2 update
CREATE OR REPLACE FUNCTION final.update_dim_sellers()
RETURNS TRIGGER AS $$
BEGIN
    UPDATE final.dim_sellers
    SET 
        current_flag = 'expired',
        expired_at = CURRENT_TIMESTAMP
    WHERE 
        seller_nk = NEW.seller_id
        AND current_flag = 'current'
        AND (
            NEW.seller_zip_code_prefix IS DISTINCT FROM seller_zip_code OR
            NEW.seller_city IS DISTINCT FROM seller_city OR
            NEW.seller_state IS DISTINCT FROM seller_state
        );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Remove and recreate trg_update_dim_sellers
DO $$
BEGIN
    IF EXISTS (
        SELECT 1
        FROM pg_trigger
        WHERE tgname = 'trg_update_dim_sellers'
    ) THEN
        DROP TRIGGER trg_update_dim_sellers ON stg.sellers;
    END IF;

    CREATE TRIGGER trg_update_dim_sellers
    AFTER UPDATE ON stg.sellers
    FOR EACH ROW
    EXECUTE FUNCTION final.update_dim_sellers();
END;
$$;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 22:11:18,481 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:11:18,491 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 22:11:18,491 - DEBUG - Asking scheduler for work...
2024-12-30 22:11:18,492 - DEBUG - Done
2024-12-30 22:11:18,493 - DEBUG - There are no more tasks to run at this time
2024-12-30 22:11:18,493 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 22:11:18,493 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 22:11:18,493 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 22:11:18,493 - INFO - Worker Worker(salt=3674310074, workers=1, host=192.168.0.100, username=fajarianatm, pid=31534) was stopped. Shutting down Keep-Alive thread
2024-12-30 22:11:18,493 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 22:15:02,779 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 22:15:03,252 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 22:15:03,289 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 22:15:03,292 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 22:15:03,468 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 22:15:03,953 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 22:15:04,505 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 22:15:04,842 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 22:15:05,281 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 22:15:05,281 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 22:15:05,285 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 22:15:05,292 - INFO - [pid 33309] Worker Worker(salt=7722700220, workers=1, host=192.168.0.100, username=fajarianatm, pid=33309) done      Extract()
2024-12-30 22:15:05,293 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:15:05,296 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 22:15:05,296 - DEBUG - Asking scheduler for work...
2024-12-30 22:15:05,298 - DEBUG - Pending tasks: 2
2024-12-30 22:15:05,298 - INFO - [pid 33309] Worker Worker(salt=7722700220, workers=1, host=192.168.0.100, username=fajarianatm, pid=33309) running   Load()
2024-12-30 22:15:05,300 - INFO - Read Load Query - SUCCESS
2024-12-30 22:15:05,996 - INFO - Read Extracted Data - SUCCESS
2024-12-30 22:15:05,997 - INFO - Connect to DWH - SUCCESS
2024-12-30 22:15:06,115 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 22:15:06,115 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 22:15:07,941 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 22:15:07,978 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 22:15:07,981 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 22:15:09,052 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 22:15:11,834 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 22:15:15,967 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 22:15:18,460 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 22:15:20,881 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 22:15:20,881 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 22:15:29,947 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 22:15:29,965 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 22:15:30,029 - INFO - [pid 33309] Worker Worker(salt=7722700220, workers=1, host=192.168.0.100, username=fajarianatm, pid=33309) done      Load()
2024-12-30 22:15:30,030 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:15:30,033 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 22:15:30,033 - DEBUG - Asking scheduler for work...
2024-12-30 22:15:30,035 - DEBUG - Pending tasks: 1
2024-12-30 22:15:30,035 - INFO - [pid 33309] Worker Worker(salt=7722700220, workers=1, host=192.168.0.100, username=fajarianatm, pid=33309) running   Transform()
2024-12-30 22:15:30,036 - INFO - Read Transform Query - SUCCESS
2024-12-30 22:15:30,037 - INFO - Connect to DWH - SUCCESS
2024-12-30 22:15:30,037 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 22:16:23,318 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 22:16:23,338 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 22:16:23,486 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 22:16:26,592 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 22:16:28,320 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 22:16:28,323 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 22:16:28,375 - ERROR - Transform Tables - FAILED
2024-12-30 22:16:28,379 - ERROR - [pid 33309] Worker Worker(salt=7722700220, workers=1, host=192.168.0.100, username=fajarianatm, pid=33309) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.GroupingError: column "dd.date_id" must appear in the GROUP BY clause or be used in an aggregate function
LINE 19:             dd.date_id,
                     ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 129, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.GroupingError) column "dd.date_id" must appear in the GROUP BY clause or be used in an aggregate function
LINE 19:             dd.date_id,
                     ^

[SQL: WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_products AS (
        SELECT *
        FROM final.dim_products
    ),

    cnt_product_sales AS (
        SELECT
            dd.date_id,
            dp.product_id,
            COUNT(dp.product_id) AS sales_quantity,
            SUM(soi.price) AS total_sales_value
        FROM stg.order_items soi
        JOIN stg.orders so ON so.order_id = soi.order_id
        JOIN final.dim_date dd ON dd.date_actual = DATE(so.order_purchase_timestamp)
        JOIN final.dim_products dp ON dp.product_nk = soi.product_id
        WHERE so.order_status = 'delivered'
        GROUP BY dd.date_actual, dp.product_id
    )

INSERT INTO final.fct_sales_daily (
    date_id,
    product_id,
    sales_quantity,
    sales_value
)
SELECT
    date_id,
    product_id,
    sales_quantity,
    total_sales_value
FROM cnt_product_sales
ON CONFLICT (date_id, product_id)
DO UPDATE SET
    sales_quantity = EXCLUDED.sales_quantity,
    sales_value = EXCLUDED.sales_value,
    updated_at = CASE 
                    WHEN final.fct_sales_daily.sales_quantity <> EXCLUDED.sales_quantity
                        OR final.fct_sales_daily.sales_value <> EXCLUDED.sales_value
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_sales_daily.updated_at
                 END;
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 22:16:28,408 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:16:28,415 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 22:16:28,416 - DEBUG - Asking scheduler for work...
2024-12-30 22:16:28,417 - DEBUG - Done
2024-12-30 22:16:28,417 - DEBUG - There are no more tasks to run at this time
2024-12-30 22:16:28,417 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 22:16:28,417 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 22:16:28,417 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 22:16:28,417 - INFO - Worker Worker(salt=7722700220, workers=1, host=192.168.0.100, username=fajarianatm, pid=33309) was stopped. Shutting down Keep-Alive thread
2024-12-30 22:16:28,418 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 22:19:09,693 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 22:19:10,118 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 22:19:10,156 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 22:19:10,159 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 22:19:10,342 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 22:19:10,826 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 22:19:11,389 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 22:19:11,729 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 22:19:12,132 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 22:19:12,132 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 22:19:12,136 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 22:19:12,144 - INFO - [pid 35081] Worker Worker(salt=7861845920, workers=1, host=192.168.0.100, username=fajarianatm, pid=35081) done      Extract()
2024-12-30 22:19:12,144 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:19:12,146 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 22:19:12,146 - DEBUG - Asking scheduler for work...
2024-12-30 22:19:12,148 - DEBUG - Pending tasks: 2
2024-12-30 22:19:12,148 - INFO - [pid 35081] Worker Worker(salt=7861845920, workers=1, host=192.168.0.100, username=fajarianatm, pid=35081) running   Load()
2024-12-30 22:19:12,150 - INFO - Read Load Query - SUCCESS
2024-12-30 22:19:12,792 - INFO - Read Extracted Data - SUCCESS
2024-12-30 22:19:12,792 - INFO - Connect to DWH - SUCCESS
2024-12-30 22:19:12,916 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 22:19:12,917 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 22:19:14,685 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 22:19:14,729 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 22:19:14,733 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 22:19:15,787 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 22:19:18,638 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 22:19:22,558 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 22:19:24,845 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 22:19:27,211 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 22:19:27,212 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 22:31:51,174 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 22:31:51,204 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 22:31:51,268 - INFO - [pid 35081] Worker Worker(salt=7861845920, workers=1, host=192.168.0.100, username=fajarianatm, pid=35081) done      Load()
2024-12-30 22:31:51,270 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:31:51,274 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 22:31:51,274 - DEBUG - Asking scheduler for work...
2024-12-30 22:31:51,277 - DEBUG - Pending tasks: 1
2024-12-30 22:31:51,277 - INFO - [pid 35081] Worker Worker(salt=7861845920, workers=1, host=192.168.0.100, username=fajarianatm, pid=35081) running   Transform()
2024-12-30 22:31:51,279 - INFO - Read Transform Query - SUCCESS
2024-12-30 22:31:51,280 - INFO - Connect to DWH - SUCCESS
2024-12-30 22:31:51,280 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 22:31:51,730 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 22:31:51,736 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 22:31:51,739 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 22:31:51,776 - ERROR - Transform Tables - FAILED
2024-12-30 22:31:51,778 - ERROR - [pid 35081] Worker Worker(salt=7861845920, workers=1, host=192.168.0.100, username=fajarianatm, pid=35081) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dim_products_pkey"
DETAIL:  Key (product_id)=(7811dc39-a97e-40f0-9903-cac16a0cfce9) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 111, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dim_products_pkey"
DETAIL:  Key (product_id)=(7811dc39-a97e-40f0-9903-cac16a0cfce9) already exists.

[SQL: -- Step 1: Initial Load od dim_products data
-- This will insert teh data into dim_products for the first time
INSERT INTO final.dim_products (
    product_id,
    product_nk,
    product_category_name,
    product_category_name_english,
    product_name_length,
    product_description_length,
    product_photos_qty,
    product_weight_g,
    product_length_cm,
    product_height_cm,
    product_width_cm,
    created_at,
    updated_at
)

SELECT
    p.id AS product_id,
    p.product_id AS product_nk,
    p.product_category_name,
    pc.product_category_name_english,
    p.product_name_length,
    p.product_description_length,
    p.product_photos_qty,
    p.product_weight_g,
    p.product_length_cm,
    p.product_height_cm,
    p.product_width_cm,
    NOW() AS created_at,
    NOW() AS updated_at
FROM stg.products AS p
JOIN stg.product_category_name_translation AS pc 
    ON p.product_category_name = pc.product_category_name;

-- Verivy the data inserted
SELECT * FROM final.dim_products;

------------------------------------------------------------------------------------------------------------

-- Step 2: Trigger Functions to Insert New Data into dim_products
CREATE OR REPLACE FUNCTION final.insert_dim_products()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert new products data into the dim_products table
    INSERT INTO final.dim_products (
        product_id,
        product_nk,
        product_category_name,
        product_category_name_english,
        product_name_length,
        product_description_length,
        product_photos_qty,
        product_weight_g,
        product_length_cm,
        product_height_cm,
        product_width_cm,
        created_at,
        updated_at
    )
    SELECT
        NEW.id AS product_id,
        NEW.product_id AS product_nk,
        NEW.product_category_name,
        pc.product_category_name_english,
        NEW.product_name_length,
        NEW.product_description_length,
        NEW.product_photos_qty,
        NEW.product_weight_g,
        NEW.product_length_cm,
        NEW.product_height_cm,
        NEW.product_width_cm,
        NOW(),
        NOW()
    FROM stg.product_category_name_translation AS pc
    WHERE NEW.product_category_name = pc.product_category_name;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create a trigger for inserting new rows into dim_sellers
CREATE TRIGGER products_insert_trigger
AFTER INSERT ON stg.products
FOR EACH ROW
EXECUTE FUNCTION final.insert_dim_products();

------------------------------------------------------------------------------------------------------------

-- Step 3: SCD Type 1 Update (Insert New Version and Update the updated_at)
CREATE OR REPLACE FUNCTION final.update_dim_products()
RETURNS TRIGGER AS $$
BEGIN
    -- Update dim_products with new values from stg.products
    UPDATE final.dim_products
    SET
        product_category_name = NEW.product_category_name,
        product_category_name_english = (
            SELECT pc.product_category_name_english
            FROM stg.product_category_name_translation AS pc
            WHERE pc.product_category_name = NEW.product_category_name
        ),
        product_name_length = NEW.product_name_length,
        product_description_length = NEW.product_description_length,
        product_photos_qty = NEW.product_photos_qty,
        product_weight_g = NEW.product_weight_g,
        product_length_cm = NEW.product_length_cm,
        product_height_cm = NEW.product_height_cm,
        product_width_cm = NEW.product_width_cm,
        updated_at = NOW() -- Update timestamp for tracking changes
    WHERE product_nk = NEW.product_id; -- Match on natural key

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger for Handling Updates to Relevant Columns in stg.products
CREATE TRIGGER products_update_trigger
AFTER UPDATE OF 
    product_category_name,
    product_name_length,
    product_description_length,
    product_photos_qty,
    product_weight_g,
    product_length_cm,
    product_height_cm,
    product_width_cm
ON stg.products
FOR EACH ROW
EXECUTE FUNCTION final.update_dim_products();

]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 22:31:51,800 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:31:51,808 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 22:31:51,808 - DEBUG - Asking scheduler for work...
2024-12-30 22:31:51,809 - DEBUG - Done
2024-12-30 22:31:51,809 - DEBUG - There are no more tasks to run at this time
2024-12-30 22:31:51,809 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 22:31:51,809 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 22:31:51,809 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 22:31:51,809 - INFO - Worker Worker(salt=7861845920, workers=1, host=192.168.0.100, username=fajarianatm, pid=35081) was stopped. Shutting down Keep-Alive thread
2024-12-30 22:31:51,810 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 22:40:29,745 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 22:40:30,166 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 22:40:30,203 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 22:40:30,207 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 22:40:30,383 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 22:40:30,887 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 22:40:31,442 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 22:40:31,784 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 22:40:32,181 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 22:40:32,181 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 22:40:32,185 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 22:40:32,193 - INFO - [pid 44105] Worker Worker(salt=1140729946, workers=1, host=192.168.0.100, username=fajarianatm, pid=44105) done      Extract()
2024-12-30 22:40:32,193 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:40:32,195 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 22:40:32,195 - DEBUG - Asking scheduler for work...
2024-12-30 22:40:32,197 - DEBUG - Pending tasks: 2
2024-12-30 22:40:32,197 - INFO - [pid 44105] Worker Worker(salt=1140729946, workers=1, host=192.168.0.100, username=fajarianatm, pid=44105) running   Load()
2024-12-30 22:40:32,199 - INFO - Read Load Query - SUCCESS
2024-12-30 22:40:32,867 - INFO - Read Extracted Data - SUCCESS
2024-12-30 22:40:32,867 - INFO - Connect to DWH - SUCCESS
2024-12-30 22:40:32,986 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 22:40:32,986 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 22:40:34,788 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 22:40:34,827 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 22:40:34,830 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 22:40:35,857 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 22:40:38,727 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 22:40:42,666 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 22:40:45,014 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 22:40:47,606 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 22:40:47,607 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 22:53:06,963 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 22:53:06,982 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 22:53:07,077 - INFO - [pid 44105] Worker Worker(salt=1140729946, workers=1, host=192.168.0.100, username=fajarianatm, pid=44105) done      Load()
2024-12-30 22:53:07,077 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:53:07,081 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 22:53:07,081 - DEBUG - Asking scheduler for work...
2024-12-30 22:53:07,082 - DEBUG - Pending tasks: 1
2024-12-30 22:53:07,082 - INFO - [pid 44105] Worker Worker(salt=1140729946, workers=1, host=192.168.0.100, username=fajarianatm, pid=44105) running   Transform()
2024-12-30 22:53:07,084 - INFO - Read Transform Query - SUCCESS
2024-12-30 22:53:07,085 - INFO - Connect to DWH - SUCCESS
2024-12-30 22:53:07,085 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 22:53:07,312 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 22:53:07,317 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 22:53:07,318 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 22:53:10,540 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 22:53:12,408 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 22:53:13,898 - INFO - Transform to 'final.fct_sales_daily' - SUCCESS
2024-12-30 22:53:13,968 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-12-30 22:53:14,016 - ERROR - Transform Tables - FAILED
2024-12-30 22:53:14,020 - ERROR - [pid 44105] Worker Worker(salt=1140729946, workers=1, host=192.168.0.100, username=fajarianatm, pid=44105) failed    Transform()
Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.CardinalityViolation: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 134, in run
    session.execute(query)
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
           ^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.CardinalityViolation) ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

[SQL: -- stg.orders, stg.order_items, final.dim_date
WITH
    stg_orders AS (
        SELECT *
        FROM stg.orders
        WHERE order_status = 'delivered'
    ),

    stg_order_items AS (
        SELECT *
        FROM stg.order_items
    ),

    dim_date AS (
        SELECT *
        FROM final.dim_date
    ),

    final_fct_delivery_performance AS (
        SELECT 
            so.order_id AS order_nk,
            dd1.date_id AS order_purchase_at,
            dd2.date_id AS order_approved_at,
            dd3.date_id AS shipping_limit_date,
            dd4.date_id AS order_carrier_date,
            dd5.date_id AS order_delivered_customer_date,
            dd6.date_id AS order_estimated_delivery_date,
            so.order_status AS order_status,
            (so.order_approved_at - so.order_purchase_timestamp) AS purchase_to_approval_days,
            (so.order_delivered_carrier_date - so.order_approved_at) AS approval_to_shipping_days,
            (so.order_delivered_customer_date - order_delivered_carrier_date) AS shipping_to_delivery_days,
            (so.order_delivered_customer_date - order_estimated_delivery_date) AS delivery_to_estimated_days,
            (so.order_delivered_customer_date - order_approved_at) AS purchase_to_delivered_days,
            (soi.shipping_limit_date - order_delivered_carrier_date) AS shipping_limit_to_carrier_days

        FROM stg.orders so
        JOIN stg.order_items soi 
            ON soi.order_id = so.order_id
        JOIN final.dim_date dd1 
            ON dd1.date_actual = DATE(so.order_purchase_timestamp)
        JOIN final.dim_date dd2
            ON dd2.date_actual = DATE(so.order_approved_at)
        JOIN final.dim_date dd3
            ON dd3.date_actual = DATE(soi.shipping_limit_date)
        JOIN final.dim_date dd4
            ON dd4.date_actual = DATE(so.order_delivered_carrier_date)
        JOIN final.dim_date dd5
            ON dd5.date_actual = DATE(so.order_delivered_customer_date)
        JOIN final.dim_date dd6
            ON dd6.date_actual = DATE(so.order_estimated_delivery_date)
    )

INSERT INTO final.fct_delivery_performance (
    order_nk,
    order_purchase_at,
    order_approved_at,
    shipping_limit_date,
    order_carrier_date,
    order_delivered_customer_date,
    order_estimated_delivery_date,
    order_status,
    purchase_to_approval_days,
    approval_to_shipping_days,
    shipping_to_delivery_days,
    delivery_to_estimated_days,
    purchase_to_delivery_days,
    shipping_limit_to_carrier_days
)

SELECT *
FROM final_fct_delivery_performance

ON CONFLICT(order_nk)
DO UPDATE SET
    order_purchase_at = EXCLUDED.order_purchase_at,
    order_approved_at = EXCLUDED.order_approved_at,
    shipping_limit_date = EXCLUDED.shipping_limit_date,
    order_carrier_date = EXCLUDED.order_carrier_date,
    order_delivered_customer_date = EXCLUDED.order_delivered_customer_date,
    order_estimated_delivery_date = EXCLUDED.order_estimated_delivery_date,
    order_status = EXCLUDED.order_status,
    purchase_to_approval_days = EXCLUDED.purchase_to_approval_days,
    approval_to_shipping_days = EXCLUDED.approval_to_shipping_days,
    shipping_to_delivery_days = EXCLUDED.shipping_to_delivery_days,
    delivery_to_estimated_days = EXCLUDED.delivery_to_estimated_days,
    purchase_to_delivery_days = EXCLUDED.purchase_to_delivery_days,
    shipping_limit_to_carrier_days = EXCLUDED.shipping_limit_to_carrier_days,
    updated_at = CASE 
                    WHEN
                        final.fct_delivery_performance.order_purchase_at <> EXCLUDED.order_purchase_at
                        OR final.fct_delivery_performance.order_approved_at <> EXCLUDED.order_approved_at
                        OR final.fct_delivery_performance.shipping_limit_date <> EXCLUDED.shipping_limit_date
                        OR final.fct_delivery_performance.order_carrier_date <> EXCLUDED.order_carrier_date
                        OR final.fct_delivery_performance.order_delivered_customer_date <> EXCLUDED.order_delivered_customer_date
                        OR final.fct_delivery_performance.order_estimated_delivery_date <> EXCLUDED.order_estimated_delivery_date
                        OR final.fct_delivery_performance.order_status <> EXCLUDED.order_status
                        OR final.fct_delivery_performance.purchase_to_approval_days <> EXCLUDED.purchase_to_approval_days
                        OR final.fct_delivery_performance.approval_to_shipping_days <> EXCLUDED.approval_to_shipping_days
                        OR final.fct_delivery_performance.shipping_to_delivery_days <> EXCLUDED.shipping_to_delivery_days
                        OR final.fct_delivery_performance.delivery_to_estimated_days <> EXCLUDED.delivery_to_estimated_days
                        OR final.fct_delivery_performance.purchase_to_delivery_days <> EXCLUDED.purchase_to_delivery_days
                        OR final.fct_delivery_performance.shipping_limit_to_carrier_days <> EXCLUDED.shipping_limit_to_carrier_days
                    THEN CURRENT_TIMESTAMP
                    ELSE final.fct_delivery_performance.updated_at
                 END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/.venv/lib/python3.12/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
               ^^^^^^^^^^^^^^^
  File "/Users/fajarianatm/exc/olist_data-pipeline-orchestration/pipeline/transform.py", line 181, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-12-30 22:53:14,043 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 22:53:14,052 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-12-30 22:53:14,052 - DEBUG - Asking scheduler for work...
2024-12-30 22:53:14,053 - DEBUG - Done
2024-12-30 22:53:14,053 - DEBUG - There are no more tasks to run at this time
2024-12-30 22:53:14,053 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-30 22:53:14,053 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-30 22:53:14,053 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-30 22:53:14,054 - INFO - Worker Worker(salt=1140729946, workers=1, host=192.168.0.100, username=fajarianatm, pid=44105) was stopped. Shutting down Keep-Alive thread
2024-12-30 22:53:14,054 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-30 23:25:23,063 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-30 23:25:23,706 - INFO - EXTRACT 'public.customers' - SUCCESS.
2024-12-30 23:25:23,742 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2024-12-30 23:25:23,747 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2024-12-30 23:25:23,930 - INFO - EXTRACT 'public.products' - SUCCESS.
2024-12-30 23:25:24,466 - INFO - EXTRACT 'public.orders' - SUCCESS.
2024-12-30 23:25:25,088 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2024-12-30 23:25:25,480 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2024-12-30 23:25:25,914 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2024-12-30 23:25:25,915 - INFO - Extract All Tables From Sources - SUCCESS
2024-12-30 23:25:25,919 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-12-30 23:25:25,927 - INFO - [pid 62711] Worker Worker(salt=2767675420, workers=1, host=192.168.0.100, username=fajarianatm, pid=62711) done      Extract()
2024-12-30 23:25:25,927 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 23:25:25,930 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-12-30 23:25:25,930 - DEBUG - Asking scheduler for work...
2024-12-30 23:25:25,931 - DEBUG - Pending tasks: 2
2024-12-30 23:25:25,931 - INFO - [pid 62711] Worker Worker(salt=2767675420, workers=1, host=192.168.0.100, username=fajarianatm, pid=62711) running   Load()
2024-12-30 23:25:25,933 - INFO - Read Load Query - SUCCESS
2024-12-30 23:25:26,678 - INFO - Read Extracted Data - SUCCESS
2024-12-30 23:25:26,679 - INFO - Connect to DWH - SUCCESS
2024-12-30 23:25:26,829 - INFO - Truncate Bookings Schema in DWH - SUCCESS
2024-12-30 23:25:26,829 - INFO - ==================================STARTING LOAD DATA=======================================
2024-12-30 23:25:28,788 - INFO - LOAD 'src.customers' - SUCCESS
2024-12-30 23:25:28,831 - INFO - LOAD 'src.sellers' - SUCCESS
2024-12-30 23:25:28,835 - INFO - LOAD 'src.product_category_name_translation' - SUCCESS
2024-12-30 23:25:29,928 - INFO - LOAD 'src.products' - SUCCESS
2024-12-30 23:25:32,816 - INFO - LOAD 'src.orders' - SUCCESS
2024-12-30 23:25:36,965 - INFO - LOAD 'src.order_items' - SUCCESS
2024-12-30 23:25:39,500 - INFO - LOAD 'src.order_payments' - SUCCESS
2024-12-30 23:25:42,066 - INFO - LOAD 'src.order_reviews' - SUCCESS
2024-12-30 23:25:42,066 - INFO - LOAD All Tables To DWH-src - SUCCESS
2024-12-30 23:40:18,551 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2024-12-30 23:40:18,571 - INFO - ==================================ENDING LOAD DATA=======================================
2024-12-30 23:40:18,631 - INFO - [pid 62711] Worker Worker(salt=2767675420, workers=1, host=192.168.0.100, username=fajarianatm, pid=62711) done      Load()
2024-12-30 23:40:18,632 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 23:40:18,636 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-12-30 23:40:18,636 - DEBUG - Asking scheduler for work...
2024-12-30 23:40:18,638 - DEBUG - Pending tasks: 1
2024-12-30 23:40:18,638 - INFO - [pid 62711] Worker Worker(salt=2767675420, workers=1, host=192.168.0.100, username=fajarianatm, pid=62711) running   Transform()
2024-12-30 23:40:18,641 - INFO - Read Transform Query - SUCCESS
2024-12-30 23:40:18,642 - INFO - Connect to DWH - SUCCESS
2024-12-30 23:40:18,642 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-12-30 23:40:19,146 - INFO - Transform to 'final.dim_customers' - SUCCESS
2024-12-30 23:40:19,155 - INFO - Transform to 'final.dim_sellers' - SUCCESS
2024-12-30 23:40:19,156 - INFO - Transform to 'final.dim_products' - SUCCESS
2024-12-30 23:40:22,969 - INFO - Transform to 'final.fct_orders' - SUCCESS
2024-12-30 23:40:24,911 - INFO - Transform to 'final.fct_reviews' - SUCCESS
2024-12-30 23:40:26,616 - INFO - Transform to 'final.fct_sales_daily' - SUCCESS
2024-12-30 23:40:29,809 - INFO - Transform to 'final.fct_delivery_performance' - SUCCESS
2024-12-30 23:40:29,811 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS
2024-12-30 23:40:29,814 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-12-30 23:40:29,814 - INFO - [pid 62711] Worker Worker(salt=2767675420, workers=1, host=192.168.0.100, username=fajarianatm, pid=62711) done      Transform()
2024-12-30 23:40:29,815 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-30 23:40:29,817 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-12-30 23:40:29,817 - DEBUG - Asking scheduler for work...
2024-12-30 23:40:29,819 - DEBUG - Done
2024-12-30 23:40:29,819 - DEBUG - There are no more tasks to run at this time
2024-12-30 23:40:29,819 - INFO - Worker Worker(salt=2767675420, workers=1, host=192.168.0.100, username=fajarianatm, pid=62711) was stopped. Shutting down Keep-Alive thread
2024-12-30 23:40:29,822 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

